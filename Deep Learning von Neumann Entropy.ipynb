{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "320177e1",
   "metadata": {},
   "source": [
    "A logical question first: deep learning von Neumann entropy from Renyi entropy or the alternative method? (In the first case, for each set of physical parameter, we only have one data point, which is not suitable for DL application)\n",
    "\n",
    "\n",
    "There are a few cases that we can study:\n",
    "\n",
    "1. Single Interval (both analytic Renyi and von Neumann are known)\n",
    "\n",
    "2. Single Interval at finite temperature and finite length (analytic Renyi is known, but von Neumann only known in high and low T expansions, we can do interpolation)\n",
    "\n",
    "3. Two Intervals (the general analytic Renyi is known, involves Riemann-Siegel theta fun; von Neumann unknown)\n",
    "(a) Small cross ratio $x \\to 0$ expansion: can get an approx of Renyi in orders of $x$.\n",
    "    (i) the analytic form of von Neumann to 1st order in $x$ is known. \n",
    "    \n",
    "    (ii)the analytic forms of von Neumann to 2nd order and above are unknown\n",
    "    (but we studied 2nd order in our paper, which is also hard to go to large $k$)\n",
    "    \n",
    "(b) Decompactification limit $\\eta \\to \\infty$: can get an approx of Renyi, as well as a good \"approx\" of von Neumann.\n",
    "\n",
    "(c) Most general $x$ and $\\eta$: von Neumann unknown, can only do the sum in our method for up to $k~15$ due to theta fun.\n",
    "\n",
    "4. Mutual Information with all the above cases.\n",
    "\n",
    "Actually we have analytic results for single interval finite T case and 2nd order small x.\n",
    "\n",
    "Note that we can also compare with XXZ spin-chain model.\n",
    "\n",
    "5. Other entanglement measure (modular entropy, relative entropy, reflected entropy, fidelity, free energy, entanglement negativity etc...) in both condensed matter and holographic systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97e5611",
   "metadata": {},
   "source": [
    "We tell NN the coefficients of the generating function $G(z;\\rho)$ up to a chosen $k$ in the Taylor expansion (then $k$ would become one of the hyperparameter, if k could be small, the better).\n",
    "\n",
    "We will feed in answers from the \"correct analytic formula\" (or the best known approx) with different physical parameters (not $k$!).\n",
    "\n",
    "NN will learn a function (we may tell NN perhaps a functional form/ansata). \n",
    "\n",
    "We then compare it to the one we get by simply summing all the coefficients (this is just like taking $w \\to 1$, the limit of getting the vN entropy). We must note that in our original approach, if $k$ small, we will get large error compared to the correct answer. If NN can use smaller $k$, but get a better result than the sum, good! This is because the coefficients up to $k$ order is the \"amount of information\" we have.\n",
    "\n",
    "\n",
    "But in case \"3-(c)\" we can also try a DL framework to estimate the values of higher $k$ for improvement of the alternative method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4acc95",
   "metadata": {},
   "source": [
    "A few places for improvements: (see the better general workflow later)\n",
    "\n",
    "1. More data input (not increasing $k$, but sets of data); More layers and nodes. Is this always a good way?\n",
    "2. Use different train_test_split (set up random_state)\n",
    "3. Use different activation functions (sigmoid, relu, etc...) in different combinations and order\n",
    "4. Scaler to scale the data to a certain range. This may avoid extreme values. Will this help? Probably not, no extreme values.\n",
    "5. Different types of hidden layers. (For regression, should just use Dense)\n",
    "6. Different optimizers (we may use SGD and adjustment of the learning rate, momentum).\n",
    "A few built-in options:\n",
    "\n",
    "Optimizers:\n",
    "1. SGD(with or without momentum) \n",
    "2. RMSprop (this optimizer is good for virtually any problem)\n",
    "3. Adam\n",
    "4. Adagrad\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=1e-4) to add learning rate\n",
    "\n",
    "7. Different loss functions.\n",
    "8. Adjusting training epochs\n",
    "9. We can also use train-validation-test separation.\n",
    "10. Use dropout, batch training etc... \n",
    "11. We can assume the NN at least know some functional form of the von Neumann.\n",
    "\n",
    "12. Or we can just use the same framework as in the paper.\n",
    "\n",
    "13. QML algorithms?\n",
    "\n",
    "\n",
    "The best way to improve a DL model is to train it with more data or better data (with enough representaion power, usually denser data points)! \n",
    "\n",
    "But we cannot increase the data points indefinitely. I will currently fix data points to 5000~20000 (and let $k$ never exceeds 200 such that the discrepancy of correct vs. approximate entropies are large enough), but with a denser distribution of physical parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8fef0f",
   "metadata": {},
   "source": [
    "1. Maintaing a holdout validation set: this is the way to go when you have plenty of data.\n",
    "2. Doing K-fold cross-validation: this is the right choice when you have too few samples for holdout validation to be reliable.\n",
    "3. Doing iterated K-fold validation: this is for performing highly accurate model evaluation when little data is available.\n",
    "\n",
    "We will perhaps want to do all the above cases if we are going to reduce the dataset availabe (can we determine the boundary of given data points with optimal performance?).\n",
    "\n",
    "Why? If we have too few data points, the validation set would end up being very small. As a consequence, the validation scores might change a lot depending on which data points we chose for validation and which we chose for training: the validation scores might have a high variance with regard to the validation split. This would prevent us from reliably evaluating our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e423d27a",
   "metadata": {},
   "source": [
    "The ideal model is one that stands right at the border between underfitting and overfitting. To figure out how big a model you will need, you must develop a model that overfits, this is easily done by:\n",
    "\n",
    "1. Add layers\n",
    "2. Make the layers bigger\n",
    "3. Train for more epochs\n",
    "When you see the model's performance on the validation data begins to degrade, you have achieved overfitting.\n",
    "\n",
    "Improving model fit:\n",
    "\n",
    "To achieve the perfect fit, you must first overfit. Since you don't know in advance where the boundary lies, you must cross it to find it. A model shows some generalization power means that it is able to overfit. There are three common problems:\n",
    "\n",
    "1. Training doesn't get started: your training loss doesn't go down over time.\n",
    "2. Training gets started just fine, but your model doesn't meanfully generalize: you cannot beat the common-sense baseline you set.\n",
    "3. Training and validation loss both go down over time, and you can beat your baseline, but you don't seem to be able to overfit, which indicates you are still underfitting.\n",
    "\n",
    "\n",
    "For case 1--> tuning key gradient descent parameters\n",
    "\n",
    "Sometimes training doesn't get started, or it stalls too early. Your loss is stuck. This is \"always\" something you can overcome. Even if nothing about your problem makes sense, you should still be able to train something-if only by memorizing the training data.\n",
    "\n",
    "This is always a problem with the configuration of the gradient descent process, your choice of optimizer, the distribution of initial values in the weights of your model, your learning rate, or your batch size. All these parameters and interdependent, and as such it is usually \"sufficient to tune the learning rate and the batch size\" while keeping the rest of the parameters constant.\n",
    "\n",
    "If you find yourself in a similar situation, try \n",
    "\n",
    "1. Lowering or increasing the learning rate. A learning rate that is too high may lead to updates that vastly overshoot a proper fit, and a learning rate that is too low may make training so slow that it appears to stall.\n",
    "\n",
    "2. Increasing the batch size. A batch with more samples will lead to gradients that are more informative and less noisy (lower variance).\n",
    "\n",
    "For case 2--> leveraging better architecture priors\n",
    "\n",
    "You have a model that fits, but for some reason your validation metrics aren't improving at all. Your model trains but doesn't generalize. This is perhaps the worst machine learning situation. It indicates that something is fundamentally wrong with your approach, and it may not be easy to tell what.\n",
    "\n",
    "First, it may be that the input data you are using simply doesn't contain sufficient information to predict your targets: the problem as formulated is not solvable. \n",
    "\n",
    "It may also be that the kind of model you are using is not suited for the problem at hand. Using a model that makes the right assumptions about the problem is essential to achieve generalization: you should leverage the right architecture priors. \n",
    "\n",
    "For case 3--> increasing model capacity\n",
    "\n",
    "If you manage to get to a model that fits, where validation metrics are going down, and that seems to achieve some level of generalization power, next, you need to get your model to start overfitting.\n",
    "\n",
    "In this case, validation metrics seem to stall, or to imrpove very slowly, instead of peaking and reversing course. The validation loss goes to, say, 0.26 and just stays there. You can fit, but you cannot clearly overfit, even after many iterations over the training data.\n",
    "\n",
    "It should always be possible to overfit. If you cannot seem to be able to overfit, it's likely a problem with the \"represnetational power\" on your model: you are going to need a bigger model, one with more \"capacity\", that is to say, one able to store more information.\n",
    "\n",
    "You can increase representational power by\n",
    "1. adding more layers\n",
    "2. using bigger layers (layers with more parameters)\n",
    "3. using kinds of layers that are more appropriate for the problem (better architecture priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575c5c02",
   "metadata": {},
   "source": [
    "Improving Generalization\n",
    "\n",
    "Once the model has some generalization power and be able to overfit, we should focus on maximizing generalization.\n",
    "\n",
    "EarlyStopping:\n",
    "\n",
    "We would start by training our models for longer than needed to figure out the number of epochs that yielded the best validation metrics, and then we would retrain a new model for exactly that number of epochs. This is standard, but it requires you to do redundant work, which can sometimes be expensive. \n",
    "\n",
    "Naturally, you could just save your model at the end of each epoch, and once you have found the best epoch, reuse the closest saved model you have.  In Keras, we can do this with an \"EarlyStopping\" callback, which will interrupt training as soon as validation metrics have stopped improving, while remembering the best known model state. (check this)\n",
    "\n",
    "Regularizing your model:\n",
    "\n",
    "Regularization techniques are a set of best practices that actively impede the model's ability to fit perfectly to the training data, with the goal of making the model perform better during validation. It tends to make the model simpler, more \"regular\", its curve smoother, more generic; thus it is less specific to the training set and better able to generalize by more closely approximating the latent manifold of the data. \n",
    "\n",
    "Three common approaches:\n",
    "\n",
    "1. Reducing the network's size\n",
    "\n",
    "2. Adding weight regularization\n",
    "\n",
    "3. Adding dropout\n",
    "\n",
    "Case 1: reducing the network's size\n",
    "\n",
    "There is no magical formula to determine the right number of layers or the right size for each layer. You must evaluate an array of different architectures (on your validation set, not on the test set) in order to find the correct model size for your data. The general workflow is to start with relatively few layers and parameters, and increase the size of the layers or add new layers until you see diminishing returns with regard to validation loss.\n",
    "\n",
    "The smaller model starts overfitting later than the large model, and its performance degrades (the increase of validation loss) more slowly once it starts overfitting. Then we add to the model with much more capacity, while it is standard to work with models that are significantly overparameterized, there can definitely be such a thing as \"too much\" memorization capacity.\n",
    "\n",
    "You will know your model is \"too large\" if it starts overfitting right away and if its validation loss curve looks choppy with high variacne (although choppy validation metrics could also be a symptom of using an unreliable validation process, such as a validation split that is too small).\n",
    "\n",
    "The bigger model starts overfitting almost immediately, after just one epoch, and it overfits much more severely. Its validation loss is also noisier. It gets training loss near zero very quickly. \n",
    "\n",
    "The more capacity the model has, the more quickly it can model the training data (resulting in a low training loss), but the more susceptible it is to overfitting (resulting in a large difference between the training and validation loss).\n",
    "\n",
    "Case 2: adding weight regularization (if your model is small)\n",
    "\n",
    "Occam's razor applies to DL models: given some training data and a network architecture, multiple sets of weight values (multiple models) could explain the data. Simpler models are less likely to overfit than complex ones.\n",
    "\n",
    "A simple model in this context is a model where the distribution of parameter values has \"less entropy\" (or a model with fewer parameters). Thus, a common way to mitigate overfitting is to put constraints on the complexity of a model by forcing its weights to take only small values, which makes the distribution of weight values more \"regular.\" This is called \"weight regularization\", and it's done by adding to the loss function of the model a cost associated with having large weights. This cost comes in two flavors:\n",
    "\n",
    "1. L1 regularization: the cost added is proportional to the absolute value of the weight coefficients (the L1 norm of the weights)\n",
    "2. L2 regularization: the cost addd is proportional to the square of the value of the weight coefficients (the L2 norm of the weights). L2 regularization is also called weight decay in the context of neural networks.  \n",
    "\n",
    "In Keras, weight regularization is added by passing weight regularizer instances to layers as keyword arguments.\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "...\n",
    "\n",
    "layers.Dense(16, kernel_regularizer=regularizers.l2(0.002), activation = ...)\n",
    "\n",
    "this means every coefficient in the weight matrix of the layer will add $0.002*\\text{weight_coefficient_value}**2$ to the total loss of the model. Note that because this penalty is \"only added at training time\", the loss for this model will be much higher at training than at test time. With L2 regularization, the model will be more resistent to overfitting.\n",
    "\n",
    "One can also use:\n",
    "\n",
    "regularizers_l1(0.001)  L1 regularization\n",
    "\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001) L1 and L2 simultaneously\n",
    "\n",
    "Case 3: adding dropout\n",
    "\n",
    "Dropout is one of the most effective and most commonly used regularization techniques for neural networks. Dropout, applied to a layer, consists of randomly dropping out (setting to zero) a number of output features of the layer during training. The \"dropout rate\" is the fraction of the features that are zeroed out; it's usually set between 0.2 and 0.5.\n",
    "\n",
    "At test time, no units are dropped out; instead, the layer's output values are scaled down by a factor equal to the dropout rate, to balance for the fact that more units are active than at training time.\n",
    "\n",
    "This technique may seem strange and arbitrary. Why would this help reduce overfitting? Randomly moving a different subset of neurons on each example would prevent \"conspiracies\" and thus reduce overfitting. The core idea is that introducing noise in the output values of a layer can break up happenstance patterns that aren't significant (the \"conspiracies\"), which the model will start memorizing if no noise is present.\n",
    "\n",
    "In Keras, we just introduce dropout layer\n",
    "\n",
    "model = Keras.Sequential([layers.Dense(...),\n",
    "                          layers.Dropout(0.5),\n",
    "                          layers.Dense(...),\n",
    "                          layers.Dropout(0.5),...])\n",
    "                          \n",
    "To recap, these are the most common ways to maximize generalization and prevent overfitting in neural networks:\n",
    "\n",
    "1. Get more training data, or better training data\n",
    "2. Develop better features\n",
    "3. Reduce the capacity of the model\n",
    "4. Add weight regularization (for smaller models)\n",
    "5. Add dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85c7504",
   "metadata": {},
   "source": [
    "Summary of general workflow:\n",
    "\n",
    "Scale up: Develop a model that overfits\n",
    "\n",
    "Once we have statistical power, the question becomes: is your model sufficiently powerful? Does it have enough layers and parameters to properly model the problem at hand? The ideal model is one that stands right at the border between underfitting and overfitting, between undercapacity and overcapacity. To figure out how big a model you will need, you must develop a model that overfits, this is easily done by:\n",
    "\n",
    "1. Add layers\n",
    "2. Make the layers bigger\n",
    "3. Train for more epochs\n",
    "\n",
    "When you see the model's performance on the validation data begins to degrade, you have achieved overfitting.\n",
    "\n",
    "\n",
    "\n",
    "Regularize and tune the model\n",
    "\n",
    "The next task is to maximize generalization performance. Need to repeatedly modify the model, train it, evaluate on the validation data (not the test data at this point), modify it again...until the model is as good as it can get. A few things to try\n",
    "\n",
    "1. Try different architectures; add or remove layers\n",
    "2. Add dropout\n",
    "3. If your model is small, add L1 or L2 regularization\n",
    "4. Try different hyperparameters (such as the number of units per layer or the learning rate of the optimizer) to find the optimal configuration\n",
    "5. Optionally, iterate on data curation or feature engineering: collect and annotate more data, develop better features, or remove features that don't seem to be informative\n",
    "\n",
    "Use the automated hyperparameter tuning software, such as \"KerasTuner.\"\n",
    "\n",
    "Warning: every time you use feedback from your validation process to tune your model, you leak information about the validation process into the model. Repeated just a few times would not be harmful. But if we do it systematically over many iterations, it will eventually cause your model to overfit to the validation process (even though no model is directly trained on any of the validation data). This makes the evaluation process less reliable.\n",
    "\n",
    "Then we will try last time on the test data. If it turns out the performance is worse than the measured on the validation data, this may mean\n",
    "1. Your validation procedure wasn't reliable after all\n",
    "2. You began overfitting to the validation data while tuning the parameters of the model\n",
    "In this case, we may switch to a more reliable evaluation protocol (such as iterated K-fold validation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb760657",
   "metadata": {},
   "source": [
    "To do/Check:\n",
    "\n",
    "Better Data.\n",
    "\n",
    "Resolve the validation loss/no overfitting problem. I will assume that we fall into case 3 above and I will try to use KerasTuner to add layers/more units.\n",
    "\n",
    "Generalization (EarlyStopping, dropout etc.)\n",
    "\n",
    "Hyperparameter tuning-->use KerasTuner!\n",
    "\n",
    "GPU TensorFlow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c04215",
   "metadata": {},
   "source": [
    "### Single Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414f9817",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\") \n",
    "# to restart the kernel, prevent from reusing any trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17a4e77",
   "metadata": {},
   "source": [
    "Physical parameter of data distributes as $L=1, L<51, L+=0.005$.\n",
    "\n",
    "10000 total data sets, with k_max=50.\n",
    "\n",
    "80% for training, 10% validation, 10% test.\n",
    "\n",
    "Data may not be very homogeneous (a point to improve in preparing data). But I don't think this should be a major problem as the DL model should be able to overcome this. In fact, we should use non-homogeneous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "776a158f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct Entropy</th>\n",
       "      <th>Approx Entropy</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.767528</td>\n",
       "      <td>0.749302</td>\n",
       "      <td>0.437659</td>\n",
       "      <td>0.117349</td>\n",
       "      <td>0.051328</td>\n",
       "      <td>0.029216</td>\n",
       "      <td>0.019315</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.008396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.769191</td>\n",
       "      <td>0.750895</td>\n",
       "      <td>0.438359</td>\n",
       "      <td>0.117652</td>\n",
       "      <td>0.051479</td>\n",
       "      <td>0.029303</td>\n",
       "      <td>0.019372</td>\n",
       "      <td>0.013975</td>\n",
       "      <td>0.010648</td>\n",
       "      <td>0.008421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.000312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.770845</td>\n",
       "      <td>0.752481</td>\n",
       "      <td>0.439056</td>\n",
       "      <td>0.117954</td>\n",
       "      <td>0.051629</td>\n",
       "      <td>0.029390</td>\n",
       "      <td>0.019429</td>\n",
       "      <td>0.014016</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.772491</td>\n",
       "      <td>0.754058</td>\n",
       "      <td>0.439748</td>\n",
       "      <td>0.118253</td>\n",
       "      <td>0.051779</td>\n",
       "      <td>0.029477</td>\n",
       "      <td>0.019486</td>\n",
       "      <td>0.014057</td>\n",
       "      <td>0.010711</td>\n",
       "      <td>0.008471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.774129</td>\n",
       "      <td>0.755627</td>\n",
       "      <td>0.440436</td>\n",
       "      <td>0.118552</td>\n",
       "      <td>0.051928</td>\n",
       "      <td>0.029563</td>\n",
       "      <td>0.019543</td>\n",
       "      <td>0.014098</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.008496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2.077970</td>\n",
       "      <td>1.939087</td>\n",
       "      <td>0.789544</td>\n",
       "      <td>0.320856</td>\n",
       "      <td>0.178727</td>\n",
       "      <td>0.114865</td>\n",
       "      <td>0.080510</td>\n",
       "      <td>0.059902</td>\n",
       "      <td>0.046567</td>\n",
       "      <td>0.037433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002643</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.001906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2.078010</td>\n",
       "      <td>1.939115</td>\n",
       "      <td>0.789549</td>\n",
       "      <td>0.320859</td>\n",
       "      <td>0.178730</td>\n",
       "      <td>0.114867</td>\n",
       "      <td>0.080512</td>\n",
       "      <td>0.059903</td>\n",
       "      <td>0.046568</td>\n",
       "      <td>0.037433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002643</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.001906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2.078040</td>\n",
       "      <td>1.939142</td>\n",
       "      <td>0.789555</td>\n",
       "      <td>0.320863</td>\n",
       "      <td>0.178733</td>\n",
       "      <td>0.114870</td>\n",
       "      <td>0.080513</td>\n",
       "      <td>0.059904</td>\n",
       "      <td>0.046569</td>\n",
       "      <td>0.037434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002643</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.001906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2.078070</td>\n",
       "      <td>1.939170</td>\n",
       "      <td>0.789560</td>\n",
       "      <td>0.320867</td>\n",
       "      <td>0.178736</td>\n",
       "      <td>0.114872</td>\n",
       "      <td>0.080515</td>\n",
       "      <td>0.059906</td>\n",
       "      <td>0.046570</td>\n",
       "      <td>0.037435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002643</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.001907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2.078100</td>\n",
       "      <td>1.939197</td>\n",
       "      <td>0.789565</td>\n",
       "      <td>0.320871</td>\n",
       "      <td>0.178738</td>\n",
       "      <td>0.114874</td>\n",
       "      <td>0.080517</td>\n",
       "      <td>0.059907</td>\n",
       "      <td>0.046572</td>\n",
       "      <td>0.037436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002643</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.001907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Correct Entropy  Approx Entropy         1         2         3         4  \\\n",
       "0            0.767528        0.749302  0.437659  0.117349  0.051328  0.029216   \n",
       "1            0.769191        0.750895  0.438359  0.117652  0.051479  0.029303   \n",
       "2            0.770845        0.752481  0.439056  0.117954  0.051629  0.029390   \n",
       "3            0.772491        0.754058  0.439748  0.118253  0.051779  0.029477   \n",
       "4            0.774129        0.755627  0.440436  0.118552  0.051928  0.029563   \n",
       "...               ...             ...       ...       ...       ...       ...   \n",
       "9995         2.077970        1.939087  0.789544  0.320856  0.178727  0.114865   \n",
       "9996         2.078010        1.939115  0.789549  0.320859  0.178730  0.114867   \n",
       "9997         2.078040        1.939142  0.789555  0.320863  0.178733  0.114870   \n",
       "9998         2.078070        1.939170  0.789560  0.320867  0.178736  0.114872   \n",
       "9999         2.078100        1.939197  0.789565  0.320871  0.178738  0.114874   \n",
       "\n",
       "             5         6         7         8  ...        41        42  \\\n",
       "0     0.019315  0.013934  0.010616  0.008396  ...  0.000446  0.000427   \n",
       "1     0.019372  0.013975  0.010648  0.008421  ...  0.000448  0.000429   \n",
       "2     0.019429  0.014016  0.010679  0.008446  ...  0.000450  0.000430   \n",
       "3     0.019486  0.014057  0.010711  0.008471  ...  0.000451  0.000432   \n",
       "4     0.019543  0.014098  0.010742  0.008496  ...  0.000453  0.000433   \n",
       "...        ...       ...       ...       ...  ...       ...       ...   \n",
       "9995  0.080510  0.059902  0.046567  0.037433  ...  0.002643  0.002540   \n",
       "9996  0.080512  0.059903  0.046568  0.037433  ...  0.002643  0.002540   \n",
       "9997  0.080513  0.059904  0.046569  0.037434  ...  0.002643  0.002540   \n",
       "9998  0.080515  0.059906  0.046570  0.037435  ...  0.002643  0.002540   \n",
       "9999  0.080517  0.059907  0.046572  0.037436  ...  0.002643  0.002540   \n",
       "\n",
       "            43        44        45        46        47        48        49  \\\n",
       "0     0.000409  0.000392  0.000377  0.000362  0.000348  0.000335  0.000322   \n",
       "1     0.000411  0.000394  0.000378  0.000363  0.000349  0.000336  0.000323   \n",
       "2     0.000412  0.000395  0.000379  0.000364  0.000350  0.000337  0.000325   \n",
       "3     0.000414  0.000397  0.000381  0.000366  0.000351  0.000338  0.000326   \n",
       "4     0.000415  0.000398  0.000382  0.000367  0.000353  0.000339  0.000327   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995  0.002444  0.002353  0.002268  0.002187  0.002111  0.002039  0.001971   \n",
       "9996  0.002444  0.002353  0.002268  0.002187  0.002111  0.002039  0.001971   \n",
       "9997  0.002444  0.002353  0.002268  0.002187  0.002111  0.002039  0.001971   \n",
       "9998  0.002444  0.002353  0.002268  0.002187  0.002111  0.002039  0.001971   \n",
       "9999  0.002444  0.002353  0.002268  0.002187  0.002111  0.002039  0.001971   \n",
       "\n",
       "            50  \n",
       "0     0.000311  \n",
       "1     0.000312  \n",
       "2     0.000313  \n",
       "3     0.000314  \n",
       "4     0.000315  \n",
       "...        ...  \n",
       "9995  0.001906  \n",
       "9996  0.001906  \n",
       "9997  0.001906  \n",
       "9998  0.001907  \n",
       "9999  0.001907  \n",
       "\n",
       "[10000 rows x 52 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#df = pd.read_csv('Data_Single_Interval.csv')\n",
    "#df\n",
    "\n",
    "df = pd.read_csv('Data_Single_Interval_1.csv', encoding='utf-8', encoding_errors='ignore')\n",
    "df\n",
    "\n",
    "# use a different data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da6d97bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zxpet\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.775x0.755)\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmEElEQVR4nO3deXxV1b338c8icyADGclASBhCGASBgCgWAS8govXiy16rVkVrcbpW+vRpa+1gp6fXVuvtQB1oS7m2Kq2KXmvVaivU4gAECBAgCSFgEjKSkJnM6/njHGLAQAKc5OSc832/Xnlx9nDO/i0SvqysvfbexlqLiIh4vmHuLkBERFxDgS4i4iUU6CIiXkKBLiLiJRToIiJewt9dB46JibGpqanuOryIiEfasWPHMWttbG/b3BboqampZGVluevwIiIeyRjz8Zm2achFRMRLKNBFRLyEAl1ExEu4bQy9N+3t7ZSUlNDS0uLuUuQ8BQcHk5ycTEBAgLtLEfE5QyrQS0pKCAsLIzU1FWOMu8uRc2Stpbq6mpKSEtLS0txdjojPGVJDLi0tLURHRyvMPZQxhujoaP2GJeImQyrQAYW5h9P3T8R9htSQi4iIN+ro7KKoppmDlY0UVDYyLTmCz0zo9dqgC6JAP015eTmrV69m+/btBAUFkZqays9//nPS09MH5fjr169nyZIlJCYmfmrbypUr+ec//0lERAQAoaGhfPDBB2f8rNraWp5//nnuu+++AatXRD7R3tnFx9VNHKxoJL+ikYOVDRRUNlJY1URbZ1f3fvcuGKdAH2jWWlasWMHtt9/Ohg0bAMjOzqaioqJfgd7Z2Ymfn98Zl/tj/fr1TJ06tddAB3jssce44YYb+vVZtbW1PPnkk70G+vnUJiIOHZ1dfFzTzMGKBvLKG8mvbKCgopHCY420dzoeGmQMJI8MIT0ujCsmxjI+dgQT4sMYFzucsOCBmQWmQO9h06ZNBAQEcM8993Svu/jiiwFH2H/961/nzTffxBjDt7/9bW688UY2b97M97//fRISEsjOzubJJ588ZXnv3r089NBDbN68mdbWVu6//37uvvtuAH7605/yhz/8gWHDhrFs2TIyMzPJysrilltuISQkhA8//JCQkJA+6/7e975HUVERhYWFFBUVsXr1ar785S/z0EMPcejQIS6++GIWL17M8uXLT6lt586d3HvvvWRlZeHv788TTzzBwoULWb9+Pa+88gqtra0cPnyYm2++mUceeYTvfOc7xMTE8OCDDwLwrW99i/j4eL785S+7/pshMgRYayk5foKDlc7grmggr7yBgqpG2jocPW5jYPTIUCbEjWBhRhzp8SOYEBfGuLjhhAYObsQO2UD//l/2sb+03qWfOTkxnEeunXLG7Tk5OcyaNavXbRs3biQ7O5vdu3dz7NgxZs+ezfz58wHYtm0bOTk5pKWlsXnz5lOW165dS0REBNu3b6e1tZV58+axZMkScnNzefXVV9m6dSuhoaHU1NQQFRXFmjVrePzxx8nMzOy1jq997Wv86Ec/AmDKlCk899xzAOTm5rJp0yYaGhqYOHEi9957L48++ig5OTlkZ2cDfKq2n/3sZwDs3buX3NxclixZQn5+/iltCg0NZfbs2SxfvpwvfvGLXH/99Tz44IN0dXWxYcMGtm3bdu7fCJEh6HhTG7nlDeSV15NX0UBueQP55Q00tXV275MYEcyE+DAunxBDenwY6fEjGB83YtCD+0yGRhUeYMuWLdx00034+fkRHx/PFVdcwfbt2wkPD2fOnDmnzLvuufz222+zZ88eXnrpJQDq6uo4ePAgf//737njjjsIDQ0FICoqql91nGnIZfny5QQFBREUFERcXBwVFRW9vr9nbVu2bOGBBx4AICMjgzFjxnQH+uLFi4mOjgbg+uuvZ8uWLaxevZro6Gh27dpFRUUFM2bM6N5HxFO0dXRxqKqR3PJ6cssaOOAM8Yr61u59IkMDmBgfxg2zkkkfFUbGqDAmxIcRPkBDJa4yZAP9bD3pgTJlypTu4D3d2R6mPXz48DMuW2v51a9+xdKlS0/Z56233nLpFL+goKDu135+fnR0dPRZ69nadHptJ5fvuusu1q9fT3l5OXfeeeeFlCwy4KoaWjlQVk9ueT0Hyho4UFbPoapPxrkD/YYxPm4E88bHkDEqjImjwskYFUZcWJBHTsEdsoHuDosWLeLhhx/mN7/5DV/60pcA2L59O83NzcyfP59nnnmG22+/nZqaGt577z0ee+wxcnNzz/qZS5cu5amnnmLRokUEBASQn59PUlISS5Ys4Qc/+AE333zzKUMuYWFhNDQ0uKQ9fX3W/Pnzee6551i0aBH5+fkUFRUxceJEdu7cyTvvvENNTQ0hISG8+uqrrFu3DoAVK1bw3e9+l/b2dp5//nmX1Clyobq6LEeqm9hXWu/8quNAWQPHGj/pdY8KDyYjIYyFGXFkjApjUkI4aTHDCfAbcpfjnDcFeg/GGF555RVWr17No48+SnBwcPe0xfnz5/Phhx8yffp0jDH89Kc/ZdSoUX0G+l133cWRI0eYOXMm1lpiY2N59dVXueqqq8jOziYzM5PAwECuvvpqfvzjH7Ny5UruueeeM54U7TmGDpx1DDs6Opp58+YxdepUli1bxvLly0/Zft9993HPPfdw0UUX4e/vz/r167t7+pdffjm33norBQUF3Hzzzd1j+oGBgSxcuJDIyEjNkhG3aOvo4mBlA/uOOoJ7X2k9B8rqu8e6A/wME+LCuCI9lsmJ4UxKCGPSqHBGDg90c+UDz5zt1+6BlJmZaU9/wMWBAweYNGmSW+qRT6xfv56srCzWrFnzqW1dXV3MnDmTF198kQkTJvT6fn0fxVWaWjs4UPZJr3tfaT35FQ3dQyahgX5MSghnSmI4UxMjmJwYzoT4EQT5e29nwxizw1rb66yJPnvoxpjRwLPAKKALWGut/cVp+xjgF8DVQDOw0lq780ILl6Fl//79XHPNNaxYseKMYS5yvmqb29h7tO6UYZPDx5o42eeMGh7IlMRw7rw8jSmJEUxJDCc1ejh+wzxvrHug9GfIpQP4qrV2pzEmDNhhjHnHWru/xz7LgAnOr0uAp5x/igdauXIlK1eu/NT6yZMnU1hYOPgFidepb2kn52gde0rq2FNSy56SOkqOn+jenhQZwuTEcD47PbE7vBMigj3yROVg6jPQrbVlQJnzdYMx5gCQBPQM9OuAZ61j/OYjY0ykMSbB+d5zYq3VN82DuWsIT4aulvZO9pXWdwf37pJaCquaurenRIUyPTmSL8wdw1RnePvCePdAOKeTosaYVGAGsPW0TUlAcY/lEue6UwLdGLMKWAWQkpLyqc8PDg6murpat9D1UCfvhx4cHOzuUsRN2ju7yCtv6O557y6pI7+igc4ux3/0cWFBTEuOZMXFSUwbHcm0pAiFtwv1O9CNMSOAl4HV1trTL+HsLX0/1VWz1q4F1oLjpOjp25OTkykpKaGqqqq/ZckQc/KJReL9rLUU15xgV/FxsotryS6uZV9pffcl8REhAUxLjuDKjHFMS45gWnIkoyL0n/1A6legG2MCcIT5c9bajb3sUgKM7rGcDJSeazEBAQF60o3IENXQ0s6ekjp2FTkCfFdRLdVNbQAEBwzjoqQIbps7hmmjI5meHEFKVKh+0x5k/ZnlYoDfAQestU+cYbfXgP80xmzAcTK07nzGz0VkaLDWcqiqiZ1Fx9lVdJydH9eSX9nQPeNkXOxwFmbEcfHoSGakRDIxPgx/L7pAx1P1p4c+D7gV2GuMyXauexhIAbDWPg28gWPKYgGOaYt3uLxSERkwzW0d7C6uY2fRcXZ8fJydRcepbW4HIDzYnxkpI1l20ShmpoxkenIkEaFD+54mvqo/s1y20PsYec99LHC/q4oSkYFVd6KdrCM1bDtcw9bDNeQcraPDeeJyQtwIlk4exawxI5k5JpKxMSMYprneHkGX/ov4gGONrWx3hvfWwzXkltdjrePmVNNHR7Bq/lhmp0YxIyWSyFDNOvFUCnQRL1RWd6K79721sJpDznnfwQHDmDVmJKuvTGdOmiPAgwO89zJ5X6NAF/Fw1lqKaprZevjkEEo1xTWOqy7DgvzJTB3JDbNGc8nYKKYmRhDor5OX3kqBLuJhrLUUVDZ2D59sO1zd/XCGkaEBzEmL4o7L0piTFsWkhHDd68SHKNBFhrjOLsuBsvru3vf2I8epcc7/jg8P4pK0aOakRXFJWhTjYnUC05cp0EWGGGsthceaeL/gGO8XHOOjwhrqTjimEKZEhbIoI647wHXxjvSkQBcZAiobWvigoJotzhAvq2sBHHcdXDolnsvGxTAnLYrEyJA+Pkl8mQJdxA3aOrrIOlLDu7mV/OvgMfIqHI8KjAwNYN64GOaNj2He+GjGRA/v45NEPqFAFxkkVQ2tbMqrZJMzxBtbOwj0G8actChWzEzi8vExTE4I1xi4nDcFusgA6eqy5JTW8W6uI8R3l9QBjhOZ10xLYGFGHJePj2F4kP4ZimvoJ0nEhRpa2tly8JgjxPOqONbYijFw8ehIvro4nYUZcUxJDNeJTBkQCnSRC3ByRsqm3Ereza1k+5Ea2jst4cH+zE+PZVFGHFekxxI9IsjdpYoPUKCLnKPWjk62FtY4e+GVfFzdDEB6/AjuvDyNRRPjmDVmpG4nK4NOgS7SD+V1LWzKc/TC3y84RnNbJ0H+w7hsXDR3XZ7GgolxjI4KdXeZ4uMU6CK96Oyy7C6pZVNuJf84UMn+MsdTF5MiQ7h+ZhKLMuK4dGwMIYG6sZUMHQp0EaeW9k4251Xx9r5yNudXUdPUht8ww6yUkXzjqgwWZsQyMT5MJzRlyFKgi09r6+hiS0EVr+8u4+39FTS2dhAZGsCC9FgWOk9o6v7g4ikU6OJzOjq7+LCwmtd3l/HWvnLqTrQTHuzP8osSuGZ6ApeOjdYJTfFICnTxCZ1dlu1Hanh9Tylv7i2nuqmNEUH+LJ4cz7XTE7h8fKzuEy4eT4EuXstay86iWl7fU8pf95RR2dBKcMAwrpwUz7XTElkwMVZP6xGvokAXr2KtJedoPa/vKeX1PWUcrT1BoP8wFqTHcs30RK7MiNOl9uK1+vzJNsasA64BKq21U3vZHgH8EUhxft7j1trfu7pQkbPJK2/gL7tLeX1PKUeqm/EfZvjMhBj+z+J0Fk+JJzw4wN0ligy4/nRV1gNrgGfPsP1+YL+19lpjTCyQZ4x5zlrb5qIaRXp1tPYEL+8o4S+7SzlY2cgwA5eNi+GeK8axdMooRg7X7BTxLX0GurX2PWNM6tl2AcKMY3LuCKAG6HBNeSKnauvo4u8HKtiwvZh/HazCWpiTFsUPr5vCVVMTiA3TPVPEd7liMHEN8BpQCoQBN1pru3rb0RizClgFkJKS4oJDi684WNHAn7YXs3HXUWqa2kiMCOaBRRP43KxkXXIv4uSKQF8KZAOLgHHAO8aYf1lr60/f0Vq7FlgLkJmZaV1wbPFiTa0d/HVPGRu2F7GzqJYAP8PiyfH8R+ZoPjMhVk+zFzmNKwL9DuBRa60FCowxh4EMYJsLPlt8jLWWXcW1/Hl7MX/ZXUpTWyfj40bw7eWTWDEjSbehFTkLVwR6EXAl8C9jTDwwESh0weeKD6lpamPjzhL+nFVMfkUjIQF+XDs9gRtnj2ZmykjdP0WkH/ozbfEFYAEQY4wpAR4BAgCstU8DPwTWG2P2Agb4hrX22IBVLF7DWssHh6p5flsRb+8rp73TcvHoSB69/iKumZ7ICM0XFzkn/ZnlclMf20uBJS6rSLxeS3snr+w6yu/fP0x+RSORoQHcOjeVG2ePZuKoMHeXJ+Kx1AWSQVNe18KzHx7hhW1FHG9uZ3JCOI9/bjrXTEvQJfgiLqBAlwG3q+g4v3//CG/sLaPLWhZPjufOeWnMSYvS2LiICynQZUC0d3bxVk45694/zK6iWsKC/Fl5WSq3X5aqeeMiA0SBLi51vKmNF7YX8ewHH1Ne30JqdCjfu3YyN2SO1klOkQGmf2HiEmV1J3jmn4Vs2F5ES3sX88ZH8/9WTGXhxDiG6QIgkUGhQJcLUlTdzFP/LOClHSVYC/8+I4m7PpNGxqhwd5cm4nMU6HJeCiobeHLTIf53dyl+xnDj7NHcPX+cxsdF3EiBLudkX2kdv95UwJs55QT7+3HHZal8af5Y4sOD3V2aiM9ToEu/7Cw6zpp3C3g3t5KwIH/uWzCOO+el6d4qIkOIAl3Oal9pHY//LY9NeVWMDA3gq4vTue2yVCJC9AQgkaFGgS69OnKsiSfeyee13aWEB/vzjasyuO3SMXoep8gQpn+dcorK+hZ++e5BNmwrxt/PcN+Ccdw9fxwRoeqRiwx1CnQBoK65naffO8Tv3z9MR6flpjkpPLBoPHE62SniMRToPq6to4v1HxxmzbsFNLR2cN30RL6yOJ0x0cPdXZqInCMFuo+y1vKPA5X86K/7OVLdzMKJsXz9qgwmJeiCIBFPpUD3QfkVDfzw9f386+AxxseN4H/unMMV6bHuLktELpAC3Yccb2rjv/+ez3Nbixge6Mcj107mC3PHEOA3zN2liYgLKNB9QFeX5bltRTz+tzwaWtq55ZIxfGVxOlHDA91dmoi4kALdy+0vrefhV/aSXVzLpWOjeeSzk3XjLBEvpUD3Us1tHfz87wf53ZbDRIYE8MR/TGfFjCQ9IUjEiynQvdDf91fwyGv7OFp7gs/PHs1DyzKIDNXwioi36zPQjTHrgGuASmvt1DPsswD4ORAAHLPWXuG6EqW/qhtb+e5r+/jrnjLS40fw4j2XMjs1yt1licgg6U8PfT2wBni2t43GmEjgSeAqa22RMSbOZdVJv72xt4zvvJpDfUs7X12czt1XjCPQX7NXRHxJn4FurX3PGJN6ll1uBjZaa4uc+1e6qDbph5698ouSInj+c3OZOCrM3WWJiBu4Ygw9HQgwxmwGwoBfWGvP1JtfBawCSElJccGhfdtbOeV865W91Le087WlE7l7/lj8NadcxGe5ItD9gVnAlUAI8KEx5iNrbf7pO1pr1wJrATIzM60Lju2Tmts6+MFf9rNhezFTk8LVKxcRwDWBXoLjRGgT0GSMeQ+YDnwq0OXC7SmpZfWGbA5XN3HfgnGs/rd0jZWLCOCaQP9fYI0xxh8IBC4B/tsFnys9dHVZnnmvkJ+9nUdsWBAvfGkuc8dGu7ssERlC+jNt8QVgARBjjCkBHsExPRFr7dPW2gPGmLeAPUAX8Ftrbc7Alex7apra+MqfsvlnfhXLL0rgxysu0gMnRORT+jPL5aZ+7PMY8JhLKpJTZB2p4YEXdlHd2MaP/n0qt1ySoqs9RaRXulJ0iLLW8rsth/mvN3NJigxh432XMTUpwt1licgQpkAfglraO/nWKzm8vLOEpVPieexz0wkP1hCLiJydAn2Iqaxv4e4/7mBXUS1f+bd0Hlg0nmHDNMQiIn1ToA8he0pqWfXsDupOtPPULTNZdlGCu0sSEQ+iQB8iXttdytde3E3MiCBevvcyJifqnuUicm4U6G7W1WX52Tt5/HrTIeakRvHkF2YSMyLI3WWJiAdSoLtRS3snX/lTNm/mlPP52aP5wXVTddWniJw3BbqbNLS0s+rZHXxYWM23l0/ii5enaX65iFwQBbobVDW0svL328grb+C/b5zOihnJ7i5JRLyAAn2QFdc0c+vvtlJe38Jvbs9k4UQ9D0REXEOBPogOlNVz27pttHV08dxdc5k1ZqS7SxIRL6JAHyTZxbXc9ruthAb68+I9l5Ier/uXi4hrKdAHQXZxLbf+bisjQwN5/kuXkDwy1N0liYgXUqAPsJ5h/sKquSRFhri7JBHxUpr0PIAU5iIymBToAyTnaJ3CXEQGlQJ9ABRUNnLbum2EBwcozEVk0CjQXazkuGOe+TBj+ONdlyjMRWTQKNBdqLa5jdvXbaOxtYNn75xDWsxwd5ckIj5Ege4iLe2drHp2B8U1J/jtbZm6/a2IDDpNW3SBri7LV1/czbYjNfzyphlcMjba3SWJiA/qs4dujFlnjKk0xuT0sd9sY0ynMeYG15XnGX7yVi5/3VPGN5dl8Nnpie4uR0R8VH+GXNYDV51tB2OMH/AT4G8uqMmjbNxZwjPvFfKFuSmsmj/W3eWIiA/rM9Ctte8BNX3s9gDwMlDpiqI8Rc7ROr65cS+XpEXxyLVTdD9zEXGrCz4paoxJAlYAT194OZ6jurGVu/+wg+jhgfz6lpkE+On8soi4lytS6OfAN6y1nX3taIxZZYzJMsZkVVVVueDQ7tHe2cX9z+/kWGMrz9yaqWeAisiQ4IpZLpnABudwQwxwtTGmw1r76uk7WmvXAmsBMjMzrQuO7RY/fuMAHxXW8MR/TOei5Ah3lyMiArgg0K21aSdfG2PWA6/3Fube4i+7S/n9+0e4c14a18/Uo+NEZOjoM9CNMS8AC4AYY0wJ8AgQAGCt9alx8+KaZh7euJeZKZE8fHWGu8sRETlFn4Furb2pvx9mrV15QdUMYR2dXTy4YRcY+MXnZ+Cvk6AiMsToStF++sU/DrKzqJZf3TSD0VF64pCIDD3qZvbDh4eqWbOpgM/NSuZaXQkqIkOUAr0PDS3t/N8Xd5MaPZzvfXaKu8sRETkjDbn04b/ezKW07gQv3XMZw4P01yUiQ5d66GfxQcExnt9axF2XpzFrzEh3lyMiclYK9DNoau3g6y/vIS1mOF9dMtHd5YiI9EljCGfw2N/yOFp7gj/ffSnBAX7uLkdEpE/qofci52gdz354hJvnpDA7Ncrd5YiI9IsC/TRdXZZvv5rDyNBAvr5UV4OKiOdQoJ/mT1nFZBfX8vDVk4gIDXB3OSIi/aZA76GuuZ2fvJXLnNQorp+Z5O5yRETOiQK9h1/84yD1J9r5/nV6+pCIeB4FulNhVSPPfniEG2ePZlJCuLvLERE5Zwp0p/96M5cg/2F8ZXG6u0sRETkvCnQg60gN7+yv4L6F44kLC3Z3OSIi50WBDjz+dh4xI4K4c15a3zuLiAxRPh/oHxQc46PCGu5fOI6QQF0RKiKey6cD3VrL42/nkRARzE1zUtxdjojIBfHpQN+cV8XOoloeWDRB92sREY/ns4FureWJd/IZHRXC5zKT3V2OiMgF89lA31JwjL1H6/jPheMJ0AOfRcQL+GySrX2vkLiwIP59hi7xFxHv0GegG2PWGWMqjTE5Z9h+izFmj/PrA2PMdNeX6Vo5R+v418Fj3DEvjSB/jZ2LiHfoTw99PXDVWbYfBq6w1k4DfgisdUFdA+o3/ypkeKAfN1+imS0i4j36DHRr7XtAzVm2f2CtPe5c/AgY0mcYi2uaeX1PGTdfkkJEiG6PKyLew9Vj6F8E3jzTRmPMKmNMljEmq6qqysWH7p917x/GAHfoqlAR8TIuC3RjzEIcgf6NM+1jrV1rrc201mbGxsa66tD91tTawUtZJVx9UQKJkSGDfnwRkYHkkodEG2OmAb8Flllrq13xmQPhtd2lNLR2cOulY9xdioiIy11wD90YkwJsBG611uZfeEkDw1rLHz/6mInxYWSOGenuckREXK7PHrox5gVgARBjjCkBHgECAKy1TwPfBaKBJ51P+emw1mYOVMHnK7u4ln2l9fxQTyMSES/VZ6Bba2/qY/tdwF0uq2iA/PGjIoYH+ulCIhHxWj5xpWhjawd/3VvKZy9OJCxYUxVFxDv5RKC/sbeMlvYubpg1pKfIi4hcEJ8I9Jd3lJAWM5yZKToZKiLey+sDvbimma2Ha7h+RpJOhoqIV/P6QH9l11EAnQwVEa/n1YFureXVXUe5JC2K0VGh7i5HRGRAeXWg51U0UHisiWunJ7q7FBGRAefVgf7G3nKMgaVTRrm7FBGRAefVgf7m3jLmpEYRGxbk7lJERAac1wZ6QWUDBysbufqiBHeXIiIyKLw20N/cWw7AVVM13CIivsFrA/2NnHIyx4wkPjzY3aWIiAwKrwz04ppmDpTVq3cuIj7FKwN9c77j8XaLMuLcXImIyODxzkDPrSQlKpS0mOHuLkVEZNB4XaC3tHfywaFqFkyM1b1bRMSneF2gbztcw4n2ThZO1HCLiPgWrwv0zXlVBPoPY+7YaHeXIiIyqLwv0PMrmTs2mpBAP3eXIiIyqLwq0MvrWiisauIz42PcXYqIyKDzqkDfergagEvHabhFRHxPn4FujFlnjKk0xuScYbsxxvzSGFNgjNljjJnp+jL758ND1YQH+zMpIdxdJYiIuE1/eujrgavOsn0ZMMH5tQp46sLLOj8fFVYzJy0av2GarigivqfPQLfWvgfUnGWX64BnrcNHQKQxZtBvcVhWd4Ij1c3MHRs12IcWERkSXDGGngQU91guca77FGPMKmNMljEmq6qqygWH/sRHhY7xc01XFBFf5YpA7218w/a2o7V2rbU201qbGRsb64JDf2JrYQ3hwf5M1vi5iPgoVwR6CTC6x3IyUOqCzz0nO4uOM2vMSIZp/FxEfJQrAv014DbnbJe5QJ21tswFn9tv9S3tHKxsZEbKyME8rIjIkOLf1w7GmBeABUCMMaYEeAQIALDWPg28AVwNFADNwB0DVeyZ7Cmuw1qYkRI52IcWERky+gx0a+1NfWy3wP0uq+g8ZBcfB2BacqQ7yxARcSuvuFJ0V1Et4+NGEBES4O5SRETcxuMD3VrLruJaZoyOdHcpIiJu5fGBXlTTTE1Tm06IiojP8/hA33u0DoBpyRFurkRExL08PtD3l9YT4GdIjw9zdykiIm7l+YFeVs/4uDAC/T2+KSIiF8TjU3B/ab0u9xcRwcMDvaqhlcqGViYnKtBFRDw60A+U1QOohy4igocH+n4FuohIN88O9NJ6kiJDiAjVFaIiIh4d6PkVDUwcpemKIiLgwYHe2WUpPNbE+LgR7i5FRGRI8NhAP3r8BG0dXYyLHe7uUkREhgSPDfSCqgYA9dBFRJw8N9ArGwEYF6tAFxEBDw/0mBGBRIYGursUEZEhwWMD/VBVk3rnIiI9eGSgW2spqGxknMbPRUS6eWSg1zS1UXeiXT10EZEePDLQP65pBiA1OtTNlYiIDB39CnRjzFXGmDxjTIEx5qFetkcYY/5ijNltjNlnjLnD9aV+otgZ6GMU6CIi3foMdGOMH/BrYBkwGbjJGDP5tN3uB/Zba6cDC4CfGWMGbPpJUbUj0JNHKtBFRE7qTw99DlBgrS201rYBG4DrTtvHAmHGGAOMAGqADpdW2kNRTTPx4UEEB/gN1CFERDxOfwI9CSjusVziXNfTGmASUArsBR601nad/kHGmFXGmCxjTFZVVdV5luwYQ0+JUu9cRKSn/gS66WWdPW15KZANJAIXA2uMMZ+6Sbm1dq21NtNamxkbG3uOpX6iuKaZ0Qp0EZFT9CfQS4DRPZaTcfTEe7oD2GgdCoDDQIZrSjxVS3sn5fUt6qGLiJymP4G+HZhgjElznuj8PPDaafsUAVcCGGPigYlAoSsLPelo7QmsRYEuInIa/752sNZ2GGP+E/gb4Aess9buM8bc49z+NPBDYL0xZi+OIZpvWGuPDUTBRZqyKCLSqz4DHcBa+wbwxmnrnu7xuhRY4trSehcW5M+SyfGMidZ90EVEeupXoA8lmalRZKZGubsMEZEhxyMv/RcRkU9ToIuIeAkFuoiIl1Cgi4h4CQW6iIiXUKCLiHgJBbqIiJdQoIuIeAlj7ek3ThykAxtTBXx8nm+PAQbk1gJDmNrsG9Rm33AhbR5jre31drVuC/QLYYzJstZmuruOwaQ2+wa12TcMVJs15CIi4iUU6CIiXsJTA32tuwtwA7XZN6jNvmFA2uyRY+giIvJpntpDFxGR0yjQRUS8hMcFujHmKmNMnjGmwBjzkLvrOV/GmNHGmE3GmAPGmH3GmAed66OMMe8YYw46/xzZ4z3fdLY7zxiztMf6WcaYvc5tvzTGGHe0qb+MMX7GmF3GmNedy17dZmNMpDHmJWNMrvP7fakPtPkrzp/rHGPMC8aYYG9rszFmnTGm0hiT02Ody9pojAkyxvzJuX6rMSa1z6KstR7zheOZpoeAsUAgsBuY7O66zrMtCcBM5+swIB+YDPwUeMi5/iHgJ87Xk53tDQLSnH8Pfs5t24BLcTzP9U1gmbvb10fb/w/wPPC6c9mr2wz8D3CX83UgEOnNbQaSgMNAiHP5z8BKb2szMB+YCeT0WOeyNgL3AU87X38e+FOfNbn7L+Uc/wIvBf7WY/mbwDfdXZeL2va/wGIgD0hwrksA8nprK46Hdl/q3Ce3x/qbgGfc3Z6ztDMZ+AewiE8C3WvbDIQ7w82ctt6b25wEFANROB5z+TqOZw57XZuB1NMC3WVtPLmP87U/jitLzdnq8bQhl5M/KCeVONd5NOevUjOArUC8tbYMwPlnnHO3M7U9yfn69PVD1c+BrwNdPdZ5c5vHAlXA753DTL81xgzHi9tsrT0KPA4UAWVAnbX2bby4zT24so3d77HWdgB1QPTZDu5pgd7b+JlHz7s0xowAXgZWW2vrz7ZrL+vsWdYPOcaYa4BKa+2O/r6ll3Ue1WYcPauZwFPW2hlAE45fxc/E49vsHDe+DsfQQiIw3BjzhbO9pZd1HtXmfjifNp5z+z0t0EuA0T2Wk4FSN9VywYwxATjC/Dlr7Ubn6gpjTIJzewJQ6Vx/praXOF+fvn4omgd81hhzBNgALDLG/BHvbnMJUGKt3epcfglHwHtzm/8NOGytrbLWtgMbgcvw7jaf5Mo2dr/HGOMPRAA1Zzu4pwX6dmCCMSbNGBOI40TBa26u6bw4z2T/DjhgrX2ix6bXgNudr2/HMbZ+cv3nnWe+04AJwDbnr3UNxpi5zs+8rcd7hhRr7TettcnW2lQc37t3rbVfwLvbXA4UG2MmOlddCezHi9uMY6hlrjEm1FnrlcABvLvNJ7myjT0/6wYc/17O/huKu08qnMdJiKtxzAg5BHzL3fVcQDsux/Hr0x4g2/l1NY4xsn8AB51/RvV4z7ec7c6jx9l+IBPIcW5bQx8nTobCF7CAT06KenWbgYuBLOf3+lVgpA+0+ftArrPeP+CY3eFVbQZewHGOoB1Hb/qLrmwjEAy8CBTgmAkztq+adOm/iIiX8LQhFxEROQMFuoiIl1Cgi4h4CQW6iIiXUKCLiHgJBbqIiJdQoIuIeIn/D4XQ6gM0ext6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we should check the data\n",
    "# If there are problems with data (e.g. extreme values, weired distribution), use Scaler in the next block\n",
    "\n",
    "print(sns.distplot(df['Correct Entropy']))\n",
    "# Safe to ignore warnings\n",
    "\n",
    "print(df.plot(y='Correct Entropy', use_index=True))\n",
    "\n",
    "print(df.reset_index().plot.scatter(x='index',y='Correct Entropy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08b16545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#scaler = MinMaxScaler()\n",
    "# this will fit all data points to 0~1\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "# this will fit data points to be mean=0, variance=1\n",
    "\n",
    "#scaler.fit(X_train)\n",
    "#X_train = scaler.transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce47b4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.437659</td>\n",
       "      <td>0.117349</td>\n",
       "      <td>0.051328</td>\n",
       "      <td>0.029216</td>\n",
       "      <td>0.019315</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.008396</td>\n",
       "      <td>0.006825</td>\n",
       "      <td>0.005668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.438359</td>\n",
       "      <td>0.117652</td>\n",
       "      <td>0.051479</td>\n",
       "      <td>0.029303</td>\n",
       "      <td>0.019372</td>\n",
       "      <td>0.013975</td>\n",
       "      <td>0.010648</td>\n",
       "      <td>0.008421</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>0.005685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.000312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.439056</td>\n",
       "      <td>0.117954</td>\n",
       "      <td>0.051629</td>\n",
       "      <td>0.029390</td>\n",
       "      <td>0.019429</td>\n",
       "      <td>0.014016</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>0.006867</td>\n",
       "      <td>0.005702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.439748</td>\n",
       "      <td>0.118253</td>\n",
       "      <td>0.051779</td>\n",
       "      <td>0.029477</td>\n",
       "      <td>0.019486</td>\n",
       "      <td>0.014057</td>\n",
       "      <td>0.010711</td>\n",
       "      <td>0.008471</td>\n",
       "      <td>0.006887</td>\n",
       "      <td>0.005720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.440436</td>\n",
       "      <td>0.118552</td>\n",
       "      <td>0.051928</td>\n",
       "      <td>0.029563</td>\n",
       "      <td>0.019543</td>\n",
       "      <td>0.014098</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>0.008496</td>\n",
       "      <td>0.006907</td>\n",
       "      <td>0.005737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0  0.437659  0.117349  0.051328  0.029216  0.019315  0.013934  0.010616   \n",
       "1  0.438359  0.117652  0.051479  0.029303  0.019372  0.013975  0.010648   \n",
       "2  0.439056  0.117954  0.051629  0.029390  0.019429  0.014016  0.010679   \n",
       "3  0.439748  0.118253  0.051779  0.029477  0.019486  0.014057  0.010711   \n",
       "4  0.440436  0.118552  0.051928  0.029563  0.019543  0.014098  0.010742   \n",
       "\n",
       "          8         9        10  ...        41        42        43        44  \\\n",
       "0  0.008396  0.006825  0.005668  ...  0.000446  0.000427  0.000409  0.000392   \n",
       "1  0.008421  0.006846  0.005685  ...  0.000448  0.000429  0.000411  0.000394   \n",
       "2  0.008446  0.006867  0.005702  ...  0.000450  0.000430  0.000412  0.000395   \n",
       "3  0.008471  0.006887  0.005720  ...  0.000451  0.000432  0.000414  0.000397   \n",
       "4  0.008496  0.006907  0.005737  ...  0.000453  0.000433  0.000415  0.000398   \n",
       "\n",
       "         45        46        47        48        49        50  \n",
       "0  0.000377  0.000362  0.000348  0.000335  0.000322  0.000311  \n",
       "1  0.000378  0.000363  0.000349  0.000336  0.000323  0.000312  \n",
       "2  0.000379  0.000364  0.000350  0.000337  0.000325  0.000313  \n",
       "3  0.000381  0.000366  0.000351  0.000338  0.000326  0.000314  \n",
       "4  0.000382  0.000367  0.000353  0.000339  0.000327  0.000315  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.drop(['Correct Entropy','Approx Entropy'], axis = 1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d05fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 50)\n",
      "(8000, 50)\n",
      "(1000, 50)\n",
      "(1000, 50)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# do the splitting twice for to separate the data points to train-validation-test sets, we do 80-10-10%.\n",
    "\n",
    "X = df1\n",
    "y = df['Correct Entropy']\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.1, random_state = 42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=1.0/9, random_state=42) \n",
    "# 1.0/9 x 0.9 = 0.1\n",
    "\n",
    "print(X_train_full.shape) # this is for later use in KerasTuner by includin training + validation\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e817b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# We don't need to worry about the input dimensions, the layers will automatically infer input shape as the shape of \n",
    "# the first inputs they see.\n",
    "\n",
    "# Write the layers separately such that it is easy to comment out each layer\n",
    "# Note we don't need to worry about input/output sizes that connect each layer, Keras will handle it automatically.\n",
    "\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(1)) \n",
    "# The final layer has only 1 node as we are predicting a single value of correct entropy\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'mse', metrics=[\"mae\"]) \n",
    "#Root Mean Squared Propagation as optimizer and  Mean Squared Error as loss fun\n",
    "\n",
    "\n",
    "# Note we can have customized setup (have to build from scratch):\n",
    "# model.compilte(optimizer = keras.optimizers.RMSprop(learning_rate=1e-4, loss = my_custom_loss, \n",
    "# metrics=[my_custom_metric_1, my_custom_metric_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c65b4a",
   "metadata": {},
   "source": [
    "In below we adopt the KerasTuner approach. Do not run the above block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5551109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
    "    # sample hyperparameter values from hp object. After sampling, these values (such as \"units\" variables here) \n",
    "    # are just regular Python constants.\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(units, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
    "    # different kinds of hyperparameters are available: Int, Float, Boolean, Choice, Fixed\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\"])\n",
    "    return model \n",
    "    # the function returns a compiled model\n",
    "    \n",
    "# note we can also use hp.xxx to tune layers, activation functions etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e11cd5",
   "metadata": {},
   "source": [
    "The next step is to define a \"tuner.\" Schematically, you can think of a tuner as a for loop that will repeatedly\n",
    "\n",
    "1. Pick a set of hyperparameter values\n",
    "2. Call the model-building function with these values to create a model\n",
    "3. Train the model and record its metrics\n",
    "\n",
    "KerasTuner has several built-in tuners available-->RandomSearch, BayesianOptimization, and Hyperband.\n",
    "\n",
    "Let's try BayerianOptimization, a tuner that attempts to make smart predictions for which new hyperparameter values are likely to perform best given the outcomes of previous choices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "754ec51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.BayesianOptimization(build_model, # specify the model-building fun (or hypermodel instance)\n",
    "                                objective=\"val_loss\", \n",
    "                                # specify the metric that the tuner will seek to optimize, always specify validation metrics,\n",
    "                                # since the goal of the search process is to find models that generalize\n",
    "                                max_trials=10, # max number of different model configurations (\"trials\")\n",
    "                                executions_per_trial=2, \n",
    "                                # To reduce metrics variance, you can train the same model multiple times and \n",
    "                                # average the results. This is how many training rounds (executions) to run for each trial. \n",
    "                                directory=\"singleintervaltest\", # where to store search logs\n",
    "                                overwrite=True, \n",
    "                                #whether to overwrite data in directory to start a new search. \n",
    "                                # Set this to True if you have modified the model-building fun, or to False to resume \n",
    "                                # a previously started search with the same model-building fun.\n",
    "                                ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11d87f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 2\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 64, 'step': 16, 'sampling': None}\n",
      "optimizer (Choice)\n",
      "{'default': 'rmsprop', 'conditions': [], 'values': ['rmsprop', 'adam'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "# display an overview of the search space via search_space_summary()\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7739e789",
   "metadata": {},
   "source": [
    "Finally we launch the search. Remember to pass validation data, and make sure not to use the test set as validation data. Otherwise we'd quickly start overfitting to the test data, and we wouldn't be able to trust the test metrics anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aafdd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 02s]\n",
      "val_loss: 0.0001466006797272712\n",
      "\n",
      "Best val_loss So Far: 0.00013724878954235464\n",
      "Total elapsed time: 00h 00m 25s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5),] \n",
    "# patience=x: interrupts training when monitor has stopped improving for x epochs\n",
    "\n",
    "tuner.search(x = X_train, y = y_train, batch_size=128, epochs=10, validation_data=(X_val, y_val), callbacks=callbacks, verbose=2,)\n",
    "# this takes the same arguments as fit() (it simply passes them down to fit() for each new model)\n",
    "\n",
    "# here use a large number of epochs (you don't know in advance how many epochs each model will need), and use an EarlyStopping\n",
    "# callback to stop training when you start overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33bc1ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras_tuner.engine.hyperparameters.HyperParameters at 0x1dd14bf0b50>,\n",
       " <keras_tuner.engine.hyperparameters.HyperParameters at 0x1dd1e851880>,\n",
       " <keras_tuner.engine.hyperparameters.HyperParameters at 0x1dd1e811430>,\n",
       " <keras_tuner.engine.hyperparameters.HyperParameters at 0x1dd1d6f12e0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query the best hyperparameter configurations, can then be used to retrain\n",
    "\n",
    "top_n = 4\n",
    "best_hps = tuner.get_best_hyperparameters(top_n) \n",
    "best_hps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e08f478",
   "metadata": {},
   "source": [
    "When retraining these models, you may want to include the validation data as part of the training data, since you won't be making any further hyperparameter changes, and thus you will no longer be evaluating performance on the validation data. In the example, we'd train these final models on the totality of the original training data, without reserving a validation set.\n",
    "\n",
    "Before we can train on the full training data, there is one last parameter we need to settle: the optimal number of epochs to train for.\n",
    "\n",
    "Typically, you will want to train the new models for longer than you did during the search: using an aggresive \"patience\" value in the EarlyStopping callback saves time during the search, but it may lead to under-fit models. Just use the validation set to find the best epoch:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe7cafc",
   "metadata": {},
   "source": [
    "There is one last parameter we need to settle: the optimal number of epochs to train for. \n",
    "\n",
    "No need to do the following not. The model is already saved at its best performing epoch evaluated on the validation_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da6d7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_epoch(hp):\n",
    "    model = build_model(hp)\n",
    "    callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)] # very high patience\n",
    "    history = model.fit(x = X_train, y = y_train, validation_data=(X_val, y_val), epochs=100, batch_size=128, callbacks=callbacks)\n",
    "    val_loss_per_epoch = history.history[\"val_loss\"]\n",
    "    best_epoch = val_loss_per_epoch.index(min(val_loss_per_epoch)) + 1\n",
    "    print(f\"Best epoch: {best_epoch}\")\n",
    "    return best_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c834259",
   "metadata": {},
   "source": [
    "Finally, train the full dataset (training + validation) for just a bit longer than this epoch count, since you are training on more data; we train for 20% more in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9cca8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_trained_model(hp):\n",
    "    best_epoch = get_best_epoch(hp)\n",
    "    model.fit(X_train_full, y_train_full, batch_size=128, epochs=int(best_epoch*1.2)) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18192a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.6143 - mae: 1.5912 - val_loss: 2.0611 - val_mae: 1.4144\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 756us/step - loss: 1.5907 - mae: 1.2329 - val_loss: 1.0983 - val_mae: 1.0237\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 788us/step - loss: 0.6767 - mae: 0.7813 - val_loss: 0.2991 - val_mae: 0.5167\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 741us/step - loss: 0.1157 - mae: 0.2912 - val_loss: 0.0258 - val_mae: 0.1304\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 772us/step - loss: 0.0244 - mae: 0.1225 - val_loss: 0.0211 - val_mae: 0.1154\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 773us/step - loss: 0.0191 - mae: 0.1074 - val_loss: 0.0155 - val_mae: 0.0956\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 754us/step - loss: 0.0134 - mae: 0.0898 - val_loss: 0.0103 - val_mae: 0.0789\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 757us/step - loss: 0.0084 - mae: 0.0711 - val_loss: 0.0060 - val_mae: 0.0626\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 746us/step - loss: 0.0045 - mae: 0.0518 - val_loss: 0.0027 - val_mae: 0.0416\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 757us/step - loss: 0.0019 - mae: 0.0332 - val_loss: 0.0010 - val_mae: 0.0263\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 772us/step - loss: 6.0082e-04 - mae: 0.0189 - val_loss: 3.7361e-04 - val_mae: 0.0167\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 788us/step - loss: 1.8448e-04 - mae: 0.0106 - val_loss: 2.2025e-04 - val_mae: 0.0135\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 724us/step - loss: 8.3005e-05 - mae: 0.0076 - val_loss: 4.4989e-05 - val_mae: 0.0058\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 772us/step - loss: 5.9370e-05 - mae: 0.0071 - val_loss: 4.0132e-05 - val_mae: 0.0062\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 756us/step - loss: 5.4987e-05 - mae: 0.0072 - val_loss: 5.3324e-05 - val_mae: 0.0071\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 740us/step - loss: 5.3909e-05 - mae: 0.0072 - val_loss: 4.3543e-05 - val_mae: 0.0065\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 756us/step - loss: 5.4290e-05 - mae: 0.0072 - val_loss: 4.4338e-05 - val_mae: 0.0065\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 756us/step - loss: 5.3115e-05 - mae: 0.0072 - val_loss: 4.9844e-05 - val_mae: 0.0070\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 788us/step - loss: 5.3853e-05 - mae: 0.0072 - val_loss: 6.1677e-05 - val_mae: 0.0077\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 773us/step - loss: 5.3517e-05 - mae: 0.0072 - val_loss: 5.1543e-05 - val_mae: 0.0071\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 789us/step - loss: 5.3789e-05 - mae: 0.0072 - val_loss: 4.6224e-05 - val_mae: 0.0067\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 804us/step - loss: 5.4248e-05 - mae: 0.0073 - val_loss: 7.0591e-05 - val_mae: 0.0083\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 820us/step - loss: 5.3653e-05 - mae: 0.0072 - val_loss: 3.5743e-05 - val_mae: 0.0059\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 789us/step - loss: 5.3998e-05 - mae: 0.0072 - val_loss: 4.3930e-05 - val_mae: 0.0065\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 901us/step - loss: 5.2876e-05 - mae: 0.0072 - val_loss: 4.5089e-05 - val_mae: 0.0066\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 949us/step - loss: 5.3687e-05 - mae: 0.0072 - val_loss: 5.8832e-05 - val_mae: 0.0076\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 965us/step - loss: 5.3733e-05 - mae: 0.0072 - val_loss: 6.8407e-05 - val_mae: 0.0082\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 853us/step - loss: 5.3313e-05 - mae: 0.0072 - val_loss: 5.0301e-05 - val_mae: 0.0070\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 804us/step - loss: 5.3488e-05 - mae: 0.0072 - val_loss: 5.5534e-05 - val_mae: 0.0074\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 788us/step - loss: 5.3599e-05 - mae: 0.0072 - val_loss: 6.0432e-05 - val_mae: 0.0077\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 783us/step - loss: 5.3278e-05 - mae: 0.0072 - val_loss: 5.4055e-05 - val_mae: 0.0073\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 772us/step - loss: 5.3982e-05 - mae: 0.0072 - val_loss: 5.1392e-05 - val_mae: 0.0071\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 772us/step - loss: 5.2978e-05 - mae: 0.0072 - val_loss: 4.8264e-05 - val_mae: 0.0069\n",
      "Best epoch: 23\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14604/3091323453.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbest_models\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mhp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbest_hps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_best_trained_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbest_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14604/4230420518.py\u001b[0m in \u001b[0;36mget_best_trained_model\u001b[1;34m(hp)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_best_trained_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mbest_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_best_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_full\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_full\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_epoch\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "best_models = []\n",
    "for hp in best_hps:\n",
    "    model = get_best_trained_model(hp)\n",
    "    model.evaluate(X_test, y_test)\n",
    "    best_models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9738b19",
   "metadata": {},
   "source": [
    "Note that if you are not worried about slightly underperforming, there is a shortcut you can take: just use the tuner to reload the top-performing models with the best weights saved during the hyperparameter search, without retraining new models from scratch:\n",
    "\n",
    "best_models = tuner.get_best_models(top_n)\n",
    "\n",
    "Note that one important issue to think about when doing automatic hyperparameter optimization at scale is validation-set overfitting. Because you are updating hyperparameters based on a signal that is computed using your validation data, you are effectively training them on the validation data, and thus they will quickly overfit to the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2b880c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.sequential.Sequential at 0x1dd1fccbb80>,\n",
       " <keras.engine.sequential.Sequential at 0x1dd1fcd57f0>,\n",
       " <keras.engine.sequential.Sequential at 0x1dd1d6a9a90>,\n",
       " <keras.engine.sequential.Sequential at 0x1dd1fc94220>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models = tuner.get_best_models(top_n)\n",
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9344ea20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 1ms/step - loss: 0.1067 - mae: 0.1557 - val_loss: 0.0054 - val_mae: 0.0680\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 634us/step - loss: 0.0055 - mae: 0.0695 - val_loss: 0.0031 - val_mae: 0.0549\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 649us/step - loss: 0.0048 - mae: 0.0660 - val_loss: 0.0056 - val_mae: 0.0744\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 615us/step - loss: 0.0045 - mae: 0.0648 - val_loss: 0.0018 - val_mae: 0.0407\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 629us/step - loss: 0.0042 - mae: 0.0619 - val_loss: 0.0040 - val_mae: 0.0626\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 613us/step - loss: 0.0040 - mae: 0.0611 - val_loss: 0.0031 - val_mae: 0.0546\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 617us/step - loss: 0.0038 - mae: 0.0593 - val_loss: 0.0025 - val_mae: 0.0495\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 621us/step - loss: 0.0035 - mae: 0.0579 - val_loss: 0.0070 - val_mae: 0.0828\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 633us/step - loss: 0.0034 - mae: 0.0564 - val_loss: 0.0029 - val_mae: 0.0536\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 629us/step - loss: 0.0033 - mae: 0.0554 - val_loss: 0.0031 - val_mae: 0.0553\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 621us/step - loss: 0.0031 - mae: 0.0544 - val_loss: 0.0021 - val_mae: 0.0451\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 628us/step - loss: 0.0030 - mae: 0.0537 - val_loss: 0.0036 - val_mae: 0.0593\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 624us/step - loss: 0.0029 - mae: 0.0521 - val_loss: 0.0017 - val_mae: 0.0400\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 637us/step - loss: 0.0028 - mae: 0.0517 - val_loss: 0.0015 - val_mae: 0.0379\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 631us/step - loss: 0.0027 - mae: 0.0501 - val_loss: 0.0016 - val_mae: 0.0387\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 621us/step - loss: 0.0026 - mae: 0.0489 - val_loss: 0.0049 - val_mae: 0.0697\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 633us/step - loss: 0.0026 - mae: 0.0490 - val_loss: 0.0022 - val_mae: 0.0465\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 622us/step - loss: 0.0025 - mae: 0.0486 - val_loss: 0.0021 - val_mae: 0.0450\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 625us/step - loss: 0.0024 - mae: 0.0477 - val_loss: 0.0022 - val_mae: 0.0466\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 647us/step - loss: 0.0024 - mae: 0.0468 - val_loss: 0.0032 - val_mae: 0.0563\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 617us/step - loss: 0.0023 - mae: 0.0456 - val_loss: 0.0016 - val_mae: 0.0394\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 717us/step - loss: 0.0022 - mae: 0.0455 - val_loss: 0.0015 - val_mae: 0.0379\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 721us/step - loss: 0.0021 - mae: 0.0444 - val_loss: 0.0022 - val_mae: 0.0465\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 699us/step - loss: 0.0020 - mae: 0.0436 - val_loss: 0.0018 - val_mae: 0.0419\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 665us/step - loss: 0.0020 - mae: 0.0437 - val_loss: 3.1401e-04 - val_mae: 0.0170\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 637us/step - loss: 0.0019 - mae: 0.0422 - val_loss: 0.0025 - val_mae: 0.0492\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 625us/step - loss: 0.0019 - mae: 0.0422 - val_loss: 0.0017 - val_mae: 0.0407\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 627us/step - loss: 0.0018 - mae: 0.0413 - val_loss: 0.0023 - val_mae: 0.0474\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 633us/step - loss: 0.0018 - mae: 0.0407 - val_loss: 4.1140e-04 - val_mae: 0.0199\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 631us/step - loss: 0.0017 - mae: 0.0403 - val_loss: 8.2566e-04 - val_mae: 0.0284\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 644us/step - loss: 0.0016 - mae: 0.0393 - val_loss: 0.0011 - val_mae: 0.0334\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 640us/step - loss: 0.0016 - mae: 0.0393 - val_loss: 0.0016 - val_mae: 0.0395\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 660us/step - loss: 0.0016 - mae: 0.0384 - val_loss: 0.0015 - val_mae: 0.0386\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 650us/step - loss: 0.0015 - mae: 0.0380 - val_loss: 6.7873e-04 - val_mae: 0.0257\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 625us/step - loss: 0.0015 - mae: 0.0379 - val_loss: 0.0021 - val_mae: 0.0455\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 641us/step - loss: 0.0015 - mae: 0.0368 - val_loss: 0.0019 - val_mae: 0.0428\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 640us/step - loss: 0.0015 - mae: 0.0369 - val_loss: 0.0019 - val_mae: 0.0432\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 635us/step - loss: 0.0014 - mae: 0.0362 - val_loss: 0.0023 - val_mae: 0.0480\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 645us/step - loss: 0.0014 - mae: 0.0360 - val_loss: 0.0013 - val_mae: 0.0355\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 729us/step - loss: 0.0014 - mae: 0.0355 - val_loss: 0.0013 - val_mae: 0.0355\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 644us/step - loss: 0.0013 - mae: 0.0351 - val_loss: 0.0010 - val_mae: 0.0318\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 634us/step - loss: 0.0013 - mae: 0.0354 - val_loss: 6.2374e-04 - val_mae: 0.0246\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 622us/step - loss: 0.0013 - mae: 0.0346 - val_loss: 0.0011 - val_mae: 0.0322\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 618us/step - loss: 0.0013 - mae: 0.0342 - val_loss: 0.0015 - val_mae: 0.0390\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 655us/step - loss: 0.0012 - mae: 0.0344 - val_loss: 0.0012 - val_mae: 0.0343\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 641us/step - loss: 0.0012 - mae: 0.0337 - val_loss: 0.0017 - val_mae: 0.0408\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 625us/step - loss: 0.0012 - mae: 0.0335 - val_loss: 9.7912e-04 - val_mae: 0.0311\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 625us/step - loss: 0.0012 - mae: 0.0334 - val_loss: 0.0015 - val_mae: 0.0378\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 629us/step - loss: 0.0012 - mae: 0.0332 - val_loss: 0.0013 - val_mae: 0.0354\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 625us/step - loss: 0.0011 - mae: 0.0327 - val_loss: 7.3103e-04 - val_mae: 0.0268\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 693us/step - loss: 0.0011 - mae: 0.0321 - val_loss: 5.2222e-04 - val_mae: 0.0225\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 672us/step - loss: 0.0011 - mae: 0.0319 - val_loss: 9.0349e-04 - val_mae: 0.0298\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 633us/step - loss: 0.0011 - mae: 0.0320 - val_loss: 7.9399e-04 - val_mae: 0.0279\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 626us/step - loss: 0.0011 - mae: 0.0318 - val_loss: 6.8146e-04 - val_mae: 0.0257\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 627us/step - loss: 0.0011 - mae: 0.0313 - val_loss: 8.9792e-04 - val_mae: 0.0297\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 695us/step - loss: 0.0010 - mae: 0.0311 - val_loss: 7.9139e-04 - val_mae: 0.0279\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 681us/step - loss: 0.0010 - mae: 0.0309 - val_loss: 7.0643e-04 - val_mae: 0.0262\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 741us/step - loss: 0.0010 - mae: 0.0306 - val_loss: 6.1189e-04 - val_mae: 0.0244\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 657us/step - loss: 9.7553e-04 - mae: 0.0302 - val_loss: 8.6305e-04 - val_mae: 0.0291\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 629us/step - loss: 9.7038e-04 - mae: 0.0303 - val_loss: 2.8509e-04 - val_mae: 0.0166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 693us/step - loss: 9.5169e-04 - mae: 0.0298 - val_loss: 0.0016 - val_mae: 0.0398\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 686us/step - loss: 9.4528e-04 - mae: 0.0298 - val_loss: 7.8762e-04 - val_mae: 0.0276\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 637us/step - loss: 9.2371e-04 - mae: 0.0292 - val_loss: 0.0015 - val_mae: 0.0387\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 624us/step - loss: 9.1937e-04 - mae: 0.0293 - val_loss: 8.1422e-04 - val_mae: 0.0283\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 654us/step - loss: 9.0590e-04 - mae: 0.0289 - val_loss: 0.0012 - val_mae: 0.0342\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 645us/step - loss: 8.9545e-04 - mae: 0.0290 - val_loss: 0.0010 - val_mae: 0.0315\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 653us/step - loss: 8.8414e-04 - mae: 0.0284 - val_loss: 0.0010 - val_mae: 0.0317\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 639us/step - loss: 8.8204e-04 - mae: 0.0287 - val_loss: 7.9094e-04 - val_mae: 0.0278\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 640us/step - loss: 8.5857e-04 - mae: 0.0284 - val_loss: 0.0012 - val_mae: 0.0347\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 657us/step - loss: 8.6870e-04 - mae: 0.0287 - val_loss: 0.0011 - val_mae: 0.0329\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 641us/step - loss: 8.4559e-04 - mae: 0.0282 - val_loss: 9.5338e-04 - val_mae: 0.0305\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 651us/step - loss: 8.3046e-04 - mae: 0.0276 - val_loss: 4.2978e-04 - val_mae: 0.0204\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 688us/step - loss: 8.3363e-04 - mae: 0.0277 - val_loss: 9.9845e-04 - val_mae: 0.0314\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 641us/step - loss: 8.2639e-04 - mae: 0.0277 - val_loss: 6.8556e-04 - val_mae: 0.0259\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 650us/step - loss: 8.1699e-04 - mae: 0.0272 - val_loss: 0.0010 - val_mae: 0.0315\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 709us/step - loss: 8.0693e-04 - mae: 0.0273 - val_loss: 8.1318e-04 - val_mae: 0.0283\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 697us/step - loss: 8.0034e-04 - mae: 0.0275 - val_loss: 7.8395e-04 - val_mae: 0.0278\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 657us/step - loss: 7.8693e-04 - mae: 0.0269 - val_loss: 3.0460e-04 - val_mae: 0.0170\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 649us/step - loss: 7.7139e-04 - mae: 0.0263 - val_loss: 0.0014 - val_mae: 0.0364\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 667us/step - loss: 7.7442e-04 - mae: 0.0269 - val_loss: 5.3605e-04 - val_mae: 0.0227\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 671us/step - loss: 7.5930e-04 - mae: 0.0266 - val_loss: 0.0011 - val_mae: 0.0331\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 691us/step - loss: 7.6069e-04 - mae: 0.0268 - val_loss: 5.2752e-04 - val_mae: 0.0226\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 681us/step - loss: 7.4495e-04 - mae: 0.0265 - val_loss: 6.0244e-04 - val_mae: 0.0243\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 673us/step - loss: 7.4183e-04 - mae: 0.0263 - val_loss: 7.7387e-04 - val_mae: 0.0277\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 663us/step - loss: 7.3357e-04 - mae: 0.0261 - val_loss: 3.5031e-04 - val_mae: 0.0183\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 659us/step - loss: 7.1867e-04 - mae: 0.0259 - val_loss: 8.1407e-04 - val_mae: 0.0281\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 649us/step - loss: 7.1720e-04 - mae: 0.0261 - val_loss: 0.0012 - val_mae: 0.0341\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 697us/step - loss: 7.0624e-04 - mae: 0.0259 - val_loss: 9.9019e-04 - val_mae: 0.0312\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 649us/step - loss: 7.0280e-04 - mae: 0.0258 - val_loss: 3.3645e-04 - val_mae: 0.0181\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 648us/step - loss: 6.9221e-04 - mae: 0.0255 - val_loss: 4.0421e-04 - val_mae: 0.0198\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 645us/step - loss: 6.8948e-04 - mae: 0.0251 - val_loss: 7.8932e-04 - val_mae: 0.0279\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 643us/step - loss: 6.7362e-04 - mae: 0.0251 - val_loss: 3.7449e-04 - val_mae: 0.0192\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 641us/step - loss: 6.6082e-04 - mae: 0.0245 - val_loss: 0.0014 - val_mae: 0.0368\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 647us/step - loss: 6.6267e-04 - mae: 0.0245 - val_loss: 3.4703e-04 - val_mae: 0.0184\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 642us/step - loss: 6.5215e-04 - mae: 0.0245 - val_loss: 4.3097e-04 - val_mae: 0.0206\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 629us/step - loss: 6.4904e-04 - mae: 0.0247 - val_loss: 3.8884e-04 - val_mae: 0.0194\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 623us/step - loss: 6.3893e-04 - mae: 0.0245 - val_loss: 2.9897e-04 - val_mae: 0.0170\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 637us/step - loss: 6.3244e-04 - mae: 0.0245 - val_loss: 7.5723e-04 - val_mae: 0.0273\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 633us/step - loss: 6.2646e-04 - mae: 0.0239 - val_loss: 0.0012 - val_mae: 0.0343\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 629us/step - loss: 6.1829e-04 - mae: 0.0240 - val_loss: 4.4693e-04 - val_mae: 0.0207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16c9e30e430>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = X_train, y = y_train, epochs = 100, batch_size = 128, validation_data=(X_val, y_val)) \n",
    "\n",
    "# Note we haven't implemented the batch_size.\n",
    "# can set verbose=0 to turn on silent mode\n",
    "# we added validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c31bd388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(50, 64) dtype=float32, numpy=\n",
       " array([[ 0.03175202, -0.19258088, -0.10230084, ...,  0.03178085,\n",
       "          0.00374114,  0.16216423],\n",
       "        [ 0.08935735,  0.11513428, -0.07067291, ..., -0.15793051,\n",
       "         -0.03092427, -0.18097706],\n",
       "        [-0.17963679,  0.1211807 ,  0.2116855 , ...,  0.14778368,\n",
       "          0.08516879, -0.2734936 ],\n",
       "        ...,\n",
       "        [-0.07617106, -0.03173135, -0.0186293 , ..., -0.22614145,\n",
       "          0.18694474, -0.44754222],\n",
       "        [-0.1429913 , -0.0774013 , -0.17576489, ..., -0.07135855,\n",
       "          0.47802478, -0.49890235],\n",
       "        [ 0.16187677, -0.08545806,  0.09846176, ..., -0.1465147 ,\n",
       "          0.284215  , -0.10149994]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([-0.00423915,  0.        ,  0.        , -0.10856755, -0.15155593,\n",
       "         0.        , -0.0866233 , -0.05470463, -0.12247694, -0.01825435,\n",
       "         0.        , -0.004597  ,  0.        ,  0.        , -0.051562  ,\n",
       "        -0.09282228, -0.10507575,  0.        , -0.13525109, -0.10745003,\n",
       "         0.        ,  0.        ,  0.11050338,  0.        ,  0.        ,\n",
       "        -0.11715595,  0.        ,  0.        , -0.09887771, -0.05187657,\n",
       "        -0.15801686, -0.09579616, -0.15648526,  0.        , -0.17230864,\n",
       "         0.        , -0.07641549,  0.        , -0.10367241, -0.11860365,\n",
       "        -0.07628112,  0.        , -0.16048208, -0.1643401 , -0.11880565,\n",
       "         0.        , -0.19942737, -0.03342854, -0.00656256,  0.        ,\n",
       "         0.        , -0.00827035,  0.        , -0.13229948,  0.        ,\n",
       "        -0.07737337,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.12570393,  0.        , -0.15143405,  0.1139069 ], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(64, 64) dtype=float32, numpy=\n",
       " array([[-0.03676537,  0.10983457,  0.12077586, ..., -0.05828792,\n",
       "          0.2121401 ,  0.07746403],\n",
       "        [-0.13772507, -0.07155946,  0.0995345 , ...,  0.12746628,\n",
       "          0.07232724, -0.04556189],\n",
       "        [-0.17755021,  0.17311122,  0.21119617, ...,  0.13095011,\n",
       "         -0.08867429,  0.11156698],\n",
       "        ...,\n",
       "        [ 0.16704752, -0.15833902,  0.03459643, ...,  0.01397444,\n",
       "         -0.12047101, -0.01824427],\n",
       "        [ 0.19658719, -0.17440733, -0.2027214 , ...,  0.07229529,\n",
       "          0.20225818,  0.08553147],\n",
       "        [ 0.06136257, -0.11409922, -0.05732568, ..., -0.05692848,\n",
       "         -0.01146396, -0.06316314]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([-0.0031605 , -0.01229682,  0.        , -0.04285852,  0.01394291,\n",
       "        -0.04169418, -0.00626232, -0.06992368, -0.03642506, -0.04365873,\n",
       "         0.10400429,  0.        , -0.00377024, -0.03177757, -0.00879982,\n",
       "         0.01737985, -0.04860776, -0.00632411,  0.        , -0.09366407,\n",
       "        -0.03466007, -0.08639274,  0.        , -0.02376026,  0.        ,\n",
       "        -0.00801488, -0.0438916 , -0.00316219,  0.07682885, -0.05680554,\n",
       "         0.01636156,  0.02682621, -0.10372261, -0.0402267 , -0.02832472,\n",
       "         0.0164931 , -0.00315846, -0.09861086, -0.05340916, -0.0997084 ,\n",
       "         0.00371243, -0.06010919, -0.01554298, -0.08526514, -0.00631776,\n",
       "        -0.00598473, -0.04417206, -0.10406218, -0.09002455, -0.07624186,\n",
       "        -0.03056579,  0.        ,  0.04661115, -0.01007911, -0.07249435,\n",
       "         0.00667289,  0.        ,  0.0537204 ,  0.        , -0.00320519,\n",
       "        -0.00296218, -0.01133416, -0.00674263, -0.06204069], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/kernel:0' shape=(64, 64) dtype=float32, numpy=\n",
       " array([[-0.04808988, -0.00368558,  0.11515675, ...,  0.16573809,\n",
       "         -0.20950045, -0.08109241],\n",
       "        [ 0.13525994,  0.1338102 ,  0.16090266, ..., -0.0420219 ,\n",
       "         -0.03650341, -0.20019606],\n",
       "        [ 0.00061716,  0.02262616,  0.13098113, ...,  0.11823879,\n",
       "          0.18581097,  0.19138594],\n",
       "        ...,\n",
       "        [ 0.01326963, -0.0262091 , -0.10110341, ..., -0.19558041,\n",
       "         -0.07470647,  0.20794426],\n",
       "        [ 0.14288725,  0.04038294,  0.19778569, ..., -0.0319237 ,\n",
       "          0.19860883, -0.1000651 ],\n",
       "        [ 0.0535933 ,  0.04171146, -0.09240935, ..., -0.147181  ,\n",
       "         -0.264258  , -0.02252806]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([-0.01093746, -0.03730701,  0.        , -0.0668415 , -0.05474654,\n",
       "        -0.00629014, -0.00314162, -0.02911198,  0.11713944, -0.0963738 ,\n",
       "        -0.00180051, -0.04068315, -0.04103411,  0.01064365, -0.00315927,\n",
       "        -0.01739265, -0.0548857 , -0.10529068,  0.01393313,  0.04134306,\n",
       "        -0.00720845, -0.01397044, -0.02601183, -0.03041993, -0.0218348 ,\n",
       "        -0.04080926, -0.00316228, -0.01616368, -0.08036306, -0.04476839,\n",
       "         0.00555946, -0.03384632, -0.01500064, -0.02103233, -0.0361757 ,\n",
       "        -0.00833158,  0.        ,  0.02497491, -0.02765677, -0.06674245,\n",
       "        -0.01560262, -0.00966209, -0.0160511 , -0.0436494 , -0.01262337,\n",
       "        -0.00315841, -0.01689593, -0.04677479,  0.06886314, -0.02967964,\n",
       "        -0.10502987, -0.01079107, -0.00934053, -0.04476247,  0.11107314,\n",
       "        -0.03187872, -0.03095899,  0.        , -0.02767096, -0.07871831,\n",
       "        -0.05899475, -0.01902571,  0.04571748,  0.06068743], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 64) dtype=float32, numpy=\n",
       " array([[ 0.01916621, -0.18120255,  0.1158694 , ...,  0.0143536 ,\n",
       "         -0.1879028 , -0.08739465],\n",
       "        [ 0.05814911, -0.16194507, -0.02578238, ...,  0.0795384 ,\n",
       "         -0.09771776,  0.00221281],\n",
       "        [-0.07750365,  0.1317967 ,  0.12921788, ..., -0.15285814,\n",
       "          0.14544822,  0.13724567],\n",
       "        ...,\n",
       "        [ 0.20089048, -0.00868481,  0.16564263, ..., -0.01926638,\n",
       "         -0.07356532, -0.12694523],\n",
       "        [-0.16936992, -0.01571479, -0.06393161, ...,  0.07042009,\n",
       "         -0.21207827,  0.10688549],\n",
       "        [-0.03350813, -0.03732871,  0.1180208 , ...,  0.07183132,\n",
       "         -0.08388987, -0.05472472]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([-0.06725546, -0.01885704,  0.08067805, -0.02528239,  0.16748472,\n",
       "        -0.01387571, -0.01250871, -0.00630808,  0.199999  ,  0.01904513,\n",
       "         0.        , -0.03140784, -0.02248134,  0.19471073,  0.01200713,\n",
       "        -0.04130099,  0.        ,  0.16906172,  0.07448943, -0.0292505 ,\n",
       "        -0.0103903 ,  0.19824678,  0.        , -0.02272796, -0.00629243,\n",
       "        -0.01921914,  0.18902978,  0.19832763,  0.        , -0.0279622 ,\n",
       "        -0.00563569, -0.02638137,  0.20449696, -0.02132383, -0.05731891,\n",
       "        -0.06041434, -0.01244923, -0.01293666, -0.0125136 , -0.00316227,\n",
       "        -0.0031432 , -0.02821059,  0.18700741,  0.19141954, -0.0169084 ,\n",
       "         0.        , -0.04100554, -0.01487488, -0.0054195 , -0.00316228,\n",
       "         0.0198385 , -0.01751867,  0.20928489,  0.14308766, -0.01608903,\n",
       "         0.        , -0.08144636, -0.02158126,  0.19310617, -0.03680455,\n",
       "        -0.05622963, -0.01669451, -0.00884391, -0.00573424], dtype=float32)>,\n",
       " <tf.Variable 'dense_4/kernel:0' shape=(64, 1) dtype=float32, numpy=\n",
       " array([[-4.69180085e-02],\n",
       "        [-1.31596863e-01],\n",
       "        [ 5.31152301e-02],\n",
       "        [-1.96181089e-01],\n",
       "        [ 1.24296665e-01],\n",
       "        [-8.52010474e-02],\n",
       "        [ 1.41382277e-01],\n",
       "        [-2.59492606e-01],\n",
       "        [ 2.78334916e-01],\n",
       "        [-1.00322277e-03],\n",
       "        [ 2.87323475e-01],\n",
       "        [-1.65148780e-01],\n",
       "        [-1.06815365e-03],\n",
       "        [ 2.35428676e-01],\n",
       "        [ 9.69386892e-04],\n",
       "        [ 1.73474150e-03],\n",
       "        [-1.23249710e-01],\n",
       "        [ 1.43113986e-01],\n",
       "        [ 2.52289395e-03],\n",
       "        [-2.09602535e-01],\n",
       "        [-1.15839735e-01],\n",
       "        [ 2.66900480e-01],\n",
       "        [ 1.70468688e-01],\n",
       "        [-9.37264785e-02],\n",
       "        [-1.36203438e-01],\n",
       "        [ 2.43071407e-01],\n",
       "        [ 1.69451207e-01],\n",
       "        [ 2.53594100e-01],\n",
       "        [-2.55476356e-01],\n",
       "        [ 4.43902100e-03],\n",
       "        [-1.36854142e-01],\n",
       "        [-2.34615833e-01],\n",
       "        [ 3.10711682e-01],\n",
       "        [-4.47316170e-02],\n",
       "        [ 2.54817889e-03],\n",
       "        [ 2.11844221e-04],\n",
       "        [-6.75774291e-02],\n",
       "        [ 8.03788134e-05],\n",
       "        [-5.05834632e-02],\n",
       "        [-1.01219937e-01],\n",
       "        [-4.26528528e-02],\n",
       "        [-9.81167629e-02],\n",
       "        [ 2.09836900e-01],\n",
       "        [ 2.34369263e-01],\n",
       "        [-1.37065053e-01],\n",
       "        [ 7.65261650e-02],\n",
       "        [-2.62434930e-01],\n",
       "        [-2.83034015e-02],\n",
       "        [-2.60732263e-01],\n",
       "        [-2.36435696e-01],\n",
       "        [-9.76845622e-04],\n",
       "        [-1.51147768e-01],\n",
       "        [ 3.32188606e-01],\n",
       "        [ 9.48098376e-02],\n",
       "        [ 8.39792937e-03],\n",
       "        [ 1.97799146e-01],\n",
       "        [-2.19641179e-02],\n",
       "        [-2.25680307e-01],\n",
       "        [ 2.43323252e-01],\n",
       "        [ 1.51072582e-03],\n",
       "        [-1.85286760e-01],\n",
       "        [ 6.96533499e-03],\n",
       "        [ 1.66277617e-01],\n",
       "        [-1.59215823e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense_4/bias:0' shape=(1,) dtype=float32, numpy=array([0.24346836], dtype=float32)>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights # show the weights of all units in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a5e58be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                3264      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 15,809\n",
      "Trainable params: 15,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# after the model is built, you can display its contents via the summary() method\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4388edd5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14604/2346730899.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#loss_df.plot()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"mae\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"MAE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training Loss and MAE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "#loss_df = pd.DataFrame(model.history.history)\n",
    "#loss_df.plot()\n",
    "\n",
    "plt.plot(best_models.history.history[\"loss\"], label=\"Loss\")\n",
    "plt.plot(best_models.history.history[\"mae\"], label=\"MAE\")\n",
    "plt.title(\"Training Loss and MAE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(best_models.history.history[\"val_loss\"], label=\"Val_Loss\")\n",
    "plt.plot(best_models.history.history[\"val_mae\"], label=\"Val_MAE\")\n",
    "plt.title(\"Validation Loss and MAE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# actually we should put training and validation loss as one fig and mae as one fig \n",
    "# (as the validation loss should eventually go up, i.e. we want to find the boundary of overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1acdae7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14604/4014598388.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#loss_df.plot()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"mae\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"MAE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training Loss and MAE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#loss_df = pd.DataFrame(model.history.history)\n",
    "#loss_df.plot()\n",
    "\n",
    "plt.plot(model.history.history[\"loss\"], label=\"Loss\")\n",
    "plt.plot(model.history.history[\"mae\"], label=\"MAE\")\n",
    "plt.title(\"Training Loss and MAE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(model.history.history[\"val_loss\"], label=\"Val_Loss\")\n",
    "plt.plot(model.history.history[\"val_mae\"], label=\"Val_MAE\")\n",
    "plt.title(\"Validation Loss and MAE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# actually we should put training and validation loss as one fig and mae as one fig \n",
    "# (as the validation loss should eventually go up, i.e. we want to find the boundary of overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e7e5796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000445059675257653, 0.020592495799064636]\n",
      "[0.00044693134259432554, 0.02067357487976551]\n",
      "[0.0004512197047006339, 0.020641539245843887]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_train, y_train, verbose=0)) # The training error\n",
    "print(model.evaluate(X_val, y_val, verbose=0))     # The validation error\n",
    "print(model.evaluate(X_test, y_test, verbose=0))   # The test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19fe285d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.9498098 ],\n",
       "       [1.8547928 ],\n",
       "       [1.543872  ],\n",
       "       [1.8588096 ],\n",
       "       [1.843251  ],\n",
       "       [1.9544469 ],\n",
       "       [1.2301006 ],\n",
       "       [1.889126  ],\n",
       "       [1.9556488 ],\n",
       "       [1.1637061 ],\n",
       "       [1.684513  ],\n",
       "       [2.0096772 ],\n",
       "       [1.8935168 ],\n",
       "       [1.9164929 ],\n",
       "       [1.8034865 ],\n",
       "       [1.9379946 ],\n",
       "       [1.2328123 ],\n",
       "       [2.0913136 ],\n",
       "       [1.9898115 ],\n",
       "       [2.036725  ],\n",
       "       [2.0903757 ],\n",
       "       [1.6223705 ],\n",
       "       [1.8517147 ],\n",
       "       [2.0787797 ],\n",
       "       [1.8726465 ],\n",
       "       [2.0910382 ],\n",
       "       [1.5811616 ],\n",
       "       [2.039997  ],\n",
       "       [1.9672942 ],\n",
       "       [2.0597649 ],\n",
       "       [1.0921433 ],\n",
       "       [1.6762382 ],\n",
       "       [1.850659  ],\n",
       "       [1.8727788 ],\n",
       "       [2.0432365 ],\n",
       "       [1.7455022 ],\n",
       "       [1.9127377 ],\n",
       "       [1.0443029 ],\n",
       "       [1.8013827 ],\n",
       "       [1.9693066 ],\n",
       "       [1.910251  ],\n",
       "       [0.82979983],\n",
       "       [2.0443895 ],\n",
       "       [1.502555  ],\n",
       "       [2.0738971 ],\n",
       "       [0.8322636 ],\n",
       "       [1.8640712 ],\n",
       "       [1.7574921 ],\n",
       "       [1.5487387 ],\n",
       "       [1.6297623 ],\n",
       "       [1.7804728 ],\n",
       "       [2.041564  ],\n",
       "       [1.8756772 ],\n",
       "       [2.0355237 ],\n",
       "       [1.7151487 ],\n",
       "       [2.0281012 ],\n",
       "       [1.715876  ],\n",
       "       [2.0836346 ],\n",
       "       [1.6604142 ],\n",
       "       [1.6660888 ],\n",
       "       [1.4299673 ],\n",
       "       [2.0292115 ],\n",
       "       [1.9404005 ],\n",
       "       [0.91718787],\n",
       "       [1.4608505 ],\n",
       "       [2.0378454 ],\n",
       "       [1.6848534 ],\n",
       "       [2.0863955 ],\n",
       "       [1.9486939 ],\n",
       "       [1.6985359 ],\n",
       "       [1.8966817 ],\n",
       "       [1.3173935 ],\n",
       "       [1.7670285 ],\n",
       "       [1.7004938 ],\n",
       "       [1.7040547 ],\n",
       "       [2.037498  ],\n",
       "       [1.3706506 ],\n",
       "       [1.9721545 ],\n",
       "       [2.0512464 ],\n",
       "       [1.5897753 ],\n",
       "       [2.0660775 ],\n",
       "       [1.365144  ],\n",
       "       [1.8988982 ],\n",
       "       [1.7918363 ],\n",
       "       [1.9284259 ],\n",
       "       [1.7267056 ],\n",
       "       [1.7424389 ],\n",
       "       [1.7124346 ],\n",
       "       [2.0644748 ],\n",
       "       [2.021359  ],\n",
       "       [2.0076113 ],\n",
       "       [2.0282602 ],\n",
       "       [2.071571  ],\n",
       "       [1.3942962 ],\n",
       "       [1.7276095 ],\n",
       "       [1.7859461 ],\n",
       "       [2.0701187 ],\n",
       "       [2.0235815 ],\n",
       "       [2.0118551 ],\n",
       "       [1.9982237 ],\n",
       "       [1.305506  ],\n",
       "       [1.8773788 ],\n",
       "       [1.8697226 ],\n",
       "       [2.0342011 ],\n",
       "       [1.9798315 ],\n",
       "       [1.6107671 ],\n",
       "       [1.5653505 ],\n",
       "       [2.024587  ],\n",
       "       [2.0681503 ],\n",
       "       [1.6345168 ],\n",
       "       [1.909061  ],\n",
       "       [1.9749297 ],\n",
       "       [1.8038094 ],\n",
       "       [1.4123703 ],\n",
       "       [2.0554752 ],\n",
       "       [1.8074981 ],\n",
       "       [2.0160444 ],\n",
       "       [1.3058511 ],\n",
       "       [1.635041  ],\n",
       "       [1.8092487 ],\n",
       "       [1.99753   ],\n",
       "       [1.8205711 ],\n",
       "       [2.0286567 ],\n",
       "       [1.9345202 ],\n",
       "       [1.7467388 ],\n",
       "       [1.8555583 ],\n",
       "       [1.7513614 ],\n",
       "       [1.8100413 ],\n",
       "       [2.0689273 ],\n",
       "       [1.4393809 ],\n",
       "       [1.9519252 ],\n",
       "       [1.7243841 ],\n",
       "       [1.1989708 ],\n",
       "       [1.9246268 ],\n",
       "       [2.0376136 ],\n",
       "       [2.0768137 ],\n",
       "       [0.90629816],\n",
       "       [1.9718556 ],\n",
       "       [1.5023528 ],\n",
       "       [2.058032  ],\n",
       "       [0.92867506],\n",
       "       [2.0222094 ],\n",
       "       [1.9635913 ],\n",
       "       [0.8288635 ],\n",
       "       [2.0260694 ],\n",
       "       [1.9791981 ],\n",
       "       [1.9026834 ],\n",
       "       [1.397512  ],\n",
       "       [1.4678162 ],\n",
       "       [1.8591535 ],\n",
       "       [1.9364545 ],\n",
       "       [1.9383235 ],\n",
       "       [1.7884827 ],\n",
       "       [2.0471137 ],\n",
       "       [1.89333   ],\n",
       "       [1.98245   ],\n",
       "       [1.8958158 ],\n",
       "       [0.82792014],\n",
       "       [1.9177166 ],\n",
       "       [1.8333937 ],\n",
       "       [0.8269698 ],\n",
       "       [1.8194935 ],\n",
       "       [2.0105166 ],\n",
       "       [1.2953452 ],\n",
       "       [1.5967201 ],\n",
       "       [0.91621244],\n",
       "       [2.083323  ],\n",
       "       [2.0612106 ],\n",
       "       [2.0313425 ],\n",
       "       [1.6200533 ],\n",
       "       [1.3769225 ],\n",
       "       [2.0766685 ],\n",
       "       [1.9901423 ],\n",
       "       [1.9771932 ],\n",
       "       [1.1163784 ],\n",
       "       [1.0810499 ],\n",
       "       [1.6702554 ],\n",
       "       [2.0633807 ],\n",
       "       [1.8426746 ],\n",
       "       [1.9311787 ],\n",
       "       [2.0426674 ],\n",
       "       [1.7221491 ],\n",
       "       [1.9193989 ],\n",
       "       [1.7952402 ],\n",
       "       [1.903835  ],\n",
       "       [2.0277832 ],\n",
       "       [1.2499796 ],\n",
       "       [1.9984082 ],\n",
       "       [1.6546453 ],\n",
       "       [1.2874378 ],\n",
       "       [2.0457222 ],\n",
       "       [1.6962377 ],\n",
       "       [1.8246195 ],\n",
       "       [1.7020091 ],\n",
       "       [2.0336936 ],\n",
       "       [1.8428909 ],\n",
       "       [1.4487724 ],\n",
       "       [1.728211  ],\n",
       "       [1.3703631 ],\n",
       "       [1.796395  ],\n",
       "       [1.8888735 ],\n",
       "       [2.0597339 ],\n",
       "       [1.0499398 ],\n",
       "       [1.7862008 ],\n",
       "       [2.0705047 ],\n",
       "       [1.1882181 ],\n",
       "       [2.0268676 ],\n",
       "       [1.2028307 ],\n",
       "       [2.0437367 ],\n",
       "       [1.0856591 ],\n",
       "       [1.7352506 ],\n",
       "       [2.027863  ],\n",
       "       [2.0084138 ],\n",
       "       [2.0872352 ],\n",
       "       [1.8879246 ],\n",
       "       [2.0335374 ],\n",
       "       [1.9627746 ],\n",
       "       [1.9772421 ],\n",
       "       [2.02144   ],\n",
       "       [1.6830333 ],\n",
       "       [2.024225  ],\n",
       "       [1.9502866 ],\n",
       "       [2.0385385 ],\n",
       "       [1.4452776 ],\n",
       "       [2.0744243 ],\n",
       "       [1.8188765 ],\n",
       "       [2.0305548 ],\n",
       "       [2.0049007 ],\n",
       "       [1.7546259 ],\n",
       "       [1.9002461 ],\n",
       "       [1.3668922 ],\n",
       "       [1.15078   ],\n",
       "       [1.9215915 ],\n",
       "       [1.9741391 ],\n",
       "       [1.8330233 ],\n",
       "       [1.8887471 ],\n",
       "       [1.4093114 ],\n",
       "       [1.6773995 ],\n",
       "       [1.961289  ],\n",
       "       [2.0588996 ],\n",
       "       [2.0228558 ],\n",
       "       [1.7523905 ],\n",
       "       [0.8881428 ],\n",
       "       [1.8498124 ],\n",
       "       [1.4733757 ],\n",
       "       [1.5017451 ],\n",
       "       [1.9597459 ],\n",
       "       [1.719078  ],\n",
       "       [1.7133765 ],\n",
       "       [1.8642749 ],\n",
       "       [2.0234206 ],\n",
       "       [0.9022482 ],\n",
       "       [2.0769007 ],\n",
       "       [1.9677483 ],\n",
       "       [1.8375165 ],\n",
       "       [2.0144331 ],\n",
       "       [1.7899119 ],\n",
       "       [2.084934  ],\n",
       "       [1.8285464 ],\n",
       "       [1.7507986 ],\n",
       "       [1.8594285 ],\n",
       "       [1.998085  ],\n",
       "       [2.0701482 ],\n",
       "       [1.6371301 ],\n",
       "       [1.4189609 ],\n",
       "       [1.9171926 ],\n",
       "       [2.0334592 ],\n",
       "       [1.8723155 ],\n",
       "       [1.7751745 ],\n",
       "       [1.5123309 ],\n",
       "       [1.8124875 ],\n",
       "       [2.0659268 ],\n",
       "       [2.0726628 ],\n",
       "       [2.0500352 ],\n",
       "       [1.3157195 ],\n",
       "       [1.9279743 ],\n",
       "       [2.0151365 ],\n",
       "       [1.518383  ],\n",
       "       [2.006708  ],\n",
       "       [1.8931428 ],\n",
       "       [1.9942765 ],\n",
       "       [0.8977162 ],\n",
       "       [2.0550053 ],\n",
       "       [2.0857782 ],\n",
       "       [2.0776248 ],\n",
       "       [1.975423  ],\n",
       "       [1.7607912 ],\n",
       "       [1.62019   ],\n",
       "       [1.690369  ],\n",
       "       [1.8361231 ],\n",
       "       [1.917018  ],\n",
       "       [1.9953486 ],\n",
       "       [2.04354   ],\n",
       "       [1.6082295 ],\n",
       "       [2.029291  ],\n",
       "       [1.9652703 ],\n",
       "       [2.0161269 ],\n",
       "       [1.9450561 ],\n",
       "       [1.4986926 ],\n",
       "       [2.0183034 ],\n",
       "       [1.9917926 ],\n",
       "       [1.4807233 ],\n",
       "       [1.9723036 ],\n",
       "       [1.7514552 ],\n",
       "       [0.91816026],\n",
       "       [1.915441  ],\n",
       "       [2.048241  ],\n",
       "       [1.9679496 ],\n",
       "       [1.4033331 ],\n",
       "       [1.9109634 ],\n",
       "       [2.0766397 ],\n",
       "       [2.0361056 ],\n",
       "       [2.054031  ],\n",
       "       [1.9675463 ],\n",
       "       [1.2508394 ],\n",
       "       [1.9811431 ],\n",
       "       [1.8636643 ],\n",
       "       [1.9653717 ],\n",
       "       [2.0114372 ],\n",
       "       [1.9246837 ],\n",
       "       [2.0075269 ],\n",
       "       [1.8206477 ],\n",
       "       [1.9328533 ],\n",
       "       [2.048851  ],\n",
       "       [1.9590234 ],\n",
       "       [1.979003  ],\n",
       "       [1.8138999 ],\n",
       "       [2.0226138 ],\n",
       "       [2.020669  ],\n",
       "       [1.8573605 ],\n",
       "       [1.5292556 ],\n",
       "       [1.8146826 ],\n",
       "       [1.5230006 ],\n",
       "       [1.5911161 ],\n",
       "       [2.0493958 ],\n",
       "       [1.8471171 ],\n",
       "       [1.8029214 ],\n",
       "       [2.0048554 ],\n",
       "       [1.9443024 ],\n",
       "       [1.8700558 ],\n",
       "       [1.8778356 ],\n",
       "       [2.0406475 ],\n",
       "       [1.8580514 ],\n",
       "       [2.0122306 ],\n",
       "       [2.0357955 ],\n",
       "       [1.5208913 ],\n",
       "       [1.8609376 ],\n",
       "       [2.034824  ],\n",
       "       [1.9850489 ],\n",
       "       [1.9363993 ],\n",
       "       [2.0196514 ],\n",
       "       [1.7644206 ],\n",
       "       [1.1344256 ],\n",
       "       [1.554358  ],\n",
       "       [2.0561638 ],\n",
       "       [1.8707886 ],\n",
       "       [1.9096565 ],\n",
       "       [1.7930853 ],\n",
       "       [2.0604115 ],\n",
       "       [1.6230487 ],\n",
       "       [1.7525773 ],\n",
       "       [1.9049833 ],\n",
       "       [1.8731754 ],\n",
       "       [2.0057602 ],\n",
       "       [1.9022582 ],\n",
       "       [2.0058959 ],\n",
       "       [2.0065725 ],\n",
       "       [2.0674613 ],\n",
       "       [1.866235  ],\n",
       "       [1.5905209 ],\n",
       "       [1.6688324 ],\n",
       "       [2.0053985 ],\n",
       "       [1.7039474 ],\n",
       "       [1.4118158 ],\n",
       "       [1.7022251 ],\n",
       "       [2.0362606 ],\n",
       "       [2.0051723 ],\n",
       "       [1.7590538 ],\n",
       "       [1.3160549 ],\n",
       "       [1.514881  ],\n",
       "       [1.9457545 ],\n",
       "       [1.9505514 ],\n",
       "       [1.6496588 ],\n",
       "       [1.7431113 ],\n",
       "       [1.4468013 ],\n",
       "       [1.9793929 ],\n",
       "       [2.058125  ],\n",
       "       [1.7901634 ],\n",
       "       [1.8342813 ],\n",
       "       [1.7692608 ],\n",
       "       [1.9688548 ],\n",
       "       [2.0450404 ],\n",
       "       [1.6049596 ],\n",
       "       [1.735937  ],\n",
       "       [1.9015888 ],\n",
       "       [1.9360684 ],\n",
       "       [1.932742  ],\n",
       "       [1.5934865 ],\n",
       "       [1.515467  ],\n",
       "       [0.81951416],\n",
       "       [1.6756562 ],\n",
       "       [1.9881519 ],\n",
       "       [2.0558197 ],\n",
       "       [2.0598264 ],\n",
       "       [1.8635963 ],\n",
       "       [1.401755  ],\n",
       "       [1.8750206 ],\n",
       "       [1.9946965 ],\n",
       "       [1.6994075 ],\n",
       "       [1.0997742 ],\n",
       "       [1.9969746 ],\n",
       "       [1.8319838 ],\n",
       "       [1.7200023 ],\n",
       "       [1.9969281 ],\n",
       "       [2.0907347 ],\n",
       "       [2.0602884 ],\n",
       "       [1.0528052 ],\n",
       "       [1.8297459 ],\n",
       "       [2.0612414 ],\n",
       "       [2.047146  ],\n",
       "       [1.9307868 ],\n",
       "       [1.499509  ],\n",
       "       [1.8185676 ],\n",
       "       [2.009593  ],\n",
       "       [2.0832949 ],\n",
       "       [2.0425534 ],\n",
       "       [2.0139773 ],\n",
       "       [1.1943362 ],\n",
       "       [2.0691066 ],\n",
       "       [2.0767267 ],\n",
       "       [1.7216393 ],\n",
       "       [1.8510817 ],\n",
       "       [1.1205779 ],\n",
       "       [1.8082151 ],\n",
       "       [2.0373435 ],\n",
       "       [1.8510113 ],\n",
       "       [1.9400188 ],\n",
       "       [1.674606  ],\n",
       "       [1.3861283 ],\n",
       "       [1.9310668 ],\n",
       "       [1.879397  ],\n",
       "       [1.9538182 ],\n",
       "       [2.0858345 ],\n",
       "       [1.536881  ],\n",
       "       [1.2717214 ],\n",
       "       [1.9117335 ],\n",
       "       [1.9230264 ],\n",
       "       [1.8862101 ],\n",
       "       [1.2946336 ],\n",
       "       [1.7630638 ],\n",
       "       [1.2264544 ],\n",
       "       [2.0700593 ],\n",
       "       [1.7035176 ],\n",
       "       [2.0270274 ],\n",
       "       [1.5115427 ],\n",
       "       [0.9112922 ],\n",
       "       [1.7125393 ],\n",
       "       [1.9968356 ],\n",
       "       [1.0803868 ],\n",
       "       [0.8828215 ],\n",
       "       [1.9754725 ],\n",
       "       [2.0529583 ],\n",
       "       [1.4352252 ],\n",
       "       [2.0202215 ],\n",
       "       [2.0388846 ],\n",
       "       [2.0627408 ],\n",
       "       [2.0460465 ],\n",
       "       [1.5512294 ],\n",
       "       [1.758228  ],\n",
       "       [1.186314  ],\n",
       "       [1.6141223 ],\n",
       "       [1.1078637 ],\n",
       "       [1.9063076 ],\n",
       "       [2.0443566 ],\n",
       "       [1.4941685 ],\n",
       "       [1.8826272 ],\n",
       "       [1.976014  ],\n",
       "       [2.0553813 ],\n",
       "       [1.8714532 ],\n",
       "       [1.9538704 ],\n",
       "       [1.6681188 ],\n",
       "       [0.81571025],\n",
       "       [1.617445  ],\n",
       "       [1.8646134 ],\n",
       "       [1.33594   ],\n",
       "       [1.9862936 ],\n",
       "       [1.9297769 ],\n",
       "       [1.2512684 ],\n",
       "       [1.0716518 ],\n",
       "       [1.5894768 ],\n",
       "       [1.269684  ],\n",
       "       [2.062038  ],\n",
       "       [2.0408008 ],\n",
       "       [2.084793  ],\n",
       "       [1.5256674 ],\n",
       "       [1.8871001 ],\n",
       "       [1.997021  ],\n",
       "       [1.6576031 ],\n",
       "       [1.6177208 ],\n",
       "       [1.9858632 ],\n",
       "       [1.962519  ],\n",
       "       [1.9477347 ],\n",
       "       [1.9889117 ],\n",
       "       [2.0068429 ],\n",
       "       [1.4079132 ],\n",
       "       [1.1697363 ],\n",
       "       [1.9517671 ],\n",
       "       [2.0923033 ],\n",
       "       [0.9434016 ],\n",
       "       [1.5528795 ],\n",
       "       [1.7518295 ],\n",
       "       [1.7017928 ],\n",
       "       [2.0423253 ],\n",
       "       [2.0098872 ],\n",
       "       [1.9416519 ],\n",
       "       [1.8420248 ],\n",
       "       [1.8795915 ],\n",
       "       [1.8893155 ],\n",
       "       [1.8099622 ],\n",
       "       [1.9834629 ],\n",
       "       [1.97783   ],\n",
       "       [1.8893784 ],\n",
       "       [1.2095959 ],\n",
       "       [1.8648165 ],\n",
       "       [1.8066195 ],\n",
       "       [1.8102788 ],\n",
       "       [1.7325903 ],\n",
       "       [1.9925913 ],\n",
       "       [1.0978816 ],\n",
       "       [1.8733076 ],\n",
       "       [1.7152528 ],\n",
       "       [2.017853  ],\n",
       "       [1.5191567 ],\n",
       "       [2.0910106 ],\n",
       "       [1.769439  ],\n",
       "       [2.0655947 ],\n",
       "       [2.030594  ],\n",
       "       [1.236398  ],\n",
       "       [1.2610065 ],\n",
       "       [2.067521  ],\n",
       "       [2.0311456 ],\n",
       "       [1.7845858 ],\n",
       "       [2.0656247 ],\n",
       "       [1.8814678 ],\n",
       "       [2.0258691 ],\n",
       "       [2.0752132 ],\n",
       "       [1.8201097 ],\n",
       "       [2.0593634 ],\n",
       "       [2.0551622 ],\n",
       "       [1.5545217 ],\n",
       "       [1.6653696 ],\n",
       "       [2.044161  ],\n",
       "       [1.6313545 ],\n",
       "       [1.818181  ],\n",
       "       [2.0591471 ],\n",
       "       [1.9908032 ],\n",
       "       [1.8911401 ],\n",
       "       [2.0565386 ],\n",
       "       [2.0542514 ],\n",
       "       [1.8605951 ],\n",
       "       [2.092468  ],\n",
       "       [1.9941831 ],\n",
       "       [1.7025486 ],\n",
       "       [2.089684  ],\n",
       "       [2.090293  ],\n",
       "       [1.5978885 ],\n",
       "       [1.8271167 ],\n",
       "       [1.9262195 ],\n",
       "       [1.6085125 ],\n",
       "       [0.9517364 ],\n",
       "       [1.8737036 ],\n",
       "       [2.036764  ],\n",
       "       [2.065353  ],\n",
       "       [1.8610743 ],\n",
       "       [2.0624046 ],\n",
       "       [2.0205064 ],\n",
       "       [2.08849   ],\n",
       "       [2.0708606 ],\n",
       "       [1.939473  ],\n",
       "       [2.0784914 ],\n",
       "       [1.9580404 ],\n",
       "       [1.7435907 ],\n",
       "       [2.0087092 ],\n",
       "       [1.7181515 ],\n",
       "       [1.4695362 ],\n",
       "       [1.8427464 ],\n",
       "       [1.9077469 ],\n",
       "       [1.8921429 ],\n",
       "       [1.8425301 ],\n",
       "       [1.543703  ],\n",
       "       [1.5484054 ],\n",
       "       [1.9703087 ],\n",
       "       [1.9701084 ],\n",
       "       [2.0893788 ],\n",
       "       [1.814604  ],\n",
       "       [2.0761163 ],\n",
       "       [1.8841032 ],\n",
       "       [0.81486213],\n",
       "       [1.5656708 ],\n",
       "       [1.2148275 ],\n",
       "       [1.1097052 ],\n",
       "       [1.9828845 ],\n",
       "       [2.086732  ],\n",
       "       [1.6577257 ],\n",
       "       [1.7573999 ],\n",
       "       [1.1735244 ],\n",
       "       [1.7142116 ],\n",
       "       [1.9996059 ],\n",
       "       [2.0796425 ],\n",
       "       [2.025469  ],\n",
       "       [1.9690558 ],\n",
       "       [1.6590728 ],\n",
       "       [0.9397803 ],\n",
       "       [1.7788312 ],\n",
       "       [1.4731635 ],\n",
       "       [1.9470404 ],\n",
       "       [1.8665718 ],\n",
       "       [1.8567377 ],\n",
       "       [1.9100728 ],\n",
       "       [1.4817603 ],\n",
       "       [1.8125662 ],\n",
       "       [1.2643355 ],\n",
       "       [2.0359116 ],\n",
       "       [1.811385  ],\n",
       "       [1.2372891 ],\n",
       "       [2.0554442 ],\n",
       "       [1.7244853 ],\n",
       "       [1.7167052 ],\n",
       "       [1.7943304 ],\n",
       "       [1.9212462 ],\n",
       "       [1.6134261 ],\n",
       "       [1.6079465 ],\n",
       "       [1.9896225 ],\n",
       "       [1.7226583 ],\n",
       "       [2.0714233 ],\n",
       "       [2.067341  ],\n",
       "       [1.6866641 ],\n",
       "       [1.8903234 ],\n",
       "       [1.9268433 ],\n",
       "       [1.544041  ],\n",
       "       [1.0542355 ],\n",
       "       [1.8854455 ],\n",
       "       [2.0409153 ],\n",
       "       [1.7984477 ],\n",
       "       [1.3044682 ],\n",
       "       [1.9977151 ],\n",
       "       [2.0468874 ],\n",
       "       [1.7377931 ],\n",
       "       [1.8298209 ],\n",
       "       [1.8316118 ],\n",
       "       [1.0889158 ],\n",
       "       [2.0332637 ],\n",
       "       [1.563584  ],\n",
       "       [1.6529082 ],\n",
       "       [2.0897393 ],\n",
       "       [2.0813322 ],\n",
       "       [1.4001696 ],\n",
       "       [2.044259  ],\n",
       "       [2.0029018 ],\n",
       "       [1.3983113 ],\n",
       "       [0.913269  ],\n",
       "       [1.9219939 ],\n",
       "       [1.4828197 ],\n",
       "       [1.5307561 ],\n",
       "       [1.8942642 ],\n",
       "       [1.419505  ],\n",
       "       [1.9944631 ],\n",
       "       [1.5135102 ],\n",
       "       [1.4025447 ],\n",
       "       [1.9408361 ],\n",
       "       [2.054377  ],\n",
       "       [2.043704  ],\n",
       "       [2.0230172 ],\n",
       "       [1.9407818 ],\n",
       "       [2.0574727 ],\n",
       "       [2.056975  ],\n",
       "       [1.537065  ],\n",
       "       [1.8582582 ],\n",
       "       [1.750235  ],\n",
       "       [1.7737714 ],\n",
       "       [1.5354055 ],\n",
       "       [0.81710136],\n",
       "       [1.9395822 ],\n",
       "       [1.9635406 ],\n",
       "       [1.8133515 ],\n",
       "       [2.056101  ],\n",
       "       [1.9386524 ],\n",
       "       [1.2259963 ],\n",
       "       [2.0692854 ],\n",
       "       [1.55583   ],\n",
       "       [2.0488832 ],\n",
       "       [1.8695222 ],\n",
       "       [1.519543  ],\n",
       "       [2.0278232 ],\n",
       "       [2.08056   ],\n",
       "       [1.6927061 ],\n",
       "       [1.9054652 ],\n",
       "       [1.7633357 ],\n",
       "       [2.0546598 ],\n",
       "       [1.4211332 ],\n",
       "       [1.9651178 ],\n",
       "       [2.0671008 ],\n",
       "       [2.015219  ],\n",
       "       [2.0420208 ],\n",
       "       [1.844616  ],\n",
       "       [2.0684793 ],\n",
       "       [1.9618025 ],\n",
       "       [1.9264466 ],\n",
       "       [1.4304963 ],\n",
       "       [2.007865  ],\n",
       "       [2.049492  ],\n",
       "       [1.367473  ],\n",
       "       [2.0082874 ],\n",
       "       [0.8302654 ],\n",
       "       [2.0108933 ],\n",
       "       [2.0162094 ],\n",
       "       [1.8372236 ],\n",
       "       [1.9449484 ],\n",
       "       [2.0203028 ],\n",
       "       [2.0817027 ],\n",
       "       [2.0352128 ],\n",
       "       [1.9858154 ],\n",
       "       [1.920266  ],\n",
       "       [1.2305541 ],\n",
       "       [2.0886292 ],\n",
       "       [1.8117003 ],\n",
       "       [2.0162916 ],\n",
       "       [1.815541  ],\n",
       "       [1.7251934 ],\n",
       "       [1.8688539 ],\n",
       "       [2.0925503 ],\n",
       "       [2.009004  ],\n",
       "       [1.5606917 ],\n",
       "       [2.0688975 ],\n",
       "       [1.8689208 ],\n",
       "       [1.6274943 ],\n",
       "       [1.4641329 ],\n",
       "       [1.6868896 ],\n",
       "       [1.7772685 ],\n",
       "       [2.0415256 ],\n",
       "       [1.9321843 ],\n",
       "       [1.2568033 ],\n",
       "       [0.8400926 ],\n",
       "       [1.6672845 ],\n",
       "       [1.5814676 ],\n",
       "       [1.6111885 ],\n",
       "       [1.879332  ],\n",
       "       [1.745216  ],\n",
       "       [1.7137944 ],\n",
       "       [2.0571928 ],\n",
       "       [2.069732  ],\n",
       "       [1.4706068 ],\n",
       "       [1.9248545 ],\n",
       "       [2.0763202 ],\n",
       "       [1.737208  ],\n",
       "       [1.9523466 ],\n",
       "       [1.6226418 ],\n",
       "       [1.9376649 ],\n",
       "       [1.4265114 ],\n",
       "       [2.0582802 ],\n",
       "       [1.7399303 ],\n",
       "       [1.7089587 ],\n",
       "       [1.75108   ],\n",
       "       [1.9844731 ],\n",
       "       [1.3689209 ],\n",
       "       [2.051215  ],\n",
       "       [1.2978244 ],\n",
       "       [2.0108097 ],\n",
       "       [1.7433032 ],\n",
       "       [1.8693887 ],\n",
       "       [2.0745707 ],\n",
       "       [1.8539561 ],\n",
       "       [2.0526104 ],\n",
       "       [1.4375683 ],\n",
       "       [1.8342074 ],\n",
       "       [1.9405643 ],\n",
       "       [1.6687136 ],\n",
       "       [1.6694261 ],\n",
       "       [2.055632  ],\n",
       "       [2.0005703 ],\n",
       "       [1.7494819 ],\n",
       "       [2.0014408 ],\n",
       "       [2.0892959 ],\n",
       "       [1.9136803 ],\n",
       "       [2.0880723 ],\n",
       "       [1.9241701 ],\n",
       "       [2.0494277 ],\n",
       "       [1.980172  ],\n",
       "       [1.5031611 ],\n",
       "       [1.8824986 ],\n",
       "       [2.0158796 ],\n",
       "       [2.0670106 ],\n",
       "       [2.0314603 ],\n",
       "       [1.641271  ],\n",
       "       [1.2346095 ],\n",
       "       [1.7624289 ],\n",
       "       [2.0165796 ],\n",
       "       [2.0628016 ],\n",
       "       [1.3340327 ],\n",
       "       [1.1010306 ],\n",
       "       [1.9695073 ],\n",
       "       [2.063594  ],\n",
       "       [2.0099292 ],\n",
       "       [1.6976622 ],\n",
       "       [1.8676476 ],\n",
       "       [1.765232  ],\n",
       "       [1.7905823 ],\n",
       "       [1.9996519 ],\n",
       "       [1.9263331 ],\n",
       "       [0.8240409 ],\n",
       "       [1.4902155 ],\n",
       "       [1.5355903 ],\n",
       "       [1.6305594 ],\n",
       "       [2.0663488 ],\n",
       "       [2.0764942 ],\n",
       "       [1.1299148 ],\n",
       "       [1.9257649 ],\n",
       "       [1.9104291 ],\n",
       "       [2.0736332 ],\n",
       "       [1.5231918 ],\n",
       "       [1.3140374 ],\n",
       "       [1.9352397 ],\n",
       "       [2.0543141 ],\n",
       "       [1.8399233 ],\n",
       "       [1.9137391 ],\n",
       "       [2.0737505 ],\n",
       "       [1.9162012 ],\n",
       "       [1.9478947 ],\n",
       "       [1.6273603 ],\n",
       "       [2.0930436 ],\n",
       "       [2.0134792 ],\n",
       "       [1.4286419 ],\n",
       "       [1.9362341 ],\n",
       "       [1.8819836 ],\n",
       "       [1.656866  ],\n",
       "       [1.813273  ],\n",
       "       [1.9087027 ],\n",
       "       [1.9149723 ],\n",
       "       [2.0443242 ],\n",
       "       [1.9290458 ],\n",
       "       [2.0524204 ],\n",
       "       [2.0196106 ],\n",
       "       [1.9344091 ],\n",
       "       [1.4278442 ],\n",
       "       [2.0571308 ],\n",
       "       [2.0396905 ],\n",
       "       [1.6921512 ],\n",
       "       [2.0922484 ],\n",
       "       [2.0552874 ],\n",
       "       [1.9682013 ],\n",
       "       [1.6923734 ],\n",
       "       [2.011688  ],\n",
       "       [1.6238613 ],\n",
       "       [1.6210092 ],\n",
       "       [1.9373354 ],\n",
       "       [1.3116692 ],\n",
       "       [1.3592542 ],\n",
       "       [1.9471473 ],\n",
       "       [1.6438342 ],\n",
       "       [1.9872481 ],\n",
       "       [2.067911  ],\n",
       "       [1.421404  ],\n",
       "       [2.0347462 ],\n",
       "       [1.9252533 ],\n",
       "       [1.8681172 ],\n",
       "       [1.7428235 ],\n",
       "       [2.0632591 ],\n",
       "       [1.5389    ],\n",
       "       [1.6539019 ],\n",
       "       [1.7790042 ],\n",
       "       [2.0412588 ],\n",
       "       [1.0689211 ],\n",
       "       [1.5212758 ],\n",
       "       [1.9693569 ],\n",
       "       [2.041335  ],\n",
       "       [2.0020807 ],\n",
       "       [1.6227776 ],\n",
       "       [2.0066175 ],\n",
       "       [2.044487  ],\n",
       "       [1.569965  ],\n",
       "       [1.880175  ],\n",
       "       [1.9427363 ],\n",
       "       [1.2241576 ],\n",
       "       [1.0723312 ],\n",
       "       [1.8570147 ],\n",
       "       [2.0188353 ],\n",
       "       [1.9549177 ],\n",
       "       [0.9749741 ],\n",
       "       [1.0556601 ],\n",
       "       [1.8515741 ],\n",
       "       [1.9910392 ],\n",
       "       [1.7472132 ],\n",
       "       [2.0413733 ],\n",
       "       [1.0882667 ],\n",
       "       [1.9741884 ],\n",
       "       [2.0790677 ],\n",
       "       [1.808931  ],\n",
       "       [1.0404537 ],\n",
       "       [1.0449399 ],\n",
       "       [1.4090322 ],\n",
       "       [1.8628484 ],\n",
       "       [1.5408162 ],\n",
       "       [0.8450649 ],\n",
       "       [1.5610133 ],\n",
       "       [2.0264287 ],\n",
       "       [1.7498586 ],\n",
       "       [1.958092  ],\n",
       "       [1.8279451 ],\n",
       "       [1.3409766 ],\n",
       "       [1.4470547 ],\n",
       "       [2.0608115 ],\n",
       "       [1.9278616 ],\n",
       "       [1.9193412 ],\n",
       "       [2.0345905 ],\n",
       "       [1.6012257 ],\n",
       "       [1.8844235 ],\n",
       "       [1.0423843 ],\n",
       "       [1.9658281 ],\n",
       "       [1.4660875 ],\n",
       "       [1.9881994 ],\n",
       "       [1.6029539 ],\n",
       "       [1.5137063 ],\n",
       "       [1.5430259 ],\n",
       "       [2.0451055 ],\n",
       "       [1.984521  ],\n",
       "       [1.8340598 ],\n",
       "       [1.6448543 ],\n",
       "       [1.716498  ],\n",
       "       [1.9076271 ],\n",
       "       [1.7787446 ],\n",
       "       [2.0379994 ],\n",
       "       [1.8971756 ],\n",
       "       [2.0879333 ],\n",
       "       [1.1681012 ],\n",
       "       [2.0263488 ],\n",
       "       [2.0560699 ],\n",
       "       [2.0237024 ],\n",
       "       [1.5500695 ],\n",
       "       [1.9781238 ],\n",
       "       [1.8561832 ],\n",
       "       [1.792836  ],\n",
       "       [1.5301942 ],\n",
       "       [1.7309047 ],\n",
       "       [1.275763  ],\n",
       "       [1.8170186 ],\n",
       "       [1.8400687 ],\n",
       "       [1.1756519 ],\n",
       "       [1.9229118 ],\n",
       "       [2.0111446 ],\n",
       "       [1.8418804 ],\n",
       "       [2.0851595 ],\n",
       "       [1.0902102 ],\n",
       "       [1.4184159 ],\n",
       "       [1.8822412 ],\n",
       "       [1.4775928 ],\n",
       "       [1.9689555 ],\n",
       "       [1.5001203 ],\n",
       "       [1.9579883 ],\n",
       "       [1.1266129 ],\n",
       "       [1.1473343 ],\n",
       "       [1.5311304 ],\n",
       "       [1.7273084 ],\n",
       "       [1.5241457 ],\n",
       "       [1.9139155 ],\n",
       "       [2.0498757 ],\n",
       "       [1.9250823 ],\n",
       "       [1.8956298 ],\n",
       "       [1.9914633 ],\n",
       "       [2.0613027 ],\n",
       "       [2.0097191 ],\n",
       "       [2.0825    ],\n",
       "       [2.0709496 ],\n",
       "       [1.5333673 ],\n",
       "       [1.6368695 ],\n",
       "       [2.0477908 ],\n",
       "       [1.0606027 ],\n",
       "       [1.6515371 ],\n",
       "       [1.9067879 ],\n",
       "       [1.8608006 ],\n",
       "       [1.6025227 ],\n",
       "       [2.0102232 ],\n",
       "       [1.8354611 ],\n",
       "       [2.0359504 ],\n",
       "       [2.0539365 ],\n",
       "       [2.0398438 ],\n",
       "       [1.6444722 ],\n",
       "       [2.0574105 ],\n",
       "       [1.6206    ],\n",
       "       [1.7842451 ],\n",
       "       [2.0874588 ],\n",
       "       [2.092934  ],\n",
       "       [2.0922759 ],\n",
       "       [2.0024457 ],\n",
       "       [1.4754907 ],\n",
       "       [1.722251  ],\n",
       "       [1.7971351 ],\n",
       "       [1.972055  ],\n",
       "       [1.7315997 ],\n",
       "       [1.5777787 ],\n",
       "       [2.0190394 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = model.predict(X_test)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f76f9547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct Entropy</th>\n",
       "      <th>Model Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.92547</td>\n",
       "      <td>1.949810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.83266</td>\n",
       "      <td>1.854793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.52335</td>\n",
       "      <td>1.543872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.83660</td>\n",
       "      <td>1.858810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.82135</td>\n",
       "      <td>1.843251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.77604</td>\n",
       "      <td>1.797135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.94712</td>\n",
       "      <td>1.972055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.71134</td>\n",
       "      <td>1.731600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.55777</td>\n",
       "      <td>1.577779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.99351</td>\n",
       "      <td>2.019039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Correct Entropy  Model Predictions\n",
       "0            1.92547           1.949810\n",
       "1            1.83266           1.854793\n",
       "2            1.52335           1.543872\n",
       "3            1.83660           1.858810\n",
       "4            1.82135           1.843251\n",
       "..               ...                ...\n",
       "995          1.77604           1.797135\n",
       "996          1.94712           1.972055\n",
       "997          1.71134           1.731600\n",
       "998          1.55777           1.577779\n",
       "999          1.99351           2.019039\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = pd.DataFrame(test_predictions)\n",
    "test_pred.columns = ['Model Predictions']\n",
    "#test_pred.index = [8, 1, 5]\n",
    "#test_pred\n",
    "\n",
    "pred_df = pd.DataFrame(y_test)\n",
    "pred_df_reset_index = pred_df.reset_index(drop=True)\n",
    "#pred_df_reset_index\n",
    "\n",
    "df_compare = pd.concat([pred_df_reset_index, test_pred], axis = 1)\n",
    "df_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dc2b32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Correct Entropy', ylabel='Model Predictions'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x='Correct Entropy', y='Model Predictions', data=df_compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c5d335",
   "metadata": {},
   "source": [
    "### Single Interval at Finite Temperature and Finite Length (all T) (Varying T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c1d70b",
   "metadata": {},
   "source": [
    "Note that we can also fix T but vary length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f4d98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\") \n",
    "# to restart the kernel, prevent from reusing any trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7582204",
   "metadata": {},
   "source": [
    "Physical parameter of data distributes as $\\beta=0.1, \\beta<3.1, \\beta+=0.03$  (not including $\\beta=3.07$)\n",
    "\n",
    "20000 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa969e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct Entropy</th>\n",
       "      <th>Approx Entropy</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.623360</td>\n",
       "      <td>4.102218</td>\n",
       "      <td>0.968806</td>\n",
       "      <td>0.469857</td>\n",
       "      <td>0.304185</td>\n",
       "      <td>0.221792</td>\n",
       "      <td>0.172683</td>\n",
       "      <td>0.140193</td>\n",
       "      <td>0.117184</td>\n",
       "      <td>0.100086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.001309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.502510</td>\n",
       "      <td>3.273667</td>\n",
       "      <td>0.927697</td>\n",
       "      <td>0.432383</td>\n",
       "      <td>0.269933</td>\n",
       "      <td>0.190405</td>\n",
       "      <td>0.143846</td>\n",
       "      <td>0.113631</td>\n",
       "      <td>0.092655</td>\n",
       "      <td>0.077379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.000670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.816530</td>\n",
       "      <td>2.694443</td>\n",
       "      <td>0.879053</td>\n",
       "      <td>0.390748</td>\n",
       "      <td>0.234082</td>\n",
       "      <td>0.159343</td>\n",
       "      <td>0.116767</td>\n",
       "      <td>0.089880</td>\n",
       "      <td>0.071696</td>\n",
       "      <td>0.058774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.357110</td>\n",
       "      <td>2.282567</td>\n",
       "      <td>0.829295</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>0.201778</td>\n",
       "      <td>0.132873</td>\n",
       "      <td>0.094828</td>\n",
       "      <td>0.071487</td>\n",
       "      <td>0.056102</td>\n",
       "      <td>0.045408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.030170</td>\n",
       "      <td>1.980069</td>\n",
       "      <td>0.781846</td>\n",
       "      <td>0.315227</td>\n",
       "      <td>0.174530</td>\n",
       "      <td>0.111668</td>\n",
       "      <td>0.078022</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>0.044962</td>\n",
       "      <td>0.036105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.386329</td>\n",
       "      <td>0.384570</td>\n",
       "      <td>0.251501</td>\n",
       "      <td>0.050257</td>\n",
       "      <td>0.020773</td>\n",
       "      <td>0.011989</td>\n",
       "      <td>0.008011</td>\n",
       "      <td>0.005781</td>\n",
       "      <td>0.004383</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.386295</td>\n",
       "      <td>0.384538</td>\n",
       "      <td>0.251486</td>\n",
       "      <td>0.050252</td>\n",
       "      <td>0.020771</td>\n",
       "      <td>0.011988</td>\n",
       "      <td>0.008010</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.386264</td>\n",
       "      <td>0.384509</td>\n",
       "      <td>0.251472</td>\n",
       "      <td>0.050248</td>\n",
       "      <td>0.020769</td>\n",
       "      <td>0.011986</td>\n",
       "      <td>0.008009</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.386236</td>\n",
       "      <td>0.384482</td>\n",
       "      <td>0.251460</td>\n",
       "      <td>0.050244</td>\n",
       "      <td>0.020767</td>\n",
       "      <td>0.011985</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.386211</td>\n",
       "      <td>0.384458</td>\n",
       "      <td>0.251449</td>\n",
       "      <td>0.050240</td>\n",
       "      <td>0.020765</td>\n",
       "      <td>0.011984</td>\n",
       "      <td>0.008007</td>\n",
       "      <td>0.005778</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Correct Entropy  Approx Entropy         1         2         3         4  \\\n",
       "0          4.623360        4.102218  0.968806  0.469857  0.304185  0.221792   \n",
       "1          3.502510        3.273667  0.927697  0.432383  0.269933  0.190405   \n",
       "2          2.816530        2.694443  0.879053  0.390748  0.234082  0.159343   \n",
       "3          2.357110        2.282567  0.829295  0.350877  0.201778  0.132873   \n",
       "4          2.030170        1.980069  0.781846  0.315227  0.174530  0.111668   \n",
       "..              ...             ...       ...       ...       ...       ...   \n",
       "95         0.386329        0.384570  0.251501  0.050257  0.020773  0.011989   \n",
       "96         0.386295        0.384538  0.251486  0.050252  0.020771  0.011988   \n",
       "97         0.386264        0.384509  0.251472  0.050248  0.020769  0.011986   \n",
       "98         0.386236        0.384482  0.251460  0.050244  0.020767  0.011985   \n",
       "99         0.386211        0.384458  0.251449  0.050240  0.020765  0.011984   \n",
       "\n",
       "           5         6         7         8  ...       191       192       193  \\\n",
       "0   0.172683  0.140193  0.117184  0.100086  ...  0.001399  0.001388  0.001378   \n",
       "1   0.143846  0.113631  0.092655  0.077379  ...  0.000719  0.000713  0.000708   \n",
       "2   0.116767  0.089880  0.071696  0.058774  ...  0.000422  0.000418  0.000415   \n",
       "3   0.094828  0.071487  0.056102  0.045408  ...  0.000274  0.000272  0.000270   \n",
       "4   0.078022  0.057924  0.044962  0.036105  ...  0.000193  0.000191  0.000190   \n",
       "..       ...       ...       ...       ...  ...       ...       ...       ...   \n",
       "95  0.008011  0.005781  0.004383  0.003443  ...  0.000009  0.000009  0.000009   \n",
       "96  0.008010  0.005780  0.004382  0.003442  ...  0.000009  0.000009  0.000009   \n",
       "97  0.008009  0.005780  0.004381  0.003442  ...  0.000009  0.000009  0.000009   \n",
       "98  0.008008  0.005779  0.004381  0.003441  ...  0.000009  0.000009  0.000009   \n",
       "99  0.008007  0.005778  0.004381  0.003441  ...  0.000009  0.000009  0.000009   \n",
       "\n",
       "         194       195       196       197       198       199       200  \n",
       "0   0.001367  0.001357  0.001347  0.001338  0.001328  0.001318  0.001309  \n",
       "1   0.000702  0.000696  0.000691  0.000686  0.000680  0.000675  0.000670  \n",
       "2   0.000411  0.000408  0.000405  0.000401  0.000398  0.000395  0.000392  \n",
       "3   0.000267  0.000265  0.000263  0.000261  0.000259  0.000256  0.000254  \n",
       "4   0.000188  0.000186  0.000185  0.000183  0.000182  0.000180  0.000179  \n",
       "..       ...       ...       ...       ...       ...       ...       ...  \n",
       "95  0.000009  0.000008  0.000008  0.000008  0.000008  0.000008  0.000008  \n",
       "96  0.000009  0.000008  0.000008  0.000008  0.000008  0.000008  0.000008  \n",
       "97  0.000009  0.000008  0.000008  0.000008  0.000008  0.000008  0.000008  \n",
       "98  0.000009  0.000008  0.000008  0.000008  0.000008  0.000008  0.000008  \n",
       "99  0.000009  0.000008  0.000008  0.000008  0.000008  0.000008  0.000008  \n",
       "\n",
       "[100 rows x 202 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "df = pd.read_csv('Data_Single_Interval_allT.csv')\n",
    "df\n",
    "\n",
    "# Note that the data here needs specal attention. \n",
    "# The first row has large deviation between correct and approx entropies.\n",
    "# The correct entropy for low temperature regime is barely changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f2afc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zxpet\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.775x0.755)\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we should check the data\n",
    "# If there are problems with data (e.g. extreme values, weired distribution), use Scaler in the next block\n",
    "\n",
    "print(sns.distplot(df['Correct Entropy']))\n",
    "# Safe to ignore warnings\n",
    "\n",
    "print(df.plot(y='Correct Entropy', use_index=True))\n",
    "\n",
    "print(df.reset_index().plot.scatter(x='index',y='Correct Entropy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4754a995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.968806</td>\n",
       "      <td>0.469857</td>\n",
       "      <td>0.304185</td>\n",
       "      <td>0.221792</td>\n",
       "      <td>0.172683</td>\n",
       "      <td>0.140193</td>\n",
       "      <td>0.117184</td>\n",
       "      <td>0.100086</td>\n",
       "      <td>0.086918</td>\n",
       "      <td>0.076492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.001309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.927697</td>\n",
       "      <td>0.432383</td>\n",
       "      <td>0.269933</td>\n",
       "      <td>0.190405</td>\n",
       "      <td>0.143846</td>\n",
       "      <td>0.113631</td>\n",
       "      <td>0.092655</td>\n",
       "      <td>0.077379</td>\n",
       "      <td>0.065846</td>\n",
       "      <td>0.056891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.000670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.879053</td>\n",
       "      <td>0.390748</td>\n",
       "      <td>0.234082</td>\n",
       "      <td>0.159343</td>\n",
       "      <td>0.116767</td>\n",
       "      <td>0.089880</td>\n",
       "      <td>0.071696</td>\n",
       "      <td>0.058774</td>\n",
       "      <td>0.049234</td>\n",
       "      <td>0.041976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.829295</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>0.201778</td>\n",
       "      <td>0.132873</td>\n",
       "      <td>0.094828</td>\n",
       "      <td>0.071487</td>\n",
       "      <td>0.056102</td>\n",
       "      <td>0.045408</td>\n",
       "      <td>0.037659</td>\n",
       "      <td>0.031852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.781846</td>\n",
       "      <td>0.315227</td>\n",
       "      <td>0.174530</td>\n",
       "      <td>0.111668</td>\n",
       "      <td>0.078022</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>0.044962</td>\n",
       "      <td>0.036105</td>\n",
       "      <td>0.029769</td>\n",
       "      <td>0.025066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0  0.968806  0.469857  0.304185  0.221792  0.172683  0.140193  0.117184   \n",
       "1  0.927697  0.432383  0.269933  0.190405  0.143846  0.113631  0.092655   \n",
       "2  0.879053  0.390748  0.234082  0.159343  0.116767  0.089880  0.071696   \n",
       "3  0.829295  0.350877  0.201778  0.132873  0.094828  0.071487  0.056102   \n",
       "4  0.781846  0.315227  0.174530  0.111668  0.078022  0.057924  0.044962   \n",
       "\n",
       "          8         9        10  ...       191       192       193       194  \\\n",
       "0  0.100086  0.086918  0.076492  ...  0.001399  0.001388  0.001378  0.001367   \n",
       "1  0.077379  0.065846  0.056891  ...  0.000719  0.000713  0.000708  0.000702   \n",
       "2  0.058774  0.049234  0.041976  ...  0.000422  0.000418  0.000415  0.000411   \n",
       "3  0.045408  0.037659  0.031852  ...  0.000274  0.000272  0.000270  0.000267   \n",
       "4  0.036105  0.029769  0.025066  ...  0.000193  0.000191  0.000190  0.000188   \n",
       "\n",
       "        195       196       197       198       199       200  \n",
       "0  0.001357  0.001347  0.001338  0.001328  0.001318  0.001309  \n",
       "1  0.000696  0.000691  0.000686  0.000680  0.000675  0.000670  \n",
       "2  0.000408  0.000405  0.000401  0.000398  0.000395  0.000392  \n",
       "3  0.000265  0.000263  0.000261  0.000259  0.000256  0.000254  \n",
       "4  0.000186  0.000185  0.000183  0.000182  0.000180  0.000179  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.drop(['Correct Entropy','Approx Entropy'], axis = 1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03f9d8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 200)\n",
      "(10, 200)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df1\n",
    "y = df['Correct Entropy']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state = 42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c1bffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# We don't need to worry about the input dimensions, the layers will automatically infer input shape as the shape of \n",
    "# the first inputs they see.\n",
    "\n",
    "# Write the layers separately such that it is easy to comment out each layer\n",
    "# Note we don't need to worry about input/output sizes that connect each layer, Keras will handle it automatically.\n",
    "\n",
    "model.add(Dense(4, activation = 'relu'))\n",
    "#model.add(Dense(4, activation = 'relu'))\n",
    "#model.add(Dense(4, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(1)) \n",
    "# The final layer has only 1 node as we are predicting a single value of correct entropy\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'mse', metrics=[\"mae\"]) \n",
    "#Root Mean Squared Propagation as optimizer and  Mean Squared Error as loss fun\n",
    "\n",
    "# Note we can have customized setup (have to build from scratch):\n",
    "# model.compilte(optimizer = keras.optimizers.RMSprop(learning_rate=1e-4, loss = my_custom_loss, \n",
    "# metrics=[my_custom_metric_1, my_custom_metric_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "739e5403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6287 - mae: 0.5993\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 0.5852 - mae: 0.5672\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.5569 - mae: 0.5453\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.5335 - mae: 0.5280\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.5120 - mae: 0.5117\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.4919 - mae: 0.4955\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.4745 - mae: 0.4816\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.4577 - mae: 0.4674\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.4424 - mae: 0.4552\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.4278 - mae: 0.4415\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.4137 - mae: 0.4304\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.3996 - mae: 0.4171\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.3864 - mae: 0.4044\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.3740 - mae: 0.3918\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.3622 - mae: 0.3798\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.3507 - mae: 0.3687\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.3387 - mae: 0.3565\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.3275 - mae: 0.3432\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.3163 - mae: 0.3317\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.3053 - mae: 0.3196\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.2947 - mae: 0.3058\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.2848 - mae: 0.2947\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.2748 - mae: 0.2824\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.2651 - mae: 0.2692\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.2565 - mae: 0.2562\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.2485 - mae: 0.2448\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.2403 - mae: 0.2345\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.2318 - mae: 0.2218\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2241 - mae: 0.2090\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.2167 - mae: 0.1977\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.2099 - mae: 0.1918\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.2031 - mae: 0.1896\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1964 - mae: 0.1886\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.1899 - mae: 0.1887\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1841 - mae: 0.1889\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 509us/step - loss: 0.1784 - mae: 0.1899\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.1733 - mae: 0.1915\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.1684 - mae: 0.1924\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.1638 - mae: 0.1949\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1602 - mae: 0.1978\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.1564 - mae: 0.1981\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.1528 - mae: 0.1997\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.1492 - mae: 0.2033\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.1460 - mae: 0.2044\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.1428 - mae: 0.2062\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.1401 - mae: 0.2078\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.1376 - mae: 0.2120\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.1349 - mae: 0.2118\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1327 - mae: 0.2158\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.1310 - mae: 0.2130\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1285 - mae: 0.2170\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1270 - mae: 0.2159\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.1247 - mae: 0.2147\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.1228 - mae: 0.2153\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1208 - mae: 0.2143\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.1194 - mae: 0.2129\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.1169 - mae: 0.2128\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.1153 - mae: 0.2133\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1131 - mae: 0.2125\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.1114 - mae: 0.2104\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.1093 - mae: 0.2090\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.1073 - mae: 0.2073\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.1052 - mae: 0.2061\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.1040 - mae: 0.2033\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.1017 - mae: 0.2010\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0996 - mae: 0.2008\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0979 - mae: 0.1980\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0957 - mae: 0.1958\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0937 - mae: 0.1934\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0921 - mae: 0.1926\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0902 - mae: 0.1881\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0880 - mae: 0.1875\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0865 - mae: 0.1854\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0844 - mae: 0.1831\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0825 - mae: 0.1810\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0809 - mae: 0.1792\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0791 - mae: 0.1770\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0774 - mae: 0.1743\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 0.0755 - mae: 0.1734\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0739 - mae: 0.1719\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0721 - mae: 0.1704\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0703 - mae: 0.1667\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0692 - mae: 0.1668\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0673 - mae: 0.1638\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0658 - mae: 0.1610\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0640 - mae: 0.1584\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0625 - mae: 0.1570\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0611 - mae: 0.1583\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0593 - mae: 0.1538\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0576 - mae: 0.1512\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0565 - mae: 0.1481\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0546 - mae: 0.1488\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0532 - mae: 0.1448\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0518 - mae: 0.1442\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0502 - mae: 0.1420\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0487 - mae: 0.1404\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0472 - mae: 0.1366\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0456 - mae: 0.1340\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0443 - mae: 0.1302\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0429 - mae: 0.1276\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0412 - mae: 0.1275\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0398 - mae: 0.1255\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0384 - mae: 0.1241\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0373 - mae: 0.1207\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0361 - mae: 0.1168\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0346 - mae: 0.1161\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0335 - mae: 0.1150\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0323 - mae: 0.1106\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 0.0311 - mae: 0.1068\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0298 - mae: 0.1068\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0286 - mae: 0.1038\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0275 - mae: 0.1007\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0261 - mae: 0.0994\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0252 - mae: 0.0985\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0242 - mae: 0.0942\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0229 - mae: 0.0924\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0226 - mae: 0.0909\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0211 - mae: 0.0877\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0202 - mae: 0.0861\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0193 - mae: 0.0843\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0185 - mae: 0.0832\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0175 - mae: 0.0817\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0168 - mae: 0.0759\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0159 - mae: 0.0765\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 0s 494us/step - loss: 0.0151 - mae: 0.0735\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 503us/step - loss: 0.0144 - mae: 0.0717\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0136 - mae: 0.0694\n",
      "Epoch 128/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0128 - mae: 0.0668\n",
      "Epoch 129/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0121 - mae: 0.0633\n",
      "Epoch 130/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0113 - mae: 0.0648\n",
      "Epoch 131/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0106 - mae: 0.0600\n",
      "Epoch 132/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0102 - mae: 0.0575\n",
      "Epoch 133/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0095 - mae: 0.0560\n",
      "Epoch 134/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0088 - mae: 0.0538\n",
      "Epoch 135/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0083 - mae: 0.0509\n",
      "Epoch 136/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0076 - mae: 0.0489\n",
      "Epoch 137/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0071 - mae: 0.0468\n",
      "Epoch 138/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0065 - mae: 0.0465\n",
      "Epoch 139/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0060 - mae: 0.0429\n",
      "Epoch 140/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0055 - mae: 0.0415\n",
      "Epoch 141/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0050 - mae: 0.0391\n",
      "Epoch 142/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0047 - mae: 0.0374\n",
      "Epoch 143/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0042 - mae: 0.0356\n",
      "Epoch 144/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0038 - mae: 0.0307\n",
      "Epoch 145/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0035 - mae: 0.0321\n",
      "Epoch 146/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0032 - mae: 0.0260\n",
      "Epoch 147/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0028 - mae: 0.0287\n",
      "Epoch 148/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0026 - mae: 0.0254\n",
      "Epoch 149/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0024 - mae: 0.0230\n",
      "Epoch 150/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0021 - mae: 0.0239\n",
      "Epoch 151/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0019 - mae: 0.0210\n",
      "Epoch 152/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0016 - mae: 0.0208\n",
      "Epoch 153/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0015 - mae: 0.0171\n",
      "Epoch 154/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0013 - mae: 0.0177\n",
      "Epoch 155/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0012 - mae: 0.0144\n",
      "Epoch 156/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0010 - mae: 0.0162\n",
      "Epoch 157/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.9836e-04 - mae: 0.0095\n",
      "Epoch 158/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.1032e-04 - mae: 0.0112\n",
      "Epoch 159/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.8258e-04 - mae: 0.0129\n",
      "Epoch 160/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.5069e-04 - mae: 0.0103\n",
      "Epoch 161/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.9194e-04 - mae: 0.0075\n",
      "Epoch 162/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 5.3973e-04 - mae: 0.0094\n",
      "Epoch 163/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 5.1781e-04 - mae: 0.0092\n",
      "Epoch 164/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.9710e-04 - mae: 0.0090\n",
      "Epoch 165/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 4.4242e-04 - mae: 0.0088\n",
      "Epoch 166/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.1885e-04 - mae: 0.0088\n",
      "Epoch 167/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.0081e-04 - mae: 0.0090\n",
      "Epoch 168/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.1292e-04 - mae: 0.0100\n",
      "Epoch 169/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 3.7583e-04 - mae: 0.0100\n",
      "Epoch 170/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 3.5749e-04 - mae: 0.0098\n",
      "Epoch 171/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 3.6534e-04 - mae: 0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.2935e-04 - mae: 0.0097\n",
      "Epoch 173/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.3575e-04 - mae: 0.0100\n",
      "Epoch 174/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.3022e-04 - mae: 0.0106\n",
      "Epoch 175/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 3.4530e-04 - mae: 0.0096\n",
      "Epoch 176/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.1023e-04 - mae: 0.0103\n",
      "Epoch 177/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.2396e-04 - mae: 0.0102\n",
      "Epoch 178/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 3.0773e-04 - mae: 0.0109\n",
      "Epoch 179/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.1064e-04 - mae: 0.0102\n",
      "Epoch 180/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.7680e-04 - mae: 0.0097\n",
      "Epoch 181/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.9960e-04 - mae: 0.0101\n",
      "Epoch 182/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.7409e-04 - mae: 0.0100\n",
      "Epoch 183/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.9231e-04 - mae: 0.0101\n",
      "Epoch 184/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 2.7420e-04 - mae: 0.0100\n",
      "Epoch 185/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.6262e-04 - mae: 0.0099\n",
      "Epoch 186/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.7622e-04 - mae: 0.0095\n",
      "Epoch 187/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.5228e-04 - mae: 0.0094\n",
      "Epoch 188/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.4141e-04 - mae: 0.0097\n",
      "Epoch 189/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.6413e-04 - mae: 0.0096\n",
      "Epoch 190/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.7744e-04 - mae: 0.0092\n",
      "Epoch 191/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 2.2642e-04 - mae: 0.0091\n",
      "Epoch 192/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.3033e-04 - mae: 0.0094\n",
      "Epoch 193/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 2.1251e-04 - mae: 0.0091\n",
      "Epoch 194/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.2712e-04 - mae: 0.0082\n",
      "Epoch 195/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 2.0877e-04 - mae: 0.0087\n",
      "Epoch 196/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.0322e-04 - mae: 0.0085\n",
      "Epoch 197/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.2284e-04 - mae: 0.0093\n",
      "Epoch 198/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.3751e-04 - mae: 0.0092\n",
      "Epoch 199/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 2.1836e-04 - mae: 0.0085\n",
      "Epoch 200/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.8554e-04 - mae: 0.0081\n",
      "Epoch 201/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 2.1661e-04 - mae: 0.0096\n",
      "Epoch 202/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.8626e-04 - mae: 0.0081\n",
      "Epoch 203/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.7050e-04 - mae: 0.0075\n",
      "Epoch 204/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.6674e-04 - mae: 0.0077\n",
      "Epoch 205/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.6823e-04 - mae: 0.0082\n",
      "Epoch 206/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.2721e-04 - mae: 0.0084\n",
      "Epoch 207/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.5903e-04 - mae: 0.0075\n",
      "Epoch 208/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.7918e-04 - mae: 0.0085\n",
      "Epoch 209/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.5499e-04 - mae: 0.0070\n",
      "Epoch 210/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.8548e-04 - mae: 0.0075\n",
      "Epoch 211/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.5280e-04 - mae: 0.0084\n",
      "Epoch 212/500\n",
      "3/3 [==============================] - 0s 497us/step - loss: 1.3681e-04 - mae: 0.0070\n",
      "Epoch 213/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.6448e-04 - mae: 0.0074\n",
      "Epoch 214/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.3571e-04 - mae: 0.0069\n",
      "Epoch 215/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.3657e-04 - mae: 0.0069\n",
      "Epoch 216/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2377e-04 - mae: 0.0067\n",
      "Epoch 217/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2398e-04 - mae: 0.0067\n",
      "Epoch 218/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1360e-04 - mae: 0.0067\n",
      "Epoch 219/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.5104e-04 - mae: 0.0068\n",
      "Epoch 220/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.2055e-04 - mae: 0.0066\n",
      "Epoch 221/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.3381e-04 - mae: 0.0070\n",
      "Epoch 222/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.0332e-04 - mae: 0.0060\n",
      "Epoch 223/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1112e-04 - mae: 0.0061\n",
      "Epoch 224/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.2450e-04 - mae: 0.0070\n",
      "Epoch 225/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2115e-04 - mae: 0.0060\n",
      "Epoch 226/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.5450e-05 - mae: 0.0056\n",
      "Epoch 227/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2421e-04 - mae: 0.0070\n",
      "Epoch 228/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 9.2106e-05 - mae: 0.0058\n",
      "Epoch 229/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.5248e-05 - mae: 0.0051\n",
      "Epoch 230/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 9.0105e-05 - mae: 0.0056\n",
      "Epoch 231/500\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7.8763e-05 - mae: 0.0052\n",
      "Epoch 232/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.6977e-05 - mae: 0.0048\n",
      "Epoch 233/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.2725e-05 - mae: 0.0052\n",
      "Epoch 234/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.4399e-05 - mae: 0.0050\n",
      "Epoch 235/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.9778e-05 - mae: 0.0052\n",
      "Epoch 236/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.9917e-05 - mae: 0.0067\n",
      "Epoch 237/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.4410e-05 - mae: 0.0056\n",
      "Epoch 238/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.2594e-05 - mae: 0.0053\n",
      "Epoch 239/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 5.8586e-05 - mae: 0.0047\n",
      "Epoch 240/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.6036e-05 - mae: 0.0047\n",
      "Epoch 241/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 6.9574e-05 - mae: 0.0050\n",
      "Epoch 242/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.7227e-05 - mae: 0.0052\n",
      "Epoch 243/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.7155e-05 - mae: 0.0041\n",
      "Epoch 244/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.2793e-05 - mae: 0.0039\n",
      "Epoch 245/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.6823e-05 - mae: 0.0046\n",
      "Epoch 246/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.8320e-05 - mae: 0.0050\n",
      "Epoch 247/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 5.3338e-05 - mae: 0.0045\n",
      "Epoch 248/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.7840e-05 - mae: 0.0055\n",
      "Epoch 249/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 5.3581e-05 - mae: 0.0044\n",
      "Epoch 250/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 6.7688e-05 - mae: 0.0046\n",
      "Epoch 251/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.3693e-05 - mae: 0.0043\n",
      "Epoch 252/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.5013e-05 - mae: 0.0039\n",
      "Epoch 253/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.0736e-05 - mae: 0.0040\n",
      "Epoch 254/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.0602e-05 - mae: 0.0040\n",
      "Epoch 255/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.8219e-05 - mae: 0.0051\n",
      "Epoch 256/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.4469e-05 - mae: 0.0029\n",
      "Epoch 257/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.8675e-05 - mae: 0.0036\n",
      "Epoch 258/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.8615e-05 - mae: 0.0036\n",
      "Epoch 259/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.0927e-05 - mae: 0.0036\n",
      "Epoch 260/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.5427e-05 - mae: 0.0038\n",
      "Epoch 261/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.6111e-05 - mae: 0.0044\n",
      "Epoch 262/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.6611e-05 - mae: 0.0041\n",
      "Epoch 263/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.8093e-05 - mae: 0.0041\n",
      "Epoch 264/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 2.9223e-05 - mae: 0.0031\n",
      "Epoch 265/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 2.6204e-05 - mae: 0.0022\n",
      "Epoch 266/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.7631e-05 - mae: 0.0033\n",
      "Epoch 267/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.7019e-05 - mae: 0.0030\n",
      "Epoch 268/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.1468e-05 - mae: 0.0045\n",
      "Epoch 269/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.0423e-05 - mae: 0.0024\n",
      "Epoch 270/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 2.4814e-05 - mae: 0.0030\n",
      "Epoch 271/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.0435e-05 - mae: 0.0026\n",
      "Epoch 272/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.1489e-05 - mae: 0.0029\n",
      "Epoch 273/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.6059e-05 - mae: 0.0022\n",
      "Epoch 274/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.7492e-05 - mae: 0.0016\n",
      "Epoch 275/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 4.2092e-05 - mae: 0.0055\n",
      "Epoch 276/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.9051e-05 - mae: 0.0027\n",
      "Epoch 277/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 3.1930e-05 - mae: 0.0036\n",
      "Epoch 278/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 2.9386e-05 - mae: 0.0040\n",
      "Epoch 279/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 3.2453e-05 - mae: 0.0038\n",
      "Epoch 280/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.7138e-05 - mae: 0.0026\n",
      "Epoch 281/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.5516e-05 - mae: 0.0024\n",
      "Epoch 282/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.8597e-05 - mae: 0.0045\n",
      "Epoch 283/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.6372e-05 - mae: 0.0026\n",
      "Epoch 284/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.4238e-05 - mae: 0.0019\n",
      "Epoch 285/500\n",
      "3/3 [==============================] - 0s 506us/step - loss: 1.6177e-05 - mae: 0.0029\n",
      "Epoch 286/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.3799e-05 - mae: 0.0040\n",
      "Epoch 287/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 3.5548e-05 - mae: 0.0045\n",
      "Epoch 288/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.0284e-05 - mae: 0.0014\n",
      "Epoch 289/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.0554e-05 - mae: 0.0018\n",
      "Epoch 290/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.1745e-05 - mae: 0.0019\n",
      "Epoch 291/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 3.0789e-05 - mae: 0.0042\n",
      "Epoch 292/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.0998e-05 - mae: 0.0035\n",
      "Epoch 293/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 2.8366e-05 - mae: 0.0040\n",
      "Epoch 294/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.0063e-05 - mae: 0.0020\n",
      "Epoch 295/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.1452e-05 - mae: 0.0024\n",
      "Epoch 296/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.1798e-06 - mae: 0.0019\n",
      "Epoch 297/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.2717e-06 - mae: 0.0016\n",
      "Epoch 298/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 2.2449e-05 - mae: 0.0040\n",
      "Epoch 299/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.1461e-05 - mae: 0.0024\n",
      "Epoch 300/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 3.6404e-05 - mae: 0.0049\n",
      "Epoch 301/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.6853e-06 - mae: 0.0016\n",
      "Epoch 302/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.5044e-05 - mae: 0.0024\n",
      "Epoch 303/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.3248e-05 - mae: 0.0030\n",
      "Epoch 304/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.9097e-05 - mae: 0.0028\n",
      "Epoch 305/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 3.8855e-05 - mae: 0.0051\n",
      "Epoch 306/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 6.7296e-06 - mae: 0.0013\n",
      "Epoch 307/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.1265e-05 - mae: 0.0024\n",
      "Epoch 308/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.7450e-06 - mae: 0.0023\n",
      "Epoch 309/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.2165e-06 - mae: 0.0013\n",
      "Epoch 310/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.5124e-05 - mae: 0.0023\n",
      "Epoch 311/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.3832e-05 - mae: 0.0041\n",
      "Epoch 312/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.5207e-05 - mae: 0.0027\n",
      "Epoch 313/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.2230e-06 - mae: 0.0021\n",
      "Epoch 314/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.3511e-06 - mae: 0.0016\n",
      "Epoch 315/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.5592e-06 - mae: 0.0020\n",
      "Epoch 316/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.0268e-05 - mae: 0.0027\n",
      "Epoch 317/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 4.4245e-05 - mae: 0.0056\n",
      "Epoch 318/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.6177e-06 - mae: 0.0014\n",
      "Epoch 319/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.0492e-05 - mae: 0.0021\n",
      "Epoch 320/500\n",
      "3/3 [==============================] - 0s 503us/step - loss: 7.6419e-06 - mae: 0.0019\n",
      "Epoch 321/500\n",
      "3/3 [==============================] - 0s 993us/step - loss: 1.1296e-05 - mae: 0.0028\n",
      "Epoch 322/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.1888e-06 - mae: 0.0015\n",
      "Epoch 323/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 4.6276e-05 - mae: 0.0058\n",
      "Epoch 324/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 5.3948e-06 - mae: 0.0014\n",
      "Epoch 325/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.5689e-06 - mae: 0.0013\n",
      "Epoch 326/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 5.4547e-06 - mae: 0.0015\n",
      "Epoch 327/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 2.3944e-05 - mae: 0.0036\n",
      "Epoch 328/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 3.0041e-05 - mae: 0.0046\n",
      "Epoch 329/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.1140e-05 - mae: 0.0023\n",
      "Epoch 330/500\n",
      "3/3 [==============================] - 0s 999us/step - loss: 9.0574e-06 - mae: 0.0023\n",
      "Epoch 331/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.6316e-06 - mae: 0.0025\n",
      "Epoch 332/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.5774e-06 - mae: 0.0015\n",
      "Epoch 333/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.7922e-05 - mae: 0.0052\n",
      "Epoch 334/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.5945e-06 - mae: 0.0021\n",
      "Epoch 335/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 997us/step - loss: 5.6104e-06 - mae: 0.0014\n",
      "Epoch 336/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.6879e-06 - mae: 0.0017\n",
      "Epoch 337/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.1155e-06 - mae: 0.0015\n",
      "Epoch 338/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 1.0134e-05 - mae: 0.0021\n",
      "Epoch 339/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 2.7272e-05 - mae: 0.0048\n",
      "Epoch 340/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 2.3909e-05 - mae: 0.0039\n",
      "Epoch 341/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.3125e-06 - mae: 0.0015\n",
      "Epoch 342/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.6163e-06 - mae: 0.0022\n",
      "Epoch 343/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.2284e-05 - mae: 0.0029\n",
      "Epoch 344/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 3.1124e-05 - mae: 0.0047\n",
      "Epoch 345/500\n",
      "3/3 [==============================] - 0s 495us/step - loss: 5.4380e-06 - mae: 0.0017\n",
      "Epoch 346/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.1322e-05 - mae: 0.0024\n",
      "Epoch 347/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 8.7900e-06 - mae: 0.0026\n",
      "Epoch 348/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 4.0027e-06 - mae: 0.0011\n",
      "Epoch 349/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.7460e-06 - mae: 0.0013\n",
      "Epoch 350/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 2.3976e-05 - mae: 0.0041\n",
      "Epoch 351/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 3.4823e-05 - mae: 0.0048\n",
      "Epoch 352/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 4.0221e-06 - mae: 9.3222e-04\n",
      "Epoch 353/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 3.8810e-06 - mae: 0.0010\n",
      "Epoch 354/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.2448e-06 - mae: 0.0011\n",
      "Epoch 355/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.5870e-06 - mae: 0.0022\n",
      "Epoch 356/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.0284e-05 - mae: 0.0029\n",
      "Epoch 357/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.7726e-06 - mae: 0.0019\n",
      "Epoch 358/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.5969e-06 - mae: 0.0021\n",
      "Epoch 359/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.6040e-05 - mae: 0.0059\n",
      "Epoch 360/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.8747e-06 - mae: 0.0021\n",
      "Epoch 361/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.1762e-05 - mae: 0.0027\n",
      "Epoch 362/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.8867e-06 - mae: 0.0020\n",
      "Epoch 363/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2812e-05 - mae: 0.0030\n",
      "Epoch 364/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.7415e-06 - mae: 0.0011\n",
      "Epoch 365/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.1229e-05 - mae: 0.0031\n",
      "Epoch 366/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0389e-05 - mae: 0.0028\n",
      "Epoch 367/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 3.7803e-05 - mae: 0.0052\n",
      "Epoch 368/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.8661e-06 - mae: 0.0021\n",
      "Epoch 369/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.3733e-06 - mae: 0.0013\n",
      "Epoch 370/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.5829e-06 - mae: 8.1773e-04\n",
      "Epoch 371/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.6426e-06 - mae: 0.0016\n",
      "Epoch 372/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 2.0554e-05 - mae: 0.0040\n",
      "Epoch 373/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.2748e-05 - mae: 0.0049\n",
      "Epoch 374/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.0049e-05 - mae: 0.0022\n",
      "Epoch 375/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.6295e-06 - mae: 0.0021\n",
      "Epoch 376/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.0389e-05 - mae: 0.0025\n",
      "Epoch 377/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.5130e-05 - mae: 0.0032\n",
      "Epoch 378/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.8568e-05 - mae: 0.0047\n",
      "Epoch 379/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 6.7567e-06 - mae: 0.0015\n",
      "Epoch 380/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.4948e-05 - mae: 0.0033\n",
      "Epoch 381/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 4.1734e-06 - mae: 0.0013\n",
      "Epoch 382/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.0562e-06 - mae: 0.0012\n",
      "Epoch 383/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.7107e-05 - mae: 0.0047\n",
      "Epoch 384/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 2.0880e-05 - mae: 0.0038\n",
      "Epoch 385/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.4891e-06 - mae: 0.0016\n",
      "Epoch 386/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 5.0804e-06 - mae: 0.0016\n",
      "Epoch 387/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.6986e-05 - mae: 0.0031\n",
      "Epoch 388/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.4691e-05 - mae: 0.0034\n",
      "Epoch 389/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.0988e-06 - mae: 0.0013\n",
      "Epoch 390/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 3.5834e-06 - mae: 9.4035e-04\n",
      "Epoch 391/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.3048e-05 - mae: 0.0027\n",
      "Epoch 392/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 2.1699e-05 - mae: 0.0042\n",
      "Epoch 393/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.5223e-05 - mae: 0.0033\n",
      "Epoch 394/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.1557e-06 - mae: 0.0015\n",
      "Epoch 395/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.3771e-06 - mae: 0.0019\n",
      "Epoch 396/500\n",
      "3/3 [==============================] - 0s 505us/step - loss: 6.7798e-06 - mae: 0.0014\n",
      "Epoch 397/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 3.1368e-05 - mae: 0.0052\n",
      "Epoch 398/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.1863e-06 - mae: 0.0012\n",
      "Epoch 399/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.3628e-05 - mae: 0.0031\n",
      "Epoch 400/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.0165e-05 - mae: 0.0025\n",
      "Epoch 401/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.9362e-06 - mae: 0.0013\n",
      "Epoch 402/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0567e-05 - mae: 0.0030\n",
      "Epoch 403/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.0958e-05 - mae: 0.0025\n",
      "Epoch 404/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.5237e-05 - mae: 0.0035\n",
      "Epoch 405/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 9.0178e-06 - mae: 0.0026\n",
      "Epoch 406/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.5361e-06 - mae: 0.0010\n",
      "Epoch 407/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.6413e-05 - mae: 0.0032\n",
      "Epoch 408/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.8750e-05 - mae: 0.0039\n",
      "Epoch 409/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.4532e-05 - mae: 0.0040\n",
      "Epoch 410/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.0270e-05 - mae: 0.0026\n",
      "Epoch 411/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.5365e-06 - mae: 8.9226e-04\n",
      "Epoch 412/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.3369e-06 - mae: 0.0017\n",
      "Epoch 413/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.3900e-05 - mae: 0.0043\n",
      "Epoch 414/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.4260e-05 - mae: 0.0033\n",
      "Epoch 415/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.2955e-06 - mae: 0.0013\n",
      "Epoch 416/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.9389e-06 - mae: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.9044e-05 - mae: 0.0040\n",
      "Epoch 418/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 2.4253e-05 - mae: 0.0041\n",
      "Epoch 419/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2540e-05 - mae: 0.0030\n",
      "Epoch 420/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 3.2971e-06 - mae: 9.0430e-04\n",
      "Epoch 421/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 3.1639e-06 - mae: 8.8869e-04\n",
      "Epoch 422/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.3246e-06 - mae: 0.0018\n",
      "Epoch 423/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.0139e-05 - mae: 0.0050\n",
      "Epoch 424/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.8162e-05 - mae: 0.0034\n",
      "Epoch 425/500\n",
      "3/3 [==============================] - 0s 497us/step - loss: 8.4037e-06 - mae: 0.0024\n",
      "Epoch 426/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.0178e-06 - mae: 0.0018\n",
      "Epoch 427/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.7552e-05 - mae: 0.0037\n",
      "Epoch 428/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.3912e-06 - mae: 0.0016\n",
      "Epoch 429/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.8168e-06 - mae: 0.0017\n",
      "Epoch 430/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 3.6943e-06 - mae: 0.0011\n",
      "Epoch 431/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 2.5210e-05 - mae: 0.0041\n",
      "Epoch 432/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 2.6063e-05 - mae: 0.0044\n",
      "Epoch 433/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.0117e-06 - mae: 0.0012\n",
      "Epoch 434/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.4649e-05 - mae: 0.0032\n",
      "Epoch 435/500\n",
      "3/3 [==============================] - 0s 999us/step - loss: 3.3487e-06 - mae: 8.9684e-04\n",
      "Epoch 436/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.6645e-05 - mae: 0.0034\n",
      "Epoch 437/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.8428e-05 - mae: 0.0036\n",
      "Epoch 438/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.1725e-05 - mae: 0.0029\n",
      "Epoch 439/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 4.3351e-06 - mae: 0.0015\n",
      "Epoch 440/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.2850e-06 - mae: 0.0014\n",
      "Epoch 441/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 3.8067e-06 - mae: 0.0012\n",
      "Epoch 442/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.9359e-05 - mae: 0.0051\n",
      "Epoch 443/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 4.9459e-06 - mae: 0.0017\n",
      "Epoch 444/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 5.1682e-06 - mae: 0.0012\n",
      "Epoch 445/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2535e-05 - mae: 0.0030\n",
      "Epoch 446/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.2254e-05 - mae: 0.0042\n",
      "Epoch 447/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 3.3563e-06 - mae: 9.3495e-04\n",
      "Epoch 448/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.8917e-06 - mae: 0.0020\n",
      "Epoch 449/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2.5524e-05 - mae: 0.0042\n",
      "Epoch 450/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2869e-05 - mae: 0.0029\n",
      "Epoch 451/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.0121e-06 - mae: 0.0021\n",
      "Epoch 452/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 3.2810e-06 - mae: 8.8927e-04\n",
      "Epoch 453/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.2736e-06 - mae: 0.0015\n",
      "Epoch 454/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.9479e-05 - mae: 0.0050\n",
      "Epoch 455/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.9976e-06 - mae: 0.0016\n",
      "Epoch 456/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.6898e-05 - mae: 0.0035\n",
      "Epoch 457/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 9.2091e-06 - mae: 0.0022\n",
      "Epoch 458/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.1856e-05 - mae: 0.0041\n",
      "Epoch 459/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 4.6138e-06 - mae: 0.0015\n",
      "Epoch 460/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 3.6249e-06 - mae: 0.0010\n",
      "Epoch 461/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.4380e-06 - mae: 0.0023\n",
      "Epoch 462/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.0540e-05 - mae: 0.0040\n",
      "Epoch 463/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 4.3378e-05 - mae: 0.0055\n",
      "Epoch 464/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.6976e-06 - mae: 0.0013\n",
      "Epoch 465/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.7845e-06 - mae: 0.0012\n",
      "Epoch 466/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.0221e-06 - mae: 0.0013\n",
      "Epoch 467/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.0727e-05 - mae: 0.0028\n",
      "Epoch 468/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.7616e-05 - mae: 0.0038\n",
      "Epoch 469/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.4915e-06 - mae: 0.0016\n",
      "Epoch 470/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.2924e-06 - mae: 0.0011\n",
      "Epoch 471/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 3.4698e-06 - mae: 0.0013\n",
      "Epoch 472/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2728e-05 - mae: 0.0023\n",
      "Epoch 473/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.1943e-05 - mae: 0.0057\n",
      "Epoch 474/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.2784e-06 - mae: 0.0012\n",
      "Epoch 475/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.7157e-06 - mae: 0.0016\n",
      "Epoch 476/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.4938e-06 - mae: 0.0013\n",
      "Epoch 477/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.3362e-06 - mae: 0.0017\n",
      "Epoch 478/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.4956e-05 - mae: 0.0048\n",
      "Epoch 479/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.1298e-05 - mae: 0.0039\n",
      "Epoch 480/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 3.0571e-06 - mae: 7.7905e-04\n",
      "Epoch 481/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 4.7537e-06 - mae: 0.0014\n",
      "Epoch 482/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 4.1689e-06 - mae: 0.0014\n",
      "Epoch 483/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1986e-05 - mae: 0.0031\n",
      "Epoch 484/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.6767e-05 - mae: 0.0045\n",
      "Epoch 485/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.4834e-06 - mae: 0.0010\n",
      "Epoch 486/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 2.3056e-05 - mae: 0.0039\n",
      "Epoch 487/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.6368e-05 - mae: 0.0043\n",
      "Epoch 488/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 5.9238e-06 - mae: 0.0012\n",
      "Epoch 489/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.0029e-06 - mae: 0.0019\n",
      "Epoch 490/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.5198e-06 - mae: 0.0013\n",
      "Epoch 491/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.3111e-05 - mae: 0.0029\n",
      "Epoch 492/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.9404e-05 - mae: 0.0039\n",
      "Epoch 493/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.4303e-05 - mae: 0.0033\n",
      "Epoch 494/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.8087e-06 - mae: 0.0015\n",
      "Epoch 495/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.0948e-06 - mae: 0.0017\n",
      "Epoch 496/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.8460e-06 - mae: 0.0013\n",
      "Epoch 497/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.4675e-05 - mae: 0.0041\n",
      "Epoch 498/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.7663e-05 - mae: 0.0043\n",
      "Epoch 499/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 2.0693e-05 - mae: 0.0038\n",
      "Epoch 500/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.2257e-06 - mae: 0.0017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae87d15070>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = X_train, y = y_train, epochs = 500) \n",
    "\n",
    "# Note we haven't implemented the batch_size.\n",
    "# can set verbose=0 to turn on silent mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c5fb25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af1fc99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.820395810791524e-06, 0.0019054260337725282]\n",
      "[0.0018629400292411447, 0.015291032381355762]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_train, y_train, verbose=0)) # The training error\n",
    "print(model.evaluate(X_test, y_test, verbose=0))   # The test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dde28ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38602355],\n",
       "       [0.40384185],\n",
       "       [0.38875455],\n",
       "       [0.4244489 ],\n",
       "       [0.42821515],\n",
       "       [0.45282054],\n",
       "       [0.66882527],\n",
       "       [0.38639536],\n",
       "       [1.1480159 ],\n",
       "       [4.487044  ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = model.predict(X_test)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f15efdfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct Entropy</th>\n",
       "      <th>Model Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.387119</td>\n",
       "      <td>0.386024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.405198</td>\n",
       "      <td>0.403842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.389909</td>\n",
       "      <td>0.388755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.425916</td>\n",
       "      <td>0.424449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.429691</td>\n",
       "      <td>0.428215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.454304</td>\n",
       "      <td>0.452821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.670638</td>\n",
       "      <td>0.668825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.387500</td>\n",
       "      <td>0.386395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.153660</td>\n",
       "      <td>1.148016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.623360</td>\n",
       "      <td>4.487044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Correct Entropy  Model Predictions\n",
       "0         0.387119           0.386024\n",
       "1         0.405198           0.403842\n",
       "2         0.389909           0.388755\n",
       "3         0.425916           0.424449\n",
       "4         0.429691           0.428215\n",
       "5         0.454304           0.452821\n",
       "6         0.670638           0.668825\n",
       "7         0.387500           0.386395\n",
       "8         1.153660           1.148016\n",
       "9         4.623360           4.487044"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = pd.DataFrame(test_predictions)\n",
    "test_pred.columns = ['Model Predictions']\n",
    "\n",
    "pred_df = pd.DataFrame(y_test)\n",
    "pred_df_reset_index = pred_df.reset_index(drop=True)\n",
    "\n",
    "df_compare = pd.concat([pred_df_reset_index, test_pred], axis = 1)\n",
    "df_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de702ba0",
   "metadata": {},
   "source": [
    "### Two Intervals at Small $x$ Expansion (First Order in $x$)(Varying x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e609bc85",
   "metadata": {},
   "source": [
    "Note that in this case we can also fix $x$ while varying $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00501cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\") \n",
    "# to restart the kernel, prevent from reusing any trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4dce69",
   "metadata": {},
   "source": [
    "$k$ is only up to 100.\n",
    "\n",
    "$x=0.1, x<0.6, x+=0.005$\n",
    "\n",
    "10000 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b60dedd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct Entropy</th>\n",
       "      <th>Approx Entropy</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.075677</td>\n",
       "      <td>1.046734</td>\n",
       "      <td>0.481315</td>\n",
       "      <td>0.154562</td>\n",
       "      <td>0.082949</td>\n",
       "      <td>0.055171</td>\n",
       "      <td>0.040093</td>\n",
       "      <td>0.030395</td>\n",
       "      <td>0.023676</td>\n",
       "      <td>0.018858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.085920</td>\n",
       "      <td>1.056349</td>\n",
       "      <td>0.484591</td>\n",
       "      <td>0.155865</td>\n",
       "      <td>0.083616</td>\n",
       "      <td>0.055637</td>\n",
       "      <td>0.040484</td>\n",
       "      <td>0.030739</td>\n",
       "      <td>0.023978</td>\n",
       "      <td>0.019119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.095533</td>\n",
       "      <td>1.065361</td>\n",
       "      <td>0.487636</td>\n",
       "      <td>0.157080</td>\n",
       "      <td>0.084237</td>\n",
       "      <td>0.056072</td>\n",
       "      <td>0.040849</td>\n",
       "      <td>0.031061</td>\n",
       "      <td>0.024261</td>\n",
       "      <td>0.019365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.104571</td>\n",
       "      <td>1.073823</td>\n",
       "      <td>0.490474</td>\n",
       "      <td>0.158216</td>\n",
       "      <td>0.084818</td>\n",
       "      <td>0.056477</td>\n",
       "      <td>0.041190</td>\n",
       "      <td>0.031363</td>\n",
       "      <td>0.024528</td>\n",
       "      <td>0.019598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.113085</td>\n",
       "      <td>1.081785</td>\n",
       "      <td>0.493123</td>\n",
       "      <td>0.159279</td>\n",
       "      <td>0.085361</td>\n",
       "      <td>0.056857</td>\n",
       "      <td>0.041510</td>\n",
       "      <td>0.031647</td>\n",
       "      <td>0.024780</td>\n",
       "      <td>0.019818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.213792</td>\n",
       "      <td>1.169927</td>\n",
       "      <td>0.511237</td>\n",
       "      <td>0.162869</td>\n",
       "      <td>0.086705</td>\n",
       "      <td>0.059177</td>\n",
       "      <td>0.045019</td>\n",
       "      <td>0.035820</td>\n",
       "      <td>0.029100</td>\n",
       "      <td>0.023948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.211492</td>\n",
       "      <td>1.167713</td>\n",
       "      <td>0.510309</td>\n",
       "      <td>0.162413</td>\n",
       "      <td>0.086478</td>\n",
       "      <td>0.059058</td>\n",
       "      <td>0.044951</td>\n",
       "      <td>0.035777</td>\n",
       "      <td>0.029069</td>\n",
       "      <td>0.023923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.209127</td>\n",
       "      <td>1.165439</td>\n",
       "      <td>0.509356</td>\n",
       "      <td>0.161947</td>\n",
       "      <td>0.086246</td>\n",
       "      <td>0.058937</td>\n",
       "      <td>0.044883</td>\n",
       "      <td>0.035733</td>\n",
       "      <td>0.029036</td>\n",
       "      <td>0.023896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.206697</td>\n",
       "      <td>1.163103</td>\n",
       "      <td>0.508379</td>\n",
       "      <td>0.161471</td>\n",
       "      <td>0.086010</td>\n",
       "      <td>0.058814</td>\n",
       "      <td>0.044812</td>\n",
       "      <td>0.035687</td>\n",
       "      <td>0.029003</td>\n",
       "      <td>0.023869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.204201</td>\n",
       "      <td>1.160705</td>\n",
       "      <td>0.507376</td>\n",
       "      <td>0.160984</td>\n",
       "      <td>0.085768</td>\n",
       "      <td>0.058689</td>\n",
       "      <td>0.044741</td>\n",
       "      <td>0.035641</td>\n",
       "      <td>0.028968</td>\n",
       "      <td>0.023841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Correct Entropy  Approx Entropy         1         2         3         4  \\\n",
       "0          1.075677        1.046734  0.481315  0.154562  0.082949  0.055171   \n",
       "1          1.085920        1.056349  0.484591  0.155865  0.083616  0.055637   \n",
       "2          1.095533        1.065361  0.487636  0.157080  0.084237  0.056072   \n",
       "3          1.104571        1.073823  0.490474  0.158216  0.084818  0.056477   \n",
       "4          1.113085        1.081785  0.493123  0.159279  0.085361  0.056857   \n",
       "..              ...             ...       ...       ...       ...       ...   \n",
       "95         1.213792        1.169927  0.511237  0.162869  0.086705  0.059177   \n",
       "96         1.211492        1.167713  0.510309  0.162413  0.086478  0.059058   \n",
       "97         1.209127        1.165439  0.509356  0.161947  0.086246  0.058937   \n",
       "98         1.206697        1.163103  0.508379  0.161471  0.086010  0.058814   \n",
       "99         1.204201        1.160705  0.507376  0.160984  0.085768  0.058689   \n",
       "\n",
       "           5         6         7         8  ...        91        92        93  \\\n",
       "0   0.040093  0.030395  0.023676  0.018858  ...  0.000265  0.000260  0.000255   \n",
       "1   0.040484  0.030739  0.023978  0.019119  ...  0.000270  0.000265  0.000260   \n",
       "2   0.040849  0.031061  0.024261  0.019365  ...  0.000275  0.000270  0.000265   \n",
       "3   0.041190  0.031363  0.024528  0.019598  ...  0.000280  0.000274  0.000269   \n",
       "4   0.041510  0.031647  0.024780  0.019818  ...  0.000284  0.000279  0.000273   \n",
       "..       ...       ...       ...       ...  ...       ...       ...       ...   \n",
       "95  0.045019  0.035820  0.029100  0.023948  ...  0.000380  0.000372  0.000366   \n",
       "96  0.044951  0.035777  0.029069  0.023923  ...  0.000379  0.000372  0.000365   \n",
       "97  0.044883  0.035733  0.029036  0.023896  ...  0.000378  0.000371  0.000364   \n",
       "98  0.044812  0.035687  0.029003  0.023869  ...  0.000377  0.000370  0.000364   \n",
       "99  0.044741  0.035641  0.028968  0.023841  ...  0.000377  0.000370  0.000363   \n",
       "\n",
       "          94        95        96        97        98        99       100  \n",
       "0   0.000250  0.000246  0.000241  0.000237  0.000233  0.000229  0.000225  \n",
       "1   0.000255  0.000250  0.000246  0.000241  0.000237  0.000233  0.000229  \n",
       "2   0.000260  0.000255  0.000250  0.000246  0.000241  0.000237  0.000233  \n",
       "3   0.000264  0.000259  0.000255  0.000250  0.000246  0.000241  0.000237  \n",
       "4   0.000268  0.000263  0.000259  0.000254  0.000249  0.000245  0.000241  \n",
       "..       ...       ...       ...       ...       ...       ...       ...  \n",
       "95  0.000359  0.000353  0.000346  0.000340  0.000334  0.000329  0.000323  \n",
       "96  0.000358  0.000352  0.000346  0.000340  0.000334  0.000328  0.000322  \n",
       "97  0.000358  0.000351  0.000345  0.000339  0.000333  0.000327  0.000322  \n",
       "98  0.000357  0.000351  0.000344  0.000338  0.000332  0.000327  0.000321  \n",
       "99  0.000356  0.000350  0.000344  0.000338  0.000332  0.000326  0.000320  \n",
       "\n",
       "[100 rows x 102 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('Data_Two_Interval_Firstx.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb7434f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zxpet\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.775x0.755)\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we should check the data\n",
    "# If there are problems with data (e.g. extreme values, weired distribution), use Scaler in the next block\n",
    "\n",
    "print(sns.distplot(df['Correct Entropy']))\n",
    "# Safe to ignore warnings\n",
    "\n",
    "print(df.plot(y='Correct Entropy', use_index=True))\n",
    "\n",
    "print(df.reset_index().plot.scatter(x='index',y='Correct Entropy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41630321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.481315</td>\n",
       "      <td>0.154562</td>\n",
       "      <td>0.082949</td>\n",
       "      <td>0.055171</td>\n",
       "      <td>0.040093</td>\n",
       "      <td>0.030395</td>\n",
       "      <td>0.023676</td>\n",
       "      <td>0.018858</td>\n",
       "      <td>0.015328</td>\n",
       "      <td>0.012694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.484591</td>\n",
       "      <td>0.155865</td>\n",
       "      <td>0.083616</td>\n",
       "      <td>0.055637</td>\n",
       "      <td>0.040484</td>\n",
       "      <td>0.030739</td>\n",
       "      <td>0.023978</td>\n",
       "      <td>0.019119</td>\n",
       "      <td>0.015552</td>\n",
       "      <td>0.012886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.487636</td>\n",
       "      <td>0.157080</td>\n",
       "      <td>0.084237</td>\n",
       "      <td>0.056072</td>\n",
       "      <td>0.040849</td>\n",
       "      <td>0.031061</td>\n",
       "      <td>0.024261</td>\n",
       "      <td>0.019365</td>\n",
       "      <td>0.015764</td>\n",
       "      <td>0.013068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.490474</td>\n",
       "      <td>0.158216</td>\n",
       "      <td>0.084818</td>\n",
       "      <td>0.056477</td>\n",
       "      <td>0.041190</td>\n",
       "      <td>0.031363</td>\n",
       "      <td>0.024528</td>\n",
       "      <td>0.019598</td>\n",
       "      <td>0.015965</td>\n",
       "      <td>0.013240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.493123</td>\n",
       "      <td>0.159279</td>\n",
       "      <td>0.085361</td>\n",
       "      <td>0.056857</td>\n",
       "      <td>0.041510</td>\n",
       "      <td>0.031647</td>\n",
       "      <td>0.024780</td>\n",
       "      <td>0.019818</td>\n",
       "      <td>0.016155</td>\n",
       "      <td>0.013404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0  0.481315  0.154562  0.082949  0.055171  0.040093  0.030395  0.023676   \n",
       "1  0.484591  0.155865  0.083616  0.055637  0.040484  0.030739  0.023978   \n",
       "2  0.487636  0.157080  0.084237  0.056072  0.040849  0.031061  0.024261   \n",
       "3  0.490474  0.158216  0.084818  0.056477  0.041190  0.031363  0.024528   \n",
       "4  0.493123  0.159279  0.085361  0.056857  0.041510  0.031647  0.024780   \n",
       "\n",
       "          8         9        10  ...        91        92        93        94  \\\n",
       "0  0.018858  0.015328  0.012694  ...  0.000265  0.000260  0.000255  0.000250   \n",
       "1  0.019119  0.015552  0.012886  ...  0.000270  0.000265  0.000260  0.000255   \n",
       "2  0.019365  0.015764  0.013068  ...  0.000275  0.000270  0.000265  0.000260   \n",
       "3  0.019598  0.015965  0.013240  ...  0.000280  0.000274  0.000269  0.000264   \n",
       "4  0.019818  0.016155  0.013404  ...  0.000284  0.000279  0.000273  0.000268   \n",
       "\n",
       "         95        96        97        98        99       100  \n",
       "0  0.000246  0.000241  0.000237  0.000233  0.000229  0.000225  \n",
       "1  0.000250  0.000246  0.000241  0.000237  0.000233  0.000229  \n",
       "2  0.000255  0.000250  0.000246  0.000241  0.000237  0.000233  \n",
       "3  0.000259  0.000255  0.000250  0.000246  0.000241  0.000237  \n",
       "4  0.000263  0.000259  0.000254  0.000249  0.000245  0.000241  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.drop(['Correct Entropy','Approx Entropy'], axis = 1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1befcf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 100)\n",
      "(10, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df1\n",
    "y = df['Correct Entropy']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state = 42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2838678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# We don't need to worry about the input dimensions, the layers will automatically infer input shape as the shape of \n",
    "# the first inputs they see.\n",
    "\n",
    "# Write the layers separately such that it is easy to comment out each layer\n",
    "# Note we don't need to worry about input/output sizes that connect each layer, Keras will handle it automatically.\n",
    "\n",
    "model.add(Dense(4, activation = 'relu'))\n",
    "#model.add(Dense(4, activation = 'relu'))\n",
    "#model.add(Dense(4, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(1)) \n",
    "# The final layer has only 1 node as we are predicting a single value of correct entropy\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'mse', metrics=[\"mae\"]) \n",
    "#Root Mean Squared Propagation as optimizer and  Mean Squared Error as loss fun\n",
    "\n",
    "# Note we can have customized setup (have to build from scratch):\n",
    "# model.compilte(optimizer = keras.optimizers.RMSprop(learning_rate=1e-4, loss = my_custom_loss, \n",
    "# metrics=[my_custom_metric_1, my_custom_metric_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9476c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.4916 - mae: 1.2206\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.4746 - mae: 1.2136\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 503us/step - loss: 1.4628 - mae: 1.2088\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.4528 - mae: 1.2046\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.4437 - mae: 1.2008\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.4352 - mae: 1.1973\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.4270 - mae: 1.1938\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 1.4189 - mae: 1.1905\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.4109 - mae: 1.1871\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.4028 - mae: 1.1837\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.3945 - mae: 1.1802\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.3862 - mae: 1.1766\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.3777 - mae: 1.1730\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.3691 - mae: 1.1694\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.3605 - mae: 1.1657\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 493us/step - loss: 1.3517 - mae: 1.1619\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.3429 - mae: 1.1581\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.3340 - mae: 1.1543\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.3251 - mae: 1.1504\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.3160 - mae: 1.1464\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.3069 - mae: 1.1425\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.2978 - mae: 1.1385\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.2886 - mae: 1.1344\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.2793 - mae: 1.1303\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.2699 - mae: 1.1262\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2605 - mae: 1.1220\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.2510 - mae: 1.1177\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 1.2415 - mae: 1.1135\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2320 - mae: 1.1092\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2223 - mae: 1.1048\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2126 - mae: 1.1004\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.2029 - mae: 1.0960\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.1931 - mae: 1.0915\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.1833 - mae: 1.0870\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.1734 - mae: 1.0825\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.1635 - mae: 1.0779\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1535 - mae: 1.0732\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1435 - mae: 1.0686\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.1335 - mae: 1.0638\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1234 - mae: 1.0591\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.1132 - mae: 1.0543\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.1031 - mae: 1.0495\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.0928 - mae: 1.0446\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.0826 - mae: 1.0397\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.0723 - mae: 1.0347\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0620 - mae: 1.0297\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.0517 - mae: 1.0247\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0413 - mae: 1.0196\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0309 - mae: 1.0145\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.0205 - mae: 1.0094\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0100 - mae: 1.0042\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.9995 - mae: 0.9990\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.9890 - mae: 0.9937\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.9785 - mae: 0.9884\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.9680 - mae: 0.9830\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.9574 - mae: 0.9776\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.9468 - mae: 0.9722\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.9362 - mae: 0.9668\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.9256 - mae: 0.9613\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.9150 - mae: 0.9557\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.9044 - mae: 0.9502\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.8937 - mae: 0.9445\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.8831 - mae: 0.9389\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.8724 - mae: 0.9332\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.8617 - mae: 0.9274\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.8511 - mae: 0.9217\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.8404 - mae: 0.9159\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.8297 - mae: 0.9100\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.8190 - mae: 0.9041\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.8083 - mae: 0.8982\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.7977 - mae: 0.8922\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.7870 - mae: 0.8862\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.7763 - mae: 0.8802\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.7657 - mae: 0.8741\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.7550 - mae: 0.8680\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.7444 - mae: 0.8619\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.7338 - mae: 0.8557\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.7231 - mae: 0.8495\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.7125 - mae: 0.8432\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 501us/step - loss: 0.7020 - mae: 0.8369\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.6914 - mae: 0.8306\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.6809 - mae: 0.8242\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.6703 - mae: 0.8178\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.6598 - mae: 0.8114\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.6493 - mae: 0.8049\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 0.6389 - mae: 0.7984\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.6284 - mae: 0.7918\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.6181 - mae: 0.7852\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.6077 - mae: 0.7786\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.5973 - mae: 0.7719\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.5870 - mae: 0.7652\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 0.5768 - mae: 0.7585\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.5665 - mae: 0.7517\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.5563 - mae: 0.7449\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.5462 - mae: 0.7381\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.5361 - mae: 0.7312\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.5260 - mae: 0.7243\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.5160 - mae: 0.7173\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.5060 - mae: 0.7103\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.4961 - mae: 0.7033\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.4862 - mae: 0.6962\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.4764 - mae: 0.6892\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.4666 - mae: 0.6821\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.4569 - mae: 0.6749\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.4472 - mae: 0.6677\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.4376 - mae: 0.6605\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.4281 - mae: 0.6532\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.4186 - mae: 0.6459\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.4092 - mae: 0.6386\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.3998 - mae: 0.6312\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.3905 - mae: 0.6238\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.3813 - mae: 0.6164\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.3721 - mae: 0.6089\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.3631 - mae: 0.6014\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.3540 - mae: 0.5939\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.3451 - mae: 0.5863\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.3363 - mae: 0.5788\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.3275 - mae: 0.5711\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.3188 - mae: 0.5634\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.3102 - mae: 0.5558\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.3017 - mae: 0.5480\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.2932 - mae: 0.5403\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.2849 - mae: 0.5325\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.2766 - mae: 0.5247\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.2684 - mae: 0.5169\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.2604 - mae: 0.5090\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.2524 - mae: 0.5011\n",
      "Epoch 128/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.2445 - mae: 0.4931\n",
      "Epoch 129/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.2367 - mae: 0.4852\n",
      "Epoch 130/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.2290 - mae: 0.4772\n",
      "Epoch 131/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.2214 - mae: 0.4692\n",
      "Epoch 132/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.2139 - mae: 0.4611\n",
      "Epoch 133/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.2065 - mae: 0.4530\n",
      "Epoch 134/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.1992 - mae: 0.4450\n",
      "Epoch 135/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1920 - mae: 0.4368\n",
      "Epoch 136/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1849 - mae: 0.4287\n",
      "Epoch 137/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.1780 - mae: 0.4205\n",
      "Epoch 138/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.1711 - mae: 0.4123\n",
      "Epoch 139/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1644 - mae: 0.4040\n",
      "Epoch 140/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1578 - mae: 0.3958\n",
      "Epoch 141/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1513 - mae: 0.3874\n",
      "Epoch 142/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1450 - mae: 0.3792\n",
      "Epoch 143/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1387 - mae: 0.3709\n",
      "Epoch 144/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1326 - mae: 0.3625\n",
      "Epoch 145/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1266 - mae: 0.3542\n",
      "Epoch 146/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1207 - mae: 0.3458\n",
      "Epoch 147/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.1150 - mae: 0.3374\n",
      "Epoch 148/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1094 - mae: 0.3290\n",
      "Epoch 149/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1039 - mae: 0.3205\n",
      "Epoch 150/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0985 - mae: 0.3121\n",
      "Epoch 151/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0933 - mae: 0.3036\n",
      "Epoch 152/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0882 - mae: 0.2951\n",
      "Epoch 153/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0833 - mae: 0.2866\n",
      "Epoch 154/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0785 - mae: 0.2781\n",
      "Epoch 155/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0738 - mae: 0.2697\n",
      "Epoch 156/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0693 - mae: 0.2611\n",
      "Epoch 157/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0649 - mae: 0.2525\n",
      "Epoch 158/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0606 - mae: 0.2440\n",
      "Epoch 159/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0565 - mae: 0.2355\n",
      "Epoch 160/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0526 - mae: 0.2270\n",
      "Epoch 161/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0488 - mae: 0.2184\n",
      "Epoch 162/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0451 - mae: 0.2099\n",
      "Epoch 163/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0416 - mae: 0.2015\n",
      "Epoch 164/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0382 - mae: 0.1929\n",
      "Epoch 165/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0350 - mae: 0.1844\n",
      "Epoch 166/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0320 - mae: 0.1760\n",
      "Epoch 167/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0290 - mae: 0.1675\n",
      "Epoch 168/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0263 - mae: 0.1591\n",
      "Epoch 169/500\n",
      "3/3 [==============================] - 0s 510us/step - loss: 0.0237 - mae: 0.1507\n",
      "Epoch 170/500\n",
      "3/3 [==============================] - 0s 503us/step - loss: 0.0212 - mae: 0.1424\n",
      "Epoch 171/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0189 - mae: 0.1341\n",
      "Epoch 172/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 499us/step - loss: 0.0168 - mae: 0.1258\n",
      "Epoch 173/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0148 - mae: 0.1176\n",
      "Epoch 174/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0130 - mae: 0.1096\n",
      "Epoch 175/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0113 - mae: 0.1016\n",
      "Epoch 176/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0097 - mae: 0.0939\n",
      "Epoch 177/500\n",
      "3/3 [==============================] - 0s 495us/step - loss: 0.0083 - mae: 0.0863\n",
      "Epoch 178/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0070 - mae: 0.0791\n",
      "Epoch 179/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0059 - mae: 0.0723\n",
      "Epoch 180/500\n",
      "3/3 [==============================] - 0s 872us/step - loss: 0.0049 - mae: 0.0659\n",
      "Epoch 181/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0041 - mae: 0.0599\n",
      "Epoch 182/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0033 - mae: 0.0543\n",
      "Epoch 183/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0027 - mae: 0.0489\n",
      "Epoch 184/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0022 - mae: 0.0439\n",
      "Epoch 185/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0018 - mae: 0.0395\n",
      "Epoch 186/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0015 - mae: 0.0356\n",
      "Epoch 187/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0013 - mae: 0.0323\n",
      "Epoch 188/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0011 - mae: 0.0295\n",
      "Epoch 189/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0010 - mae: 0.0274\n",
      "Epoch 190/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.4805e-04 - mae: 0.0257\n",
      "Epoch 191/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.9772e-04 - mae: 0.0243\n",
      "Epoch 192/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.8410e-04 - mae: 0.0231\n",
      "Epoch 193/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.7410e-04 - mae: 0.0228\n",
      "Epoch 194/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.7033e-04 - mae: 0.0225\n",
      "Epoch 195/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.7002e-04 - mae: 0.0226\n",
      "Epoch 196/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.6464e-04 - mae: 0.0220\n",
      "Epoch 197/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.6934e-04 - mae: 0.0222\n",
      "Epoch 198/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.6925e-04 - mae: 0.0218\n",
      "Epoch 199/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.7227e-04 - mae: 0.0215\n",
      "Epoch 200/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.6458e-04 - mae: 0.0224\n",
      "Epoch 201/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.8728e-04 - mae: 0.0229\n",
      "Epoch 202/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.6758e-04 - mae: 0.0211\n",
      "Epoch 203/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.7940e-04 - mae: 0.0225\n",
      "Epoch 204/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.6238e-04 - mae: 0.0214\n",
      "Epoch 205/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.8371e-04 - mae: 0.0228\n",
      "Epoch 206/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.7607e-04 - mae: 0.0219\n",
      "Epoch 207/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.7670e-04 - mae: 0.0215\n",
      "Epoch 208/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.6634e-04 - mae: 0.0215\n",
      "Epoch 209/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.7007e-04 - mae: 0.0218\n",
      "Epoch 210/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.6120e-04 - mae: 0.0222\n",
      "Epoch 211/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.6321e-04 - mae: 0.0222\n",
      "Epoch 212/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.8159e-04 - mae: 0.0211\n",
      "Epoch 213/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.7002e-04 - mae: 0.0229\n",
      "Epoch 214/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.9982e-04 - mae: 0.0215\n",
      "Epoch 215/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.7214e-04 - mae: 0.0224\n",
      "Epoch 216/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.6745e-04 - mae: 0.0220\n",
      "Epoch 217/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.6499e-04 - mae: 0.0221\n",
      "Epoch 218/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.7228e-04 - mae: 0.0215\n",
      "Epoch 219/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.6562e-04 - mae: 0.0219\n",
      "Epoch 220/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.5558e-04 - mae: 0.0224\n",
      "Epoch 221/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.5241e-04 - mae: 0.0217\n",
      "Epoch 222/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.5276e-04 - mae: 0.0221\n",
      "Epoch 223/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.5146e-04 - mae: 0.0216\n",
      "Epoch 224/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.7610e-04 - mae: 0.0224\n",
      "Epoch 225/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.9507e-04 - mae: 0.0220\n",
      "Epoch 226/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.5222e-04 - mae: 0.0224\n",
      "Epoch 227/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.6252e-04 - mae: 0.0215\n",
      "Epoch 228/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.4965e-04 - mae: 0.0219\n",
      "Epoch 229/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.6355e-04 - mae: 0.0220\n",
      "Epoch 230/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.7692e-04 - mae: 0.0216\n",
      "Epoch 231/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.4631e-04 - mae: 0.0213\n",
      "Epoch 232/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.5436e-04 - mae: 0.0223\n",
      "Epoch 233/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.5309e-04 - mae: 0.0218\n",
      "Epoch 234/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.6488e-04 - mae: 0.0213\n",
      "Epoch 235/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.5256e-04 - mae: 0.0230\n",
      "Epoch 236/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.7005e-04 - mae: 0.0217\n",
      "Epoch 237/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.4375e-04 - mae: 0.0220\n",
      "Epoch 238/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.6133e-04 - mae: 0.0221\n",
      "Epoch 239/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.4659e-04 - mae: 0.0212\n",
      "Epoch 240/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.4093e-04 - mae: 0.0216\n",
      "Epoch 241/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.3864e-04 - mae: 0.0214\n",
      "Epoch 242/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.7973e-04 - mae: 0.0221\n",
      "Epoch 243/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.4695e-04 - mae: 0.0217\n",
      "Epoch 244/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.4557e-04 - mae: 0.0216\n",
      "Epoch 245/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.4934e-04 - mae: 0.0217\n",
      "Epoch 246/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.4076e-04 - mae: 0.0215\n",
      "Epoch 247/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.4726e-04 - mae: 0.0219\n",
      "Epoch 248/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.6138e-04 - mae: 0.0216\n",
      "Epoch 249/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.5019e-04 - mae: 0.0212\n",
      "Epoch 250/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.3524e-04 - mae: 0.0215\n",
      "Epoch 251/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.6171e-04 - mae: 0.0219\n",
      "Epoch 252/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.4688e-04 - mae: 0.0205\n",
      "Epoch 253/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.4831e-04 - mae: 0.0230\n",
      "Epoch 254/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.4110e-04 - mae: 0.0211\n",
      "Epoch 255/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.4114e-04 - mae: 0.0213\n",
      "Epoch 256/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.2968e-04 - mae: 0.0218\n",
      "Epoch 257/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.5215e-04 - mae: 0.0222\n",
      "Epoch 258/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.4025e-04 - mae: 0.0211\n",
      "Epoch 259/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.3035e-04 - mae: 0.0218\n",
      "Epoch 260/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.4272e-04 - mae: 0.0214\n",
      "Epoch 261/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.2549e-04 - mae: 0.0216\n",
      "Epoch 262/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.2687e-04 - mae: 0.0216\n",
      "Epoch 263/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.2516e-04 - mae: 0.0210\n",
      "Epoch 264/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.3282e-04 - mae: 0.0211\n",
      "Epoch 265/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.3609e-04 - mae: 0.0214\n",
      "Epoch 266/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.4153e-04 - mae: 0.0227\n",
      "Epoch 267/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 8.4248e-04 - mae: 0.0214\n",
      "Epoch 268/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.3338e-04 - mae: 0.0210\n",
      "Epoch 269/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.2870e-04 - mae: 0.0214\n",
      "Epoch 270/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.3672e-04 - mae: 0.0206\n",
      "Epoch 271/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.2688e-04 - mae: 0.0223\n",
      "Epoch 272/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.3064e-04 - mae: 0.0213\n",
      "Epoch 273/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.2293e-04 - mae: 0.0215\n",
      "Epoch 274/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.1783e-04 - mae: 0.0216\n",
      "Epoch 275/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.2724e-04 - mae: 0.0214\n",
      "Epoch 276/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.4317e-04 - mae: 0.0212\n",
      "Epoch 277/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.1693e-04 - mae: 0.0215\n",
      "Epoch 278/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.1559e-04 - mae: 0.0211\n",
      "Epoch 279/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.1669e-04 - mae: 0.0212\n",
      "Epoch 280/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.6327e-04 - mae: 0.0223\n",
      "Epoch 281/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.3905e-04 - mae: 0.0208\n",
      "Epoch 282/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.2445e-04 - mae: 0.0224\n",
      "Epoch 283/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.2675e-04 - mae: 0.0214\n",
      "Epoch 284/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.4097e-04 - mae: 0.0214\n",
      "Epoch 285/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.1404e-04 - mae: 0.0209\n",
      "Epoch 286/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.1388e-04 - mae: 0.0210\n",
      "Epoch 287/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.1273e-04 - mae: 0.0212\n",
      "Epoch 288/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.1336e-04 - mae: 0.0213\n",
      "Epoch 289/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.1597e-04 - mae: 0.0217\n",
      "Epoch 290/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.1862e-04 - mae: 0.0219\n",
      "Epoch 291/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.1382e-04 - mae: 0.0213\n",
      "Epoch 292/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.6034e-04 - mae: 0.0219\n",
      "Epoch 293/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.1305e-04 - mae: 0.0214\n",
      "Epoch 294/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.1315e-04 - mae: 0.0213\n",
      "Epoch 295/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.1106e-04 - mae: 0.0212\n",
      "Epoch 296/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.1084e-04 - mae: 0.0205\n",
      "Epoch 297/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.2911e-04 - mae: 0.0223\n",
      "Epoch 298/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.2732e-04 - mae: 0.0208\n",
      "Epoch 299/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.0486e-04 - mae: 0.0213\n",
      "Epoch 300/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.1728e-04 - mae: 0.0214\n",
      "Epoch 301/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.1850e-04 - mae: 0.0214\n",
      "Epoch 302/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.3663e-04 - mae: 0.0217\n",
      "Epoch 303/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.0376e-04 - mae: 0.0206\n",
      "Epoch 304/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.0783e-04 - mae: 0.0214\n",
      "Epoch 305/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.0949e-04 - mae: 0.0211\n",
      "Epoch 306/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.0775e-04 - mae: 0.0209\n",
      "Epoch 307/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.9716e-04 - mae: 0.0211\n",
      "Epoch 308/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.1203e-04 - mae: 0.0218\n",
      "Epoch 309/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.1043e-04 - mae: 0.0206\n",
      "Epoch 310/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.0571e-04 - mae: 0.0210\n",
      "Epoch 311/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.0312e-04 - mae: 0.0216\n",
      "Epoch 312/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.2373e-04 - mae: 0.0213\n",
      "Epoch 313/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.0397e-04 - mae: 0.0209\n",
      "Epoch 314/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.1795e-04 - mae: 0.0212\n",
      "Epoch 315/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.9836e-04 - mae: 0.0211\n",
      "Epoch 316/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.9828e-04 - mae: 0.0210\n",
      "Epoch 317/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.0235e-04 - mae: 0.0209\n",
      "Epoch 318/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.1294e-04 - mae: 0.0210\n",
      "Epoch 319/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 7.9761e-04 - mae: 0.0207\n",
      "Epoch 320/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.1489e-04 - mae: 0.0219\n",
      "Epoch 321/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.8876e-04 - mae: 0.0211\n",
      "Epoch 322/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.0245e-04 - mae: 0.0205\n",
      "Epoch 323/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.0505e-04 - mae: 0.0213\n",
      "Epoch 324/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.0095e-04 - mae: 0.0210\n",
      "Epoch 325/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.8970e-04 - mae: 0.0215\n",
      "Epoch 326/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.8542e-04 - mae: 0.0208\n",
      "Epoch 327/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.8419e-04 - mae: 0.0211\n",
      "Epoch 328/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.9905e-04 - mae: 0.0212\n",
      "Epoch 329/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.8545e-04 - mae: 0.0211\n",
      "Epoch 330/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.0227e-04 - mae: 0.0212\n",
      "Epoch 331/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.8965e-04 - mae: 0.0220\n",
      "Epoch 332/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.3641e-04 - mae: 0.0214\n",
      "Epoch 333/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.8293e-04 - mae: 0.0206\n",
      "Epoch 334/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.9108e-04 - mae: 0.0206\n",
      "Epoch 335/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.7993e-04 - mae: 0.0213\n",
      "Epoch 336/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 998us/step - loss: 8.1600e-04 - mae: 0.0212\n",
      "Epoch 337/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.0189e-04 - mae: 0.0217\n",
      "Epoch 338/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.9369e-04 - mae: 0.0209\n",
      "Epoch 339/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.1211e-04 - mae: 0.0216\n",
      "Epoch 340/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.7884e-04 - mae: 0.0202\n",
      "Epoch 341/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.7515e-04 - mae: 0.0211\n",
      "Epoch 342/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.8328e-04 - mae: 0.0211\n",
      "Epoch 343/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.8183e-04 - mae: 0.0204\n",
      "Epoch 344/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.7774e-04 - mae: 0.0206\n",
      "Epoch 345/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.0142e-04 - mae: 0.0207\n",
      "Epoch 346/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.8196e-04 - mae: 0.0213\n",
      "Epoch 347/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.8135e-04 - mae: 0.0199\n",
      "Epoch 348/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.7634e-04 - mae: 0.0215\n",
      "Epoch 349/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.7165e-04 - mae: 0.0201\n",
      "Epoch 350/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.0056e-04 - mae: 0.0215\n",
      "Epoch 351/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.7009e-04 - mae: 0.0206\n",
      "Epoch 352/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.6937e-04 - mae: 0.0208\n",
      "Epoch 353/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.8981e-04 - mae: 0.0207\n",
      "Epoch 354/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.7686e-04 - mae: 0.0208\n",
      "Epoch 355/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.8047e-04 - mae: 0.0210\n",
      "Epoch 356/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.7024e-04 - mae: 0.0209\n",
      "Epoch 357/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.8346e-04 - mae: 0.0215\n",
      "Epoch 358/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.6885e-04 - mae: 0.0203\n",
      "Epoch 359/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.7927e-04 - mae: 0.0210\n",
      "Epoch 360/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.6535e-04 - mae: 0.0207\n",
      "Epoch 361/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.9288e-04 - mae: 0.0205\n",
      "Epoch 362/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.0107e-04 - mae: 0.0208\n",
      "Epoch 363/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.6750e-04 - mae: 0.0208\n",
      "Epoch 364/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.6345e-04 - mae: 0.0206\n",
      "Epoch 365/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.6255e-04 - mae: 0.0208\n",
      "Epoch 366/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.6090e-04 - mae: 0.0206\n",
      "Epoch 367/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.6875e-04 - mae: 0.0210\n",
      "Epoch 368/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.7648e-04 - mae: 0.0209\n",
      "Epoch 369/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.7412e-04 - mae: 0.0214\n",
      "Epoch 370/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.8550e-04 - mae: 0.0207\n",
      "Epoch 371/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.7262e-04 - mae: 0.0205\n",
      "Epoch 372/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.5761e-04 - mae: 0.0199\n",
      "Epoch 373/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.5535e-04 - mae: 0.0210\n",
      "Epoch 374/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.7754e-04 - mae: 0.0201\n",
      "Epoch 375/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.7132e-04 - mae: 0.0208\n",
      "Epoch 376/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.5491e-04 - mae: 0.0209\n",
      "Epoch 377/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.6344e-04 - mae: 0.0206\n",
      "Epoch 378/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.5581e-04 - mae: 0.0201\n",
      "Epoch 379/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.6379e-04 - mae: 0.0204\n",
      "Epoch 380/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.7894e-04 - mae: 0.0215\n",
      "Epoch 381/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.7513e-04 - mae: 0.0217\n",
      "Epoch 382/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.5593e-04 - mae: 0.0201\n",
      "Epoch 383/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.4923e-04 - mae: 0.0204\n",
      "Epoch 384/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.5270e-04 - mae: 0.0209\n",
      "Epoch 385/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.5362e-04 - mae: 0.0198\n",
      "Epoch 386/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.5150e-04 - mae: 0.0210\n",
      "Epoch 387/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.5277e-04 - mae: 0.0206\n",
      "Epoch 388/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.5125e-04 - mae: 0.0204\n",
      "Epoch 389/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.4700e-04 - mae: 0.0202\n",
      "Epoch 390/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.5532e-04 - mae: 0.0201\n",
      "Epoch 391/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.6387e-04 - mae: 0.0209\n",
      "Epoch 392/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.4279e-04 - mae: 0.0202\n",
      "Epoch 393/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 7.4295e-04 - mae: 0.0201\n",
      "Epoch 394/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.6437e-04 - mae: 0.0207\n",
      "Epoch 395/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.4945e-04 - mae: 0.0205\n",
      "Epoch 396/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.4644e-04 - mae: 0.0209\n",
      "Epoch 397/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 7.3901e-04 - mae: 0.0200\n",
      "Epoch 398/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.4385e-04 - mae: 0.0207\n",
      "Epoch 399/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.4824e-04 - mae: 0.0203\n",
      "Epoch 400/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 7.3998e-04 - mae: 0.0197\n",
      "Epoch 401/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.9228e-04 - mae: 0.0213\n",
      "Epoch 402/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.5581e-04 - mae: 0.0209\n",
      "Epoch 403/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.3497e-04 - mae: 0.0202\n",
      "Epoch 404/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.5257e-04 - mae: 0.0210\n",
      "Epoch 405/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.3948e-04 - mae: 0.0196\n",
      "Epoch 406/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.4421e-04 - mae: 0.0208\n",
      "Epoch 407/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.4407e-04 - mae: 0.0200\n",
      "Epoch 408/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.3134e-04 - mae: 0.0202\n",
      "Epoch 409/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.5101e-04 - mae: 0.0207\n",
      "Epoch 410/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.5683e-04 - mae: 0.0207\n",
      "Epoch 411/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.3081e-04 - mae: 0.0199\n",
      "Epoch 412/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.5346e-04 - mae: 0.0209\n",
      "Epoch 413/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.4084e-04 - mae: 0.0198\n",
      "Epoch 414/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.3856e-04 - mae: 0.0199\n",
      "Epoch 415/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.2764e-04 - mae: 0.0204\n",
      "Epoch 416/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.4266e-04 - mae: 0.0210\n",
      "Epoch 417/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.3462e-04 - mae: 0.0192\n",
      "Epoch 418/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 499us/step - loss: 7.3863e-04 - mae: 0.0212\n",
      "Epoch 419/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.3210e-04 - mae: 0.0198\n",
      "Epoch 420/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.2878e-04 - mae: 0.0204\n",
      "Epoch 421/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.2289e-04 - mae: 0.0205\n",
      "Epoch 422/500\n",
      "3/3 [==============================] - 0s 508us/step - loss: 7.2324e-04 - mae: 0.0200\n",
      "Epoch 423/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.5256e-04 - mae: 0.0203\n",
      "Epoch 424/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.4451e-04 - mae: 0.0202\n",
      "Epoch 425/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.3406e-04 - mae: 0.0209\n",
      "Epoch 426/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.2243e-04 - mae: 0.0204\n",
      "Epoch 427/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.2543e-04 - mae: 0.0200\n",
      "Epoch 428/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.3411e-04 - mae: 0.0197\n",
      "Epoch 429/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.2736e-04 - mae: 0.0208\n",
      "Epoch 430/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.1844e-04 - mae: 0.0198\n",
      "Epoch 431/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.2612e-04 - mae: 0.0203\n",
      "Epoch 432/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.1833e-04 - mae: 0.0191\n",
      "Epoch 433/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.3367e-04 - mae: 0.0212\n",
      "Epoch 434/500\n",
      "3/3 [==============================] - 0s 993us/step - loss: 7.3720e-04 - mae: 0.0203\n",
      "Epoch 435/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.1914e-04 - mae: 0.0193\n",
      "Epoch 436/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.1910e-04 - mae: 0.0199\n",
      "Epoch 437/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.1529e-04 - mae: 0.0203\n",
      "Epoch 438/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.3314e-04 - mae: 0.0211\n",
      "Epoch 439/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.3645e-04 - mae: 0.0194\n",
      "Epoch 440/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.2166e-04 - mae: 0.0207\n",
      "Epoch 441/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.1779e-04 - mae: 0.0196\n",
      "Epoch 442/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.1030e-04 - mae: 0.0195\n",
      "Epoch 443/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.1047e-04 - mae: 0.0202\n",
      "Epoch 444/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.0997e-04 - mae: 0.0198\n",
      "Epoch 445/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.6670e-04 - mae: 0.0212\n",
      "Epoch 446/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.1567e-04 - mae: 0.0205\n",
      "Epoch 447/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.2472e-04 - mae: 0.0200\n",
      "Epoch 448/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.5019e-04 - mae: 0.0195\n",
      "Epoch 449/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.0699e-04 - mae: 0.0203\n",
      "Epoch 450/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 7.1191e-04 - mae: 0.0197\n",
      "Epoch 451/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.0807e-04 - mae: 0.0201\n",
      "Epoch 452/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.1811e-04 - mae: 0.0200\n",
      "Epoch 453/500\n",
      "3/3 [==============================] - 0s 992us/step - loss: 7.1017e-04 - mae: 0.0199\n",
      "Epoch 454/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 7.1668e-04 - mae: 0.0200\n",
      "Epoch 455/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.3246e-04 - mae: 0.0207\n",
      "Epoch 456/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.1732e-04 - mae: 0.0197\n",
      "Epoch 457/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.0137e-04 - mae: 0.0197\n",
      "Epoch 458/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.1045e-04 - mae: 0.0203\n",
      "Epoch 459/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.1418e-04 - mae: 0.0192\n",
      "Epoch 460/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.0100e-04 - mae: 0.0204\n",
      "Epoch 461/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.0616e-04 - mae: 0.0196\n",
      "Epoch 462/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.0405e-04 - mae: 0.0192\n",
      "Epoch 463/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.9718e-04 - mae: 0.0200\n",
      "Epoch 464/500\n",
      "3/3 [==============================] - 0s 502us/step - loss: 7.1418e-04 - mae: 0.0198\n",
      "Epoch 465/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.3511e-04 - mae: 0.0206\n",
      "Epoch 466/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.9480e-04 - mae: 0.0195\n",
      "Epoch 467/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.0786e-04 - mae: 0.0199\n",
      "Epoch 468/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.9643e-04 - mae: 0.0197\n",
      "Epoch 469/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.9562e-04 - mae: 0.0196\n",
      "Epoch 470/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.9294e-04 - mae: 0.0201\n",
      "Epoch 471/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 6.9782e-04 - mae: 0.0187\n",
      "Epoch 472/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.1793e-04 - mae: 0.0212\n",
      "Epoch 473/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.0380e-04 - mae: 0.0196\n",
      "Epoch 474/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 6.9701e-04 - mae: 0.0198\n",
      "Epoch 475/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 6.9478e-04 - mae: 0.0194\n",
      "Epoch 476/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.2487e-04 - mae: 0.0206\n",
      "Epoch 477/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.9232e-04 - mae: 0.0192\n",
      "Epoch 478/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.8888e-04 - mae: 0.0194\n",
      "Epoch 479/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.1113e-04 - mae: 0.0200\n",
      "Epoch 480/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.9266e-04 - mae: 0.0195\n",
      "Epoch 481/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.9330e-04 - mae: 0.0199\n",
      "Epoch 482/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.0584e-04 - mae: 0.0200\n",
      "Epoch 483/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.9717e-04 - mae: 0.0194\n",
      "Epoch 484/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.8823e-04 - mae: 0.0194\n",
      "Epoch 485/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.8977e-04 - mae: 0.0198\n",
      "Epoch 486/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 6.9958e-04 - mae: 0.0200\n",
      "Epoch 487/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 6.9088e-04 - mae: 0.0189\n",
      "Epoch 488/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.9485e-04 - mae: 0.0198\n",
      "Epoch 489/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.8146e-04 - mae: 0.0199\n",
      "Epoch 490/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.9209e-04 - mae: 0.0192\n",
      "Epoch 491/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.9089e-04 - mae: 0.0201\n",
      "Epoch 492/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.7838e-04 - mae: 0.0195\n",
      "Epoch 493/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.1163e-04 - mae: 0.0201\n",
      "Epoch 494/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.8153e-04 - mae: 0.0195\n",
      "Epoch 495/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.9878e-04 - mae: 0.0197\n",
      "Epoch 496/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.9867e-04 - mae: 0.0206\n",
      "Epoch 497/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.7496e-04 - mae: 0.0193\n",
      "Epoch 498/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.7744e-04 - mae: 0.0196\n",
      "Epoch 499/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.7599e-04 - mae: 0.0193\n",
      "Epoch 500/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 7.3554e-04 - mae: 0.0194\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "3/3 [==============================] - 0s 498us/step - loss: 6.7817e-04 - mae: 0.0194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ae890fcb20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = X_train, y = y_train, epochs = 500) \n",
    "\n",
    "# Note we haven't implemented the batch_size.\n",
    "# can set verbose=0 to turn on silent mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33fbf686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1057d79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0006751315668225288, 0.01997135952115059]\n",
      "[0.0012092717224732041, 0.026368319988250732]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_train, y_train, verbose=0)) # The training error\n",
    "print(model.evaluate(X_test, y_test, verbose=0))   # The test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cccdb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.22571  ],\n",
       "       [1.2331102],\n",
       "       [1.2312996],\n",
       "       [1.2315612],\n",
       "       [1.2312443],\n",
       "       [1.2292063],\n",
       "       [1.2151873],\n",
       "       [1.2273164],\n",
       "       [1.1949992],\n",
       "       [1.1650548]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = model.predict(X_test)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cf42115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct Entropy</th>\n",
       "      <th>Model Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.236597</td>\n",
       "      <td>1.225710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.256971</td>\n",
       "      <td>1.233110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.251861</td>\n",
       "      <td>1.231300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.252892</td>\n",
       "      <td>1.231561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.252051</td>\n",
       "      <td>1.231244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.246620</td>\n",
       "      <td>1.229206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.209142</td>\n",
       "      <td>1.215187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.240973</td>\n",
       "      <td>1.227316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.155256</td>\n",
       "      <td>1.194999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.075677</td>\n",
       "      <td>1.165055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Correct Entropy  Model Predictions\n",
       "0         1.236597           1.225710\n",
       "1         1.256971           1.233110\n",
       "2         1.251861           1.231300\n",
       "3         1.252892           1.231561\n",
       "4         1.252051           1.231244\n",
       "5         1.246620           1.229206\n",
       "6         1.209142           1.215187\n",
       "7         1.240973           1.227316\n",
       "8         1.155256           1.194999\n",
       "9         1.075677           1.165055"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = pd.DataFrame(test_predictions)\n",
    "test_pred.columns = ['Model Predictions']\n",
    "\n",
    "pred_df = pd.DataFrame(y_test)\n",
    "pred_df_reset_index = pred_df.reset_index(drop=True)\n",
    "\n",
    "df_compare = pd.concat([pred_df_reset_index, test_pred], axis = 1)\n",
    "df_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736cc2fc",
   "metadata": {},
   "source": [
    "### Two Intervals at Small $x$ Expansion (Second Order in $x$)(Varying $x$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cc8c02",
   "metadata": {},
   "source": [
    "Note that in this case we can also fix $x$ while varying $\\alpha$.\n",
    "\n",
    "Actually we have analytic result from (arXiv:1312.5740)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b18989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\") \n",
    "# to restart the kernel, prevent from reusing any trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8342e6",
   "metadata": {},
   "source": [
    "$k$ is only up to 100.\n",
    "\n",
    "$x=0.1, x<0.6, x+=0.005$\n",
    "\n",
    "10000 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "098e564d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct Entropy</th>\n",
       "      <th>Approx Entropy</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.734460</td>\n",
       "      <td>0.725126</td>\n",
       "      <td>0.423867</td>\n",
       "      <td>0.111389</td>\n",
       "      <td>0.048338</td>\n",
       "      <td>0.027470</td>\n",
       "      <td>0.018160</td>\n",
       "      <td>0.013099</td>\n",
       "      <td>0.009976</td>\n",
       "      <td>0.007885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.742817</td>\n",
       "      <td>0.733292</td>\n",
       "      <td>0.427486</td>\n",
       "      <td>0.112914</td>\n",
       "      <td>0.049085</td>\n",
       "      <td>0.027899</td>\n",
       "      <td>0.018440</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.010129</td>\n",
       "      <td>0.008007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.750508</td>\n",
       "      <td>0.740806</td>\n",
       "      <td>0.430799</td>\n",
       "      <td>0.114319</td>\n",
       "      <td>0.049776</td>\n",
       "      <td>0.028296</td>\n",
       "      <td>0.018700</td>\n",
       "      <td>0.013486</td>\n",
       "      <td>0.010272</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.757592</td>\n",
       "      <td>0.747726</td>\n",
       "      <td>0.433836</td>\n",
       "      <td>0.115614</td>\n",
       "      <td>0.050415</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>0.018940</td>\n",
       "      <td>0.013659</td>\n",
       "      <td>0.010403</td>\n",
       "      <td>0.008225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.764122</td>\n",
       "      <td>0.754101</td>\n",
       "      <td>0.436621</td>\n",
       "      <td>0.116808</td>\n",
       "      <td>0.051006</td>\n",
       "      <td>0.029003</td>\n",
       "      <td>0.019163</td>\n",
       "      <td>0.013818</td>\n",
       "      <td>0.010525</td>\n",
       "      <td>0.008322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.588748</td>\n",
       "      <td>0.582431</td>\n",
       "      <td>0.360025</td>\n",
       "      <td>0.085256</td>\n",
       "      <td>0.035556</td>\n",
       "      <td>0.020043</td>\n",
       "      <td>0.013233</td>\n",
       "      <td>0.009527</td>\n",
       "      <td>0.007235</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.582010</td>\n",
       "      <td>0.575811</td>\n",
       "      <td>0.356815</td>\n",
       "      <td>0.084048</td>\n",
       "      <td>0.034998</td>\n",
       "      <td>0.019728</td>\n",
       "      <td>0.013026</td>\n",
       "      <td>0.009378</td>\n",
       "      <td>0.007121</td>\n",
       "      <td>0.005610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.575158</td>\n",
       "      <td>0.569077</td>\n",
       "      <td>0.353534</td>\n",
       "      <td>0.082820</td>\n",
       "      <td>0.034433</td>\n",
       "      <td>0.019410</td>\n",
       "      <td>0.012818</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>0.007006</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.568189</td>\n",
       "      <td>0.562228</td>\n",
       "      <td>0.350180</td>\n",
       "      <td>0.081574</td>\n",
       "      <td>0.033861</td>\n",
       "      <td>0.019088</td>\n",
       "      <td>0.012607</td>\n",
       "      <td>0.009076</td>\n",
       "      <td>0.006890</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.561103</td>\n",
       "      <td>0.555262</td>\n",
       "      <td>0.346751</td>\n",
       "      <td>0.080309</td>\n",
       "      <td>0.033282</td>\n",
       "      <td>0.018762</td>\n",
       "      <td>0.012394</td>\n",
       "      <td>0.008922</td>\n",
       "      <td>0.006773</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Correct Entropy  Approx Entropy         1         2         3         4  \\\n",
       "0          0.734460        0.725126  0.423867  0.111389  0.048338  0.027470   \n",
       "1          0.742817        0.733292  0.427486  0.112914  0.049085  0.027899   \n",
       "2          0.750508        0.740806  0.430799  0.114319  0.049776  0.028296   \n",
       "3          0.757592        0.747726  0.433836  0.115614  0.050415  0.028663   \n",
       "4          0.764122        0.754101  0.436621  0.116808  0.051006  0.029003   \n",
       "..              ...             ...       ...       ...       ...       ...   \n",
       "95         0.588748        0.582431  0.360025  0.085256  0.035556  0.020043   \n",
       "96         0.582010        0.575811  0.356815  0.084048  0.034998  0.019728   \n",
       "97         0.575158        0.569077  0.353534  0.082820  0.034433  0.019410   \n",
       "98         0.568189        0.562228  0.350180  0.081574  0.033861  0.019088   \n",
       "99         0.561103        0.555262  0.346751  0.080309  0.033282  0.018762   \n",
       "\n",
       "           5         6         7         8  ...        91        92        93  \\\n",
       "0   0.018160  0.013099  0.009976  0.007885  ...  0.000096  0.000094  0.000092   \n",
       "1   0.018440  0.013300  0.010129  0.008007  ...  0.000097  0.000096  0.000094   \n",
       "2   0.018700  0.013486  0.010272  0.008120  ...  0.000099  0.000097  0.000095   \n",
       "3   0.018940  0.013659  0.010403  0.008225  ...  0.000101  0.000099  0.000097   \n",
       "4   0.019163  0.013818  0.010525  0.008322  ...  0.000102  0.000100  0.000098   \n",
       "..       ...       ...       ...       ...  ...       ...       ...       ...   \n",
       "95  0.013233  0.009527  0.007235  0.005700  ...  0.000065  0.000064  0.000063   \n",
       "96  0.013026  0.009378  0.007121  0.005610  ...  0.000064  0.000063  0.000062   \n",
       "97  0.012818  0.009228  0.007006  0.005518  ...  0.000063  0.000062  0.000061   \n",
       "98  0.012607  0.009076  0.006890  0.005426  ...  0.000062  0.000061  0.000059   \n",
       "99  0.012394  0.008922  0.006773  0.005333  ...  0.000061  0.000059  0.000058   \n",
       "\n",
       "          94        95        96        97        98        99       100  \n",
       "0   0.000090  0.000088  0.000087  0.000085  0.000083  0.000082  0.000080  \n",
       "1   0.000092  0.000090  0.000088  0.000087  0.000085  0.000083  0.000082  \n",
       "2   0.000093  0.000092  0.000090  0.000088  0.000086  0.000085  0.000083  \n",
       "3   0.000095  0.000093  0.000091  0.000090  0.000088  0.000086  0.000085  \n",
       "4   0.000096  0.000094  0.000093  0.000091  0.000089  0.000087  0.000086  \n",
       "..       ...       ...       ...       ...       ...       ...       ...  \n",
       "95  0.000062  0.000060  0.000059  0.000058  0.000057  0.000056  0.000055  \n",
       "96  0.000060  0.000059  0.000058  0.000057  0.000056  0.000055  0.000054  \n",
       "97  0.000059  0.000058  0.000057  0.000056  0.000055  0.000054  0.000053  \n",
       "98  0.000058  0.000057  0.000056  0.000055  0.000054  0.000053  0.000052  \n",
       "99  0.000057  0.000056  0.000055  0.000054  0.000053  0.000052  0.000051  \n",
       "\n",
       "[100 rows x 102 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('Data_Two_Interval_Secondx.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63e00b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zxpet\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.775x0.755)\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we should check the data\n",
    "# If there are problems with data (e.g. extreme values, weired distribution), use Scaler in the next block\n",
    "\n",
    "print(sns.distplot(df['Correct Entropy']))\n",
    "# Safe to ignore warnings\n",
    "\n",
    "print(df.plot(y='Correct Entropy', use_index=True))\n",
    "\n",
    "print(df.reset_index().plot.scatter(x='index',y='Correct Entropy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c7f5884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct Entropy</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.734460</td>\n",
       "      <td>0.423867</td>\n",
       "      <td>0.111389</td>\n",
       "      <td>0.048338</td>\n",
       "      <td>0.027470</td>\n",
       "      <td>0.018160</td>\n",
       "      <td>0.013099</td>\n",
       "      <td>0.009976</td>\n",
       "      <td>0.007885</td>\n",
       "      <td>0.006405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.742817</td>\n",
       "      <td>0.427486</td>\n",
       "      <td>0.112914</td>\n",
       "      <td>0.049085</td>\n",
       "      <td>0.027899</td>\n",
       "      <td>0.018440</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.010129</td>\n",
       "      <td>0.008007</td>\n",
       "      <td>0.006506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.750508</td>\n",
       "      <td>0.430799</td>\n",
       "      <td>0.114319</td>\n",
       "      <td>0.049776</td>\n",
       "      <td>0.028296</td>\n",
       "      <td>0.018700</td>\n",
       "      <td>0.013486</td>\n",
       "      <td>0.010272</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.757592</td>\n",
       "      <td>0.433836</td>\n",
       "      <td>0.115614</td>\n",
       "      <td>0.050415</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>0.018940</td>\n",
       "      <td>0.013659</td>\n",
       "      <td>0.010403</td>\n",
       "      <td>0.008225</td>\n",
       "      <td>0.006684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.764122</td>\n",
       "      <td>0.436621</td>\n",
       "      <td>0.116808</td>\n",
       "      <td>0.051006</td>\n",
       "      <td>0.029003</td>\n",
       "      <td>0.019163</td>\n",
       "      <td>0.013818</td>\n",
       "      <td>0.010525</td>\n",
       "      <td>0.008322</td>\n",
       "      <td>0.006764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Correct Entropy         1         2         3         4         5  \\\n",
       "0         0.734460  0.423867  0.111389  0.048338  0.027470  0.018160   \n",
       "1         0.742817  0.427486  0.112914  0.049085  0.027899  0.018440   \n",
       "2         0.750508  0.430799  0.114319  0.049776  0.028296  0.018700   \n",
       "3         0.757592  0.433836  0.115614  0.050415  0.028663  0.018940   \n",
       "4         0.764122  0.436621  0.116808  0.051006  0.029003  0.019163   \n",
       "\n",
       "          6         7         8         9  ...        91        92        93  \\\n",
       "0  0.013099  0.009976  0.007885  0.006405  ...  0.000096  0.000094  0.000092   \n",
       "1  0.013300  0.010129  0.008007  0.006506  ...  0.000097  0.000096  0.000094   \n",
       "2  0.013486  0.010272  0.008120  0.006598  ...  0.000099  0.000097  0.000095   \n",
       "3  0.013659  0.010403  0.008225  0.006684  ...  0.000101  0.000099  0.000097   \n",
       "4  0.013818  0.010525  0.008322  0.006764  ...  0.000102  0.000100  0.000098   \n",
       "\n",
       "         94        95        96        97        98        99       100  \n",
       "0  0.000090  0.000088  0.000087  0.000085  0.000083  0.000082  0.000080  \n",
       "1  0.000092  0.000090  0.000088  0.000087  0.000085  0.000083  0.000082  \n",
       "2  0.000093  0.000092  0.000090  0.000088  0.000086  0.000085  0.000083  \n",
       "3  0.000095  0.000093  0.000091  0.000090  0.000088  0.000086  0.000085  \n",
       "4  0.000096  0.000094  0.000093  0.000091  0.000089  0.000087  0.000086  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.drop(['Approx Entropy'], axis = 1) # No correct entropy\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f05a3ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 101)\n",
      "(10, 101)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df1\n",
    "y = df['Correct Entropy']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state = 42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9de3a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# We don't need to worry about the input dimensions, the layers will automatically infer input shape as the shape of \n",
    "# the first inputs they see.\n",
    "\n",
    "# Write the layers separately such that it is easy to comment out each layer\n",
    "# Note we don't need to worry about input/output sizes that connect each layer, Keras will handle it automatically.\n",
    "\n",
    "model.add(Dense(4, activation = 'relu'))\n",
    "#model.add(Dense(4, activation = 'relu'))\n",
    "#model.add(Dense(4, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(1)) \n",
    "# The final layer has only 1 node as we are predicting a single value of correct entropy\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'mse', metrics=[\"mae\"]) \n",
    "#Root Mean Squared Propagation as optimizer and  Mean Squared Error as loss fun\n",
    "\n",
    "# Note we can have customized setup (have to build from scratch):\n",
    "# model.compilte(optimizer = keras.optimizers.RMSprop(learning_rate=1e-4, loss = my_custom_loss, \n",
    "# metrics=[my_custom_metric_1, my_custom_metric_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbb12543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5566 - mae: 0.7420\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 986us/step - loss: 0.5030 - mae: 0.7051\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 978us/step - loss: 0.4677 - mae: 0.6800\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.4384 - mae: 0.6582\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.4126 - mae: 0.6383\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.3889 - mae: 0.6196\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 999us/step - loss: 0.3668 - mae: 0.6016\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.3459 - mae: 0.5841\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.3260 - mae: 0.5669\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.3069 - mae: 0.5499\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.2885 - mae: 0.5331\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.2708 - mae: 0.5164\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.2538 - mae: 0.4997\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.2374 - mae: 0.4831\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.2217 - mae: 0.4667\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2065 - mae: 0.4504\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1918 - mae: 0.4339\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 999us/step - loss: 0.1778 - mae: 0.4173\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 995us/step - loss: 0.1644 - mae: 0.4012\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1515 - mae: 0.3849\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1392 - mae: 0.3687\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1275 - mae: 0.3524\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.1162 - mae: 0.3364\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 493us/step - loss: 0.1056 - mae: 0.3203\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0955 - mae: 0.3042\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0859 - mae: 0.2883\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0769 - mae: 0.2724\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0685 - mae: 0.2565\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0607 - mae: 0.2411\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0534 - mae: 0.2256\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 980us/step - loss: 0.0466 - mae: 0.2101\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0404 - mae: 0.1949\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0346 - mae: 0.1800\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0294 - mae: 0.1651\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0248 - mae: 0.1506\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0206 - mae: 0.1360\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0169 - mae: 0.1225\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0137 - mae: 0.1085\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0110 - mae: 0.0960\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0087 - mae: 0.0840\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0068 - mae: 0.0743\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0052 - mae: 0.0654\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0040 - mae: 0.0575\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0031 - mae: 0.0511\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0025 - mae: 0.0454\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0020 - mae: 0.0408\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0017 - mae: 0.0375\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0016 - mae: 0.0350\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0015 - mae: 0.0330\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0014 - mae: 0.0317\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0014 - mae: 0.0313\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0014 - mae: 0.0307\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0014 - mae: 0.0307\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0014 - mae: 0.0307\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0014 - mae: 0.0303\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0014 - mae: 0.0301\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0014 - mae: 0.0298\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0014 - mae: 0.0297\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0013 - mae: 0.0306\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0013 - mae: 0.0296\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0014 - mae: 0.0303\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0013 - mae: 0.0289\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0013 - mae: 0.0291\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0013 - mae: 0.0291\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0012 - mae: 0.0292\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0012 - mae: 0.0281\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0012 - mae: 0.0283\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0012 - mae: 0.0290\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 497us/step - loss: 0.0013 - mae: 0.0280\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0012 - mae: 0.0279\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0012 - mae: 0.0277\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0012 - mae: 0.0272\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0011 - mae: 0.0276\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0011 - mae: 0.0272\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0268\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0271\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0259\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0011 - mae: 0.0272\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0011 - mae: 0.0266\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0011 - mae: 0.0268\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0010 - mae: 0.0264\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 9.9622e-04 - mae: 0.0256\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.9065e-04 - mae: 0.0258\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.7676e-04 - mae: 0.0255\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.7118e-04 - mae: 0.0253\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.6296e-04 - mae: 0.0251\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.5340e-04 - mae: 0.0248\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.6062e-04 - mae: 0.0257\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.0319e-04 - mae: 0.0230\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 9.1384e-04 - mae: 0.0251\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.8537e-04 - mae: 0.0246\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.9988e-04 - mae: 0.0234\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.5458e-04 - mae: 0.0242\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.4391e-04 - mae: 0.0234\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.2460e-04 - mae: 0.0234\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.3847e-04 - mae: 0.0236\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.2378e-04 - mae: 0.0231\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.8134e-04 - mae: 0.0226\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.4427e-04 - mae: 0.0237\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.1016e-04 - mae: 0.0235\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.6875e-04 - mae: 0.0220\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.3819e-04 - mae: 0.0223\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.4022e-04 - mae: 0.0222\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.2792e-04 - mae: 0.0221\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.0723e-04 - mae: 0.0205\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.9902e-04 - mae: 0.0217\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 6.7987e-04 - mae: 0.0213\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.6929e-04 - mae: 0.0208\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.4365e-04 - mae: 0.0208\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.7756e-04 - mae: 0.0198\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.2854e-04 - mae: 0.0201\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.3494e-04 - mae: 0.0207\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.3117e-04 - mae: 0.0202\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.9320e-04 - mae: 0.0201\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.8580e-04 - mae: 0.0193\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.3200e-04 - mae: 0.0213\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 5.7094e-04 - mae: 0.0189\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.5703e-04 - mae: 0.0186\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 5.7158e-04 - mae: 0.0198\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.6839e-04 - mae: 0.0195\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.3475e-04 - mae: 0.0188\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 5.2740e-04 - mae: 0.0189\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.1624e-04 - mae: 0.0182\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.3188e-04 - mae: 0.0188\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.4365e-04 - mae: 0.0189\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.0146e-04 - mae: 0.0188\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.8645e-04 - mae: 0.0177\n",
      "Epoch 128/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.8262e-04 - mae: 0.0187\n",
      "Epoch 129/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.9219e-04 - mae: 0.0172\n",
      "Epoch 130/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.6397e-04 - mae: 0.0169\n",
      "Epoch 131/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.6109e-04 - mae: 0.0173\n",
      "Epoch 132/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.3962e-04 - mae: 0.0175\n",
      "Epoch 133/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.3855e-04 - mae: 0.0170\n",
      "Epoch 134/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 4.4494e-04 - mae: 0.0174\n",
      "Epoch 135/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.0840e-04 - mae: 0.0150\n",
      "Epoch 136/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.6660e-04 - mae: 0.0177\n",
      "Epoch 137/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.2686e-04 - mae: 0.0172\n",
      "Epoch 138/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 3.9517e-04 - mae: 0.0161\n",
      "Epoch 139/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.1527e-04 - mae: 0.0167\n",
      "Epoch 140/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.8035e-04 - mae: 0.0156\n",
      "Epoch 141/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.8325e-04 - mae: 0.0161\n",
      "Epoch 142/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.1032e-04 - mae: 0.0164\n",
      "Epoch 143/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.6655e-04 - mae: 0.0156\n",
      "Epoch 144/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 3.7487e-04 - mae: 0.0155\n",
      "Epoch 145/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.0459e-04 - mae: 0.0163\n",
      "Epoch 146/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.4630e-04 - mae: 0.0150\n",
      "Epoch 147/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.6813e-04 - mae: 0.0155\n",
      "Epoch 148/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 3.5460e-04 - mae: 0.0154\n",
      "Epoch 149/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.3948e-04 - mae: 0.0147\n",
      "Epoch 150/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 3.3557e-04 - mae: 0.0147\n",
      "Epoch 151/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 3.1972e-04 - mae: 0.0141\n",
      "Epoch 152/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 3.1859e-04 - mae: 0.0143\n",
      "Epoch 153/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 3.1127e-04 - mae: 0.0143\n",
      "Epoch 154/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 3.0272e-04 - mae: 0.0144\n",
      "Epoch 155/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 2.8701e-04 - mae: 0.0141\n",
      "Epoch 156/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.3147e-04 - mae: 0.0139\n",
      "Epoch 157/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.0726e-04 - mae: 0.0149\n",
      "Epoch 158/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.6901e-04 - mae: 0.0129\n",
      "Epoch 159/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.6448e-04 - mae: 0.0137\n",
      "Epoch 160/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.6176e-04 - mae: 0.0129\n",
      "Epoch 161/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 3.0362e-04 - mae: 0.0141\n",
      "Epoch 162/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.4875e-04 - mae: 0.0128\n",
      "Epoch 163/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.4777e-04 - mae: 0.0128\n",
      "Epoch 164/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.9095e-04 - mae: 0.0134\n",
      "Epoch 165/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.8795e-04 - mae: 0.0139\n",
      "Epoch 166/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.3550e-04 - mae: 0.0127\n",
      "Epoch 167/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.4006e-04 - mae: 0.0125\n",
      "Epoch 168/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.2104e-04 - mae: 0.0121\n",
      "Epoch 169/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 499us/step - loss: 2.7187e-04 - mae: 0.0131\n",
      "Epoch 170/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.2397e-04 - mae: 0.0127\n",
      "Epoch 171/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.3288e-04 - mae: 0.0120\n",
      "Epoch 172/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.1885e-04 - mae: 0.0120\n",
      "Epoch 173/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.0287e-04 - mae: 0.0118\n",
      "Epoch 174/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.9854e-04 - mae: 0.0111\n",
      "Epoch 175/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.1621e-04 - mae: 0.0124\n",
      "Epoch 176/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.8672e-04 - mae: 0.0104\n",
      "Epoch 177/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 2.3430e-04 - mae: 0.0125\n",
      "Epoch 178/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 1.9553e-04 - mae: 0.0111\n",
      "Epoch 179/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.8562e-04 - mae: 0.0107\n",
      "Epoch 180/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.7563e-04 - mae: 0.0108\n",
      "Epoch 181/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.9098e-04 - mae: 0.0114\n",
      "Epoch 182/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.7026e-04 - mae: 0.0107\n",
      "Epoch 183/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.0166e-04 - mae: 0.0116\n",
      "Epoch 184/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.9789e-04 - mae: 0.0110\n",
      "Epoch 185/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.5608e-04 - mae: 0.0101\n",
      "Epoch 186/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.6615e-04 - mae: 0.0107\n",
      "Epoch 187/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.8152e-04 - mae: 0.0106\n",
      "Epoch 188/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.4558e-04 - mae: 0.0097\n",
      "Epoch 189/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.5380e-04 - mae: 0.0103\n",
      "Epoch 190/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.7247e-04 - mae: 0.0098\n",
      "Epoch 191/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.3604e-04 - mae: 0.0098\n",
      "Epoch 192/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.4877e-04 - mae: 0.0095\n",
      "Epoch 193/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.2641e-04 - mae: 0.0097\n",
      "Epoch 194/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.3401e-04 - mae: 0.0088\n",
      "Epoch 195/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.3021e-04 - mae: 0.0092\n",
      "Epoch 196/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.3357e-04 - mae: 0.0096\n",
      "Epoch 197/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1953e-04 - mae: 0.0087\n",
      "Epoch 198/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2438e-04 - mae: 0.0088\n",
      "Epoch 199/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.3449e-04 - mae: 0.0094\n",
      "Epoch 200/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1258e-04 - mae: 0.0087\n",
      "Epoch 201/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.2575e-04 - mae: 0.0090\n",
      "Epoch 202/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2117e-04 - mae: 0.0086\n",
      "Epoch 203/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0785e-04 - mae: 0.0081\n",
      "Epoch 204/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.0194e-04 - mae: 0.0080\n",
      "Epoch 205/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.1259e-04 - mae: 0.0087\n",
      "Epoch 206/500\n",
      "3/3 [==============================] - 0s 495us/step - loss: 1.2477e-04 - mae: 0.0090\n",
      "Epoch 207/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.1247e-05 - mae: 0.0077\n",
      "Epoch 208/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.0120e-05 - mae: 0.0076\n",
      "Epoch 209/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.0097e-04 - mae: 0.0077\n",
      "Epoch 210/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.3048e-05 - mae: 0.0078\n",
      "Epoch 211/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.1598e-04 - mae: 0.0090\n",
      "Epoch 212/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.4164e-05 - mae: 0.0074\n",
      "Epoch 213/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.9005e-05 - mae: 0.0072\n",
      "Epoch 214/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.1357e-05 - mae: 0.0069\n",
      "Epoch 215/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.2748e-05 - mae: 0.0080\n",
      "Epoch 216/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.2952e-05 - mae: 0.0074\n",
      "Epoch 217/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.5963e-05 - mae: 0.0068\n",
      "Epoch 218/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 6.7826e-05 - mae: 0.0068\n",
      "Epoch 219/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.1396e-05 - mae: 0.0071\n",
      "Epoch 220/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0801e-04 - mae: 0.0082\n",
      "Epoch 221/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.4141e-05 - mae: 0.0071\n",
      "Epoch 222/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.7756e-05 - mae: 0.0064\n",
      "Epoch 223/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.3965e-05 - mae: 0.0062\n",
      "Epoch 224/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0048e-04 - mae: 0.0085\n",
      "Epoch 225/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.0606e-05 - mae: 0.0061\n",
      "Epoch 226/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.4864e-05 - mae: 0.0059\n",
      "Epoch 227/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.9809e-05 - mae: 0.0077\n",
      "Epoch 228/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.6644e-05 - mae: 0.0069\n",
      "Epoch 229/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 5.2271e-05 - mae: 0.0060\n",
      "Epoch 230/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.8219e-05 - mae: 0.0058\n",
      "Epoch 231/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.7652e-05 - mae: 0.0057\n",
      "Epoch 232/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 4.7990e-05 - mae: 0.0058\n",
      "Epoch 233/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 5.0644e-05 - mae: 0.0054\n",
      "Epoch 234/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.3494e-05 - mae: 0.0067\n",
      "Epoch 235/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.5788e-05 - mae: 0.0080\n",
      "Epoch 236/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.2222e-05 - mae: 0.0054\n",
      "Epoch 237/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 3.9833e-05 - mae: 0.0051\n",
      "Epoch 238/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 4.7203e-05 - mae: 0.0052\n",
      "Epoch 239/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.2316e-05 - mae: 0.0062\n",
      "Epoch 240/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 3.9033e-05 - mae: 0.0050\n",
      "Epoch 241/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.6114e-05 - mae: 0.0048\n",
      "Epoch 242/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.7409e-05 - mae: 0.0076\n",
      "Epoch 243/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.6210e-05 - mae: 0.0052\n",
      "Epoch 244/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.1555e-05 - mae: 0.0054\n",
      "Epoch 245/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.4229e-05 - mae: 0.0051\n",
      "Epoch 246/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.0783e-05 - mae: 0.0044\n",
      "Epoch 247/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.0346e-05 - mae: 0.0047\n",
      "Epoch 248/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.3543e-05 - mae: 0.0046\n",
      "Epoch 249/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.8668e-05 - mae: 0.0078\n",
      "Epoch 250/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 3.3037e-05 - mae: 0.0045\n",
      "Epoch 251/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 998us/step - loss: 2.9249e-05 - mae: 0.0041\n",
      "Epoch 252/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.5808e-05 - mae: 0.0041\n",
      "Epoch 253/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 2.5640e-05 - mae: 0.0040\n",
      "Epoch 254/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.7663e-05 - mae: 0.0044\n",
      "Epoch 255/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.6416e-05 - mae: 0.0069\n",
      "Epoch 256/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.9780e-05 - mae: 0.0041\n",
      "Epoch 257/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.3614e-05 - mae: 0.0041\n",
      "Epoch 258/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.6156e-05 - mae: 0.0039\n",
      "Epoch 259/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 2.5388e-05 - mae: 0.0040\n",
      "Epoch 260/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.0975e-05 - mae: 0.0066\n",
      "Epoch 261/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 3.5233e-05 - mae: 0.0050\n",
      "Epoch 262/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.4405e-05 - mae: 0.0039\n",
      "Epoch 263/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.2338e-05 - mae: 0.0040\n",
      "Epoch 264/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 4.5080e-05 - mae: 0.0055\n",
      "Epoch 265/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 2.7298e-05 - mae: 0.0042\n",
      "Epoch 266/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.8003e-05 - mae: 0.0034\n",
      "Epoch 267/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.3223e-05 - mae: 0.0038\n",
      "Epoch 268/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.8884e-05 - mae: 0.0062\n",
      "Epoch 269/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 3.8804e-05 - mae: 0.0052\n",
      "Epoch 270/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.6828e-05 - mae: 0.0034\n",
      "Epoch 271/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.4892e-05 - mae: 0.0032\n",
      "Epoch 272/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.0598e-05 - mae: 0.0034\n",
      "Epoch 273/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.4823e-05 - mae: 0.0032\n",
      "Epoch 274/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 2.9754e-05 - mae: 0.0046\n",
      "Epoch 275/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.4196e-05 - mae: 0.0060\n",
      "Epoch 276/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.3493e-05 - mae: 0.0028\n",
      "Epoch 277/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.5844e-05 - mae: 0.0033\n",
      "Epoch 278/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.3246e-05 - mae: 0.0028\n",
      "Epoch 279/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.6239e-05 - mae: 0.0033\n",
      "Epoch 280/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.6529e-05 - mae: 0.0055\n",
      "Epoch 281/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 2.4083e-05 - mae: 0.0041\n",
      "Epoch 282/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.6951e-05 - mae: 0.0046\n",
      "Epoch 283/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2195e-05 - mae: 0.0028\n",
      "Epoch 284/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.4743e-05 - mae: 0.0029\n",
      "Epoch 285/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 3.2181e-05 - mae: 0.0050\n",
      "Epoch 286/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 3.0691e-05 - mae: 0.0049\n",
      "Epoch 287/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1753e-05 - mae: 0.0027\n",
      "Epoch 288/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.0796e-05 - mae: 0.0027\n",
      "Epoch 289/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.0757e-05 - mae: 0.0024\n",
      "Epoch 290/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.0023e-05 - mae: 0.0040\n",
      "Epoch 291/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.9417e-05 - mae: 0.0048\n",
      "Epoch 292/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.1897e-05 - mae: 0.0041\n",
      "Epoch 293/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.9462e-05 - mae: 0.0037\n",
      "Epoch 294/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1579e-05 - mae: 0.0030\n",
      "Epoch 295/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.9064e-06 - mae: 0.0021\n",
      "Epoch 296/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.4774e-05 - mae: 0.0033\n",
      "Epoch 297/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.9089e-05 - mae: 0.0049\n",
      "Epoch 298/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.3310e-05 - mae: 0.0042\n",
      "Epoch 299/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.7475e-05 - mae: 0.0037\n",
      "Epoch 300/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1564e-05 - mae: 0.0026\n",
      "Epoch 301/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.0770e-05 - mae: 0.0029\n",
      "Epoch 302/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.2696e-05 - mae: 0.0043\n",
      "Epoch 303/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.0010e-05 - mae: 0.0040\n",
      "Epoch 304/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.2095e-06 - mae: 0.0025\n",
      "Epoch 305/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.5779e-05 - mae: 0.0035\n",
      "Epoch 306/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 2.6753e-05 - mae: 0.0048\n",
      "Epoch 307/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.7643e-05 - mae: 0.0036\n",
      "Epoch 308/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.9113e-06 - mae: 0.0022\n",
      "Epoch 309/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.0992e-05 - mae: 0.0029\n",
      "Epoch 310/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.3439e-05 - mae: 0.0044\n",
      "Epoch 311/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.9367e-05 - mae: 0.0041\n",
      "Epoch 312/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2721e-05 - mae: 0.0031\n",
      "Epoch 313/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.6301e-06 - mae: 0.0022\n",
      "Epoch 314/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.0761e-06 - mae: 0.0017\n",
      "Epoch 315/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.6715e-05 - mae: 0.0035\n",
      "Epoch 316/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.2168e-05 - mae: 0.0062\n",
      "Epoch 317/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0955e-05 - mae: 0.0027\n",
      "Epoch 318/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.1779e-06 - mae: 0.0016\n",
      "Epoch 319/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.2144e-06 - mae: 0.0024\n",
      "Epoch 320/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.3980e-05 - mae: 0.0045\n",
      "Epoch 321/500\n",
      "3/3 [==============================] - 0s 983us/step - loss: 2.4889e-05 - mae: 0.0047\n",
      "Epoch 322/500\n",
      "3/3 [==============================] - 0s 983us/step - loss: 1.1266e-05 - mae: 0.0030\n",
      "Epoch 323/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 7.0971e-06 - mae: 0.0023\n",
      "Epoch 324/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.9584e-05 - mae: 0.0041\n",
      "Epoch 325/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.8359e-05 - mae: 0.0040\n",
      "Epoch 326/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1834e-05 - mae: 0.0031\n",
      "Epoch 327/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.6015e-06 - mae: 0.0023\n",
      "Epoch 328/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.3059e-05 - mae: 0.0033\n",
      "Epoch 329/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.8183e-05 - mae: 0.0051\n",
      "Epoch 330/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.2270e-06 - mae: 0.0023\n",
      "Epoch 331/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 3.7101e-06 - mae: 0.0016\n",
      "Epoch 332/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.0898e-05 - mae: 0.0029\n",
      "Epoch 333/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 499us/step - loss: 2.2561e-05 - mae: 0.0045\n",
      "Epoch 334/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.3130e-05 - mae: 0.0046\n",
      "Epoch 335/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 5.6731e-06 - mae: 0.0021\n",
      "Epoch 336/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 2.5322e-06 - mae: 0.0012\n",
      "Epoch 337/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.8273e-06 - mae: 9.9596e-04\n",
      "Epoch 338/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.7692e-06 - mae: 0.0010\n",
      "Epoch 339/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.2506e-05 - mae: 0.0030\n",
      "Epoch 340/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.7981e-05 - mae: 0.0064\n",
      "Epoch 341/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 3.6957e-06 - mae: 0.0016\n",
      "Epoch 342/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 1.8227e-06 - mae: 9.7853e-04\n",
      "Epoch 343/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.5026e-06 - mae: 9.5899e-04\n",
      "Epoch 344/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.5849e-06 - mae: 9.7145e-04\n",
      "Epoch 345/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.9087e-06 - mae: 0.0014\n",
      "Epoch 346/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.3504e-05 - mae: 0.0071\n",
      "Epoch 347/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1320e-05 - mae: 0.0030\n",
      "Epoch 348/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 3.4326e-06 - mae: 0.0016\n",
      "Epoch 349/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.2255e-06 - mae: 0.0013\n",
      "Epoch 350/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 2.8830e-06 - mae: 0.0014\n",
      "Epoch 351/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 2.3109e-05 - mae: 0.0045\n",
      "Epoch 352/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.7523e-05 - mae: 0.0050\n",
      "Epoch 353/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.3992e-06 - mae: 0.0021\n",
      "Epoch 354/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.2726e-06 - mae: 0.0021\n",
      "Epoch 355/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0406e-05 - mae: 0.0030\n",
      "Epoch 356/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.8837e-05 - mae: 0.0042\n",
      "Epoch 357/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2804e-05 - mae: 0.0034\n",
      "Epoch 358/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.4554e-06 - mae: 0.0028\n",
      "Epoch 359/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.2023e-06 - mae: 0.0025\n",
      "Epoch 360/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.2932e-05 - mae: 0.0047\n",
      "Epoch 361/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 2.0202e-05 - mae: 0.0044\n",
      "Epoch 362/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.7621e-06 - mae: 0.0026\n",
      "Epoch 363/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 3.6160e-06 - mae: 0.0017\n",
      "Epoch 364/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 5.7625e-06 - mae: 0.0022\n",
      "Epoch 365/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.8122e-05 - mae: 0.0041\n",
      "Epoch 366/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 2.5267e-05 - mae: 0.0050\n",
      "Epoch 367/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0195e-05 - mae: 0.0031\n",
      "Epoch 368/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.5982e-06 - mae: 0.0022\n",
      "Epoch 369/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.2500e-06 - mae: 0.0024\n",
      "Epoch 370/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.7944e-05 - mae: 0.0041\n",
      "Epoch 371/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.8313e-05 - mae: 0.0042\n",
      "Epoch 372/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.0056e-06 - mae: 0.0025\n",
      "Epoch 373/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.8495e-06 - mae: 0.0030\n",
      "Epoch 374/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.7021e-06 - mae: 0.0029\n",
      "Epoch 375/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0600e-05 - mae: 0.0031\n",
      "Epoch 376/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.4181e-05 - mae: 0.0037\n",
      "Epoch 377/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.4992e-05 - mae: 0.0038\n",
      "Epoch 378/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.3732e-05 - mae: 0.0037\n",
      "Epoch 379/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 9.5848e-06 - mae: 0.0030\n",
      "Epoch 380/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.0567e-05 - mae: 0.0032\n",
      "Epoch 381/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1036e-05 - mae: 0.0032\n",
      "Epoch 382/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.3115e-05 - mae: 0.0035\n",
      "Epoch 383/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.3269e-06 - mae: 0.0028\n",
      "Epoch 384/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.0069e-05 - mae: 0.0031\n",
      "Epoch 385/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.7489e-05 - mae: 0.0041\n",
      "Epoch 386/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.2967e-05 - mae: 0.0035\n",
      "Epoch 387/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.9123e-06 - mae: 0.0025\n",
      "Epoch 388/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 9.9933e-06 - mae: 0.0031\n",
      "Epoch 389/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.7554e-05 - mae: 0.0041\n",
      "Epoch 390/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.3536e-05 - mae: 0.0036\n",
      "Epoch 391/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 9.9543e-06 - mae: 0.0031\n",
      "Epoch 392/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.7493e-06 - mae: 0.0029\n",
      "Epoch 393/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1199e-05 - mae: 0.0033\n",
      "Epoch 394/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.1782e-05 - mae: 0.0034\n",
      "Epoch 395/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.3633e-05 - mae: 0.0036\n",
      "Epoch 396/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.4423e-05 - mae: 0.0038\n",
      "Epoch 397/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.0984e-05 - mae: 0.0033\n",
      "Epoch 398/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.1704e-05 - mae: 0.0034\n",
      "Epoch 399/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2810e-05 - mae: 0.0035\n",
      "Epoch 400/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0251e-05 - mae: 0.0032\n",
      "Epoch 401/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0930e-05 - mae: 0.0032\n",
      "Epoch 402/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2254e-05 - mae: 0.0035\n",
      "Epoch 403/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.3417e-05 - mae: 0.0036\n",
      "Epoch 404/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.2796e-05 - mae: 0.0035\n",
      "Epoch 405/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1139e-05 - mae: 0.0033\n",
      "Epoch 406/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.5314e-06 - mae: 0.0029\n",
      "Epoch 407/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2025e-05 - mae: 0.0034\n",
      "Epoch 408/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.6330e-05 - mae: 0.0040\n",
      "Epoch 409/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.2086e-05 - mae: 0.0034\n",
      "Epoch 410/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.2419e-06 - mae: 0.0028\n",
      "Epoch 411/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0190e-05 - mae: 0.0031\n",
      "Epoch 412/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.5286e-05 - mae: 0.0039\n",
      "Epoch 413/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2826e-05 - mae: 0.0035\n",
      "Epoch 414/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.0058e-05 - mae: 0.0031\n",
      "Epoch 415/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.0593e-06 - mae: 0.0030\n",
      "Epoch 416/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.3673e-05 - mae: 0.0037\n",
      "Epoch 417/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.4317e-05 - mae: 0.0038\n",
      "Epoch 418/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.3492e-05 - mae: 0.0037\n",
      "Epoch 419/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.0317e-05 - mae: 0.0032\n",
      "Epoch 420/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.7676e-06 - mae: 0.0028\n",
      "Epoch 421/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.1753e-05 - mae: 0.0034\n",
      "Epoch 422/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.7751e-05 - mae: 0.0042\n",
      "Epoch 423/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.1811e-05 - mae: 0.0034\n",
      "Epoch 424/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.7039e-06 - mae: 0.0029\n",
      "Epoch 425/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.9839e-06 - mae: 0.0030\n",
      "Epoch 426/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.4542e-05 - mae: 0.0038\n",
      "Epoch 427/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.3216e-05 - mae: 0.0036\n",
      "Epoch 428/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 1.1168e-05 - mae: 0.0033\n",
      "Epoch 429/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0310e-05 - mae: 0.0032\n",
      "Epoch 430/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0671e-05 - mae: 0.0032\n",
      "Epoch 431/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 1.2221e-05 - mae: 0.0035\n",
      "Epoch 432/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.4299e-05 - mae: 0.0038\n",
      "Epoch 433/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.2166e-05 - mae: 0.0035\n",
      "Epoch 434/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 9.6408e-06 - mae: 0.0031\n",
      "Epoch 435/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.0967e-05 - mae: 0.0033\n",
      "Epoch 436/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.1940e-05 - mae: 0.0034\n",
      "Epoch 437/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.4288e-05 - mae: 0.0038\n",
      "Epoch 438/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1064e-05 - mae: 0.0033\n",
      "Epoch 439/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.6957e-06 - mae: 0.0029\n",
      "Epoch 440/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1432e-05 - mae: 0.0034\n",
      "Epoch 441/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.6146e-05 - mae: 0.0040\n",
      "Epoch 442/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.1599e-05 - mae: 0.0034\n",
      "Epoch 443/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.9528e-06 - mae: 0.0028\n",
      "Epoch 444/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0644e-05 - mae: 0.0032\n",
      "Epoch 445/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.4530e-05 - mae: 0.0038\n",
      "Epoch 446/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2465e-05 - mae: 0.0035\n",
      "Epoch 447/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0342e-05 - mae: 0.0032\n",
      "Epoch 448/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0068e-05 - mae: 0.0032\n",
      "Epoch 449/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1578e-05 - mae: 0.0034\n",
      "Epoch 450/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.2877e-05 - mae: 0.0036\n",
      "Epoch 451/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2467e-05 - mae: 0.0035\n",
      "Epoch 452/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.7315e-06 - mae: 0.0031\n",
      "Epoch 453/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.0885e-05 - mae: 0.0033\n",
      "Epoch 454/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.3977e-05 - mae: 0.0037\n",
      "Epoch 455/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0562e-05 - mae: 0.0032\n",
      "Epoch 456/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.1014e-05 - mae: 0.0033\n",
      "Epoch 457/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.2426e-05 - mae: 0.0035\n",
      "Epoch 458/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.1994e-05 - mae: 0.0035\n",
      "Epoch 459/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0738e-05 - mae: 0.0033\n",
      "Epoch 460/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.2708e-05 - mae: 0.0036\n",
      "Epoch 461/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.2695e-05 - mae: 0.0035\n",
      "Epoch 462/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.0716e-05 - mae: 0.0033\n",
      "Epoch 463/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 1.0949e-05 - mae: 0.0033\n",
      "Epoch 464/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.6131e-06 - mae: 0.0031\n",
      "Epoch 465/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1108e-05 - mae: 0.0033\n",
      "Epoch 466/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.4575e-05 - mae: 0.0038\n",
      "Epoch 467/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2668e-05 - mae: 0.0035\n",
      "Epoch 468/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.1188e-06 - mae: 0.0030\n",
      "Epoch 469/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0820e-05 - mae: 0.0033\n",
      "Epoch 470/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2475e-05 - mae: 0.0035\n",
      "Epoch 471/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2692e-05 - mae: 0.0035\n",
      "Epoch 472/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.0615e-05 - mae: 0.0032\n",
      "Epoch 473/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.0084e-05 - mae: 0.0032\n",
      "Epoch 474/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2435e-05 - mae: 0.0035\n",
      "Epoch 475/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.3304e-05 - mae: 0.0036\n",
      "Epoch 476/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0667e-05 - mae: 0.0033\n",
      "Epoch 477/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.0298e-05 - mae: 0.0032\n",
      "Epoch 478/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.2503e-05 - mae: 0.0035\n",
      "Epoch 479/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.1101e-05 - mae: 0.0033\n",
      "Epoch 480/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1956e-05 - mae: 0.0034\n",
      "Epoch 481/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.2764e-05 - mae: 0.0036\n",
      "Epoch 482/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.9025e-06 - mae: 0.0031\n",
      "Epoch 483/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0695e-05 - mae: 0.0033\n",
      "Epoch 484/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.3335e-05 - mae: 0.0036\n",
      "Epoch 485/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1506e-05 - mae: 0.0034\n",
      "Epoch 486/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0534e-05 - mae: 0.0032\n",
      "Epoch 487/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.1748e-05 - mae: 0.0034\n",
      "Epoch 488/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2981e-05 - mae: 0.0036\n",
      "Epoch 489/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0845e-05 - mae: 0.0033\n",
      "Epoch 490/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.0501e-05 - mae: 0.0032\n",
      "Epoch 491/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.2166e-05 - mae: 0.0035\n",
      "Epoch 492/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2614e-05 - mae: 0.0035\n",
      "Epoch 493/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.0799e-05 - mae: 0.0033\n",
      "Epoch 494/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1166e-05 - mae: 0.0033\n",
      "Epoch 495/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.2578e-05 - mae: 0.0035\n",
      "Epoch 496/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 997us/step - loss: 1.2431e-05 - mae: 0.0035\n",
      "Epoch 497/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0840e-05 - mae: 0.0033\n",
      "Epoch 498/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.0243e-05 - mae: 0.0032\n",
      "Epoch 499/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.1044e-05 - mae: 0.0033\n",
      "Epoch 500/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.4129e-05 - mae: 0.0038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18ea6d27be0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = X_train, y = y_train, epochs = 500) \n",
    "\n",
    "# Note we haven't implemented the batch_size.\n",
    "# can set verbose=0 to turn on silent mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad66d786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAngklEQVR4nO3deZRc5Xnn8e9T1dV7q3fRQq2lERIgJMBYErZxBMTBCGfBxM4E4vEWE8Jk8EwmZ3BwPM7Yh3O85kyS45Bgjo2XiW1wjO1obAVsE9uYhBhJGAFCCC1I0Fq7W1Kr962e+eOtloqmqrok9Va3fp9z+lTVvW9VPbfV+t233vvWvebuiIhI4YvNdgEiIjI1FOgiIhGhQBcRiQgFuohIRCjQRUQiomS23ripqcmXLl06W28vIlKQtm7d2unuzZnWzVqgL126lC1btszW24uIFCQz259tnYZcREQiQoEuIhIRCnQRkYiYtTF0EZGzNTIyQnt7O4ODg7NdyrQpLy+ntbWVRCKR93MU6CJScNrb26mpqWHp0qWY2WyXM+Xcna6uLtrb22lra8v7eRpyEZGCMzg4SGNjYyTDHMDMaGxsPONPIAp0ESlIUQ3zcWezfYUX6EdegMfugb6u2a5ERGROKbxAP7YHfvFX0HNwtisRkSJWXV092yW8TuEFetm8cDvYPbt1iIjMMYUX6OW14VaBLiJzgLtz1113sWrVKlavXs1DDz0EwKFDh1i/fj1XXHEFq1at4he/+AVjY2N84AMfONX2r//6r6e0lsKbtqhAF5E0n/x/23nh4Mkpfc2V58/jf//2pXm1/e53v8szzzzDtm3b6OzsZO3ataxfv55vfvOb3HDDDXzsYx9jbGyM/v5+nnnmGQ4cOMDzzz8PwIkTJ6a0bvXQRUTOwRNPPMGtt95KPB7nvPPO45prrmHz5s2sXbuWr3zlK3ziE5/gueeeo6amhgsuuIC9e/fy4Q9/mEceeYR58+ZNaS2F10PXGLqIpMm3Jz1d3D3j8vXr1/P444/zwx/+kPe+973cddddvO9972Pbtm08+uij3HvvvXz729/mgQcemLJaCq+HHi+B0hoFuojMCevXr+ehhx5ibGyMjo4OHn/8cdatW8f+/fuZP38+f/RHf8SHPvQhnn76aTo7O0kmk7zrXe/innvu4emnn57SWgqvhw5h2EWBLiJzwM0338yTTz7J5Zdfjpnxuc99jpaWFr72ta/x+c9/nkQiQXV1NV//+tc5cOAAH/zgB0kmkwB8+tOfntJaLNvHhdc0MtsA/C0QB77k7p+ZsP4u4D2phyXAJUCzux/L9ppr1qzxs77Axd+/GRougFu+cXbPF5GCtmPHDi655JLZLmPaZdpOM9vq7msytZ90yMXM4sC9wI3ASuBWM1uZ3sbdP+/uV7j7FcBHgZ/nCvNzph66iMjr5DOGvg7Y7e573X0YeBC4KUf7W4FvTUVxWVU0QL+++i8iki6fQF8IvJr2uD217HXMrBLYADycZf3tZrbFzLZ0dHScaa2n1ZwHPYfP/vkiIhGUT6BnOuVXtoH33wb+Ldtwi7vf7+5r3H1Nc3PGi1bnp7oFBo7B6PDZv4aISMTkE+jtwKK0x61AtjNj3cJ0D7dA6KED9B6Z9rcSESkU+QT6ZmC5mbWZWSkhtDdObGRmtcA1wD9PbYkZVLeEWwW6iMgpk85Dd/dRM7sTeJQwbfEBd99uZnek1t+Xanoz8CN375u2aseN99A1ji4ickpeXyxy903ApgnL7pvw+KvAV6eqsJxO9dAV6CIi4wrvq/8AVc2AQY+GXERkduzbt4+LL76Y2267jVWrVvGe97yHn/zkJ1x99dUsX76cp556iqeeeoq3vOUtvOENb+Atb3kLO3fuBGBsbIy77rqLtWvXctlll/HFL35xSmoqzK/+x0tCqGsMXUT+5W44/NzUvmbLarjxM5M22717N//0T//E/fffz9q1a/nmN7/JE088wcaNG/nUpz7F17/+dR5//HFKSkr4yU9+wl/8xV/w8MMP8+Uvf5na2lo2b97M0NAQV199NW9/+9tpa2s7p7ILM9AhjKMr0EVkFrW1tbF69WoALr30Ut72trdhZqxevZp9+/bR3d3N+9//fnbt2oWZMTIyAsCPfvQjnn32Wb7zne8A0N3dza5du4o40KtbdFBURPLqSU+XsrKyU/djsdipx7FYjNHRUT7+8Y9z3XXX8b3vfY99+/Zx7bXXAuGUu1/4whe44YYbprSewhxDB/XQRWTO6+7uZuHC8MX6r371q6eW33DDDfzDP/zDqR77Sy+9RF/fuU8QLOBAXwC9RyE5NtuViIhk9JGPfISPfvSjXH311YyNnc6q2267jZUrV3LllVeyatUq/viP/5jR0dFzfr+8Tp87Hc7p9LkAW74CP/hT+B/bobZ1yuoSkblPp889y9Pnzll1qbMRnHg1dzsRkSJRuIFeuzjcnnhldusQEZkjCjjQU8Ms3Qp0kWI0W8PFM+Vstq9wA720EiqbNOQiUoTKy8vp6uqKbKi7O11dXZSXl5/R8wp3HjqEcfRuBbpIsWltbaW9vZ1zulDOHFdeXk5r65lN+CjsQK9dBEd3zHYVIjLDEonEOX+rMooKd8gFoG4xdLdDRD92iYicicIO9NpFMDoAfZ2zXYmIyKwr7EAfn4uumS4iIgUe6LX6cpGIyLjCDvRTPXQFuohIXoFuZhvMbKeZ7Tazu7O0udbMnjGz7Wb286ktM4vyOiitUQ9dRIQ8pi2aWRy4F7geaAc2m9lGd38hrU0d8PfABnd/xczmT1O9E4vTXHQRkZR8eujrgN3uvtfdh4EHgZsmtPkD4Lvu/gqAux+d2jJzqFus87mIiJBfoC8E0rvA7all6VYA9Wb2MzPbambvy/RCZna7mW0xsy1T9g2vuiVwfL/mootI0csn0C3DsonpWQK8EfhN4Abg42a24nVPcr/f3de4+5rm5uYzLjajhjYY7oH+rql5PRGRApVPoLcDi9IetwIHM7R5xN373L0TeBy4fGpKnET90nB7fN+MvJ2IyFyVT6BvBpabWZuZlQK3ABsntPln4NfMrMTMKoGrgJk5yUp96nwOx16ekbcTEZmrJp3l4u6jZnYn8CgQBx5w9+1mdkdq/X3uvsPMHgGeBZLAl9z9+eks/JT6JeFWPXQRKXJ5nW3R3TcBmyYsu2/C488Dn5+60vKUqAgXjD6uHrqIFLfC/qbouPo2DbmISNGLSKAv1ZCLiBS9aAR6Qxv0HISRgdmuRERk1kQj0MenLuoboyJSxAou0AdHxmg/3s/waPL0Qk1dFBEpvED/0QtHeOtnf8r+rr7TC/XlIhGRwgv0ykQcgP7hsdMLq5qgtFpTF0WkqBVeoJdmCHQzzXQRkaJXcIFekQr0gZHR166oX6oxdBEpagUX6JWl4cutr+mhQwj0E/shmXz9k0REikABBnqGIRcIc9FHB6H38CxUJSIy+wou0E8NuWTqoYPG0UWkaBVcoGftoWsuuogUuYIL9PKS8YOiEwK9bjFYTD10ESlaBRfosZhRkYgzMDxhlks8AbWtmosuIkWr4AIdwjj664ZcIAy7qIcuIkWqMAM9EX/9QVHQXHQRKWoFGeiV2XroDW3Q3wlDPTNflIjILMsr0M1sg5ntNLPdZnZ3hvXXmlm3mT2T+vnLqS/1tMrSOP0TD4qCpi6KSFGb9JqiZhYH7gWuB9qBzWa20d1fmND0F+7+W9NQ4+tUlGY4KAqnpy4e3wctq2eiFBGROSOfHvo6YLe773X3YeBB4KbpLSu3mvIEPYOZAn1puNU4uogUoXwCfSHwatrj9tSyid5sZtvM7F/M7NJML2Rmt5vZFjPb0tHRcRblBvWVCU70j7x+RUUdVDRo6qKIFKV8At0yLPMJj58Glrj75cAXgO9neiF3v9/d17j7mubm5jMqNF1dZSknBoYzr2y4AI7tPevXFhEpVPkEejuwKO1xK3AwvYG7n3T33tT9TUDCzJqmrMoJaisSDI4kGcx0YFSBLiJFKp9A3wwsN7M2MysFbgE2pjcwsxYzs9T9danX7ZrqYsfVVSYAMg+7NFwA3e0wOjRdby8iMidNOsvF3UfN7E7gUSAOPODu283sjtT6+4B3A//FzEaBAeAWd584LDNl6ipKATgxMExLbflrVza0gSfhxCvQtHy6ShARmXMmDXQ4NYyyacKy+9Lu/x3wd1NbWnaT9tAhDLso0EWkiBTkN0XzDnQRkSJSoIEehly6M810qWyEsnmaiy4iRacwA70iRw/dLIyjq4cuIkWmIAO9sjROIm4czxTooKmLIlKUCjLQzYzaitLMQy4QAv3EfhjLcHoAEZGIKshAh3BgNOOQC4RAT45C96uZ14uIRFDBBnrW87lA2gWjNewiIsWjYAO9tqKUEwM5euigQBeRolKwgV5XmaC7P8sYek0LlFRo6qKIFJXCDfSKRPYeuplmuohI0SnYQK+vKqV/eCzzxaIhzEXXedFFpIgUbKA315QB0Nmb5ayKDReEIZdkcgarEhGZPYUb6NUh0DtyBfrYEPQczLxeRCRiCjfQUz30jp4cgQ4aRxeRohHhQNdcdBEpLgUb6A1V4YyLWcfQ5y2EeKkCXUSKRsEGeiIeo6GqNHsPPRaH+qUKdBEpGnkFupltMLOdZrbbzO7O0W6tmY2Z2bunrsTsmqvLsgc6nJ7pIiJSBCYNdDOLA/cCNwIrgVvNbGWWdp8lXHt0RjTVlGYfcoHTgT59lzcVEZkz8umhrwN2u/tedx8GHgRuytDuw8DDwNEprC+n5uqy7NMWIQT6SB/0zlhJIiKzJp9AXwikn4e2PbXsFDNbCNwM3EcOZna7mW0xsy0dHR1nWuvrNNeEIRfP1gPXTBcRKSL5BLplWDYxQf8G+HN3z/I9/NST3O939zXuvqa5uTnPErNrriljcCRJX9av/2suuogUj5I82rQDi9IetwITv365BnjQzACagHeY2ai7f38qisymqfr0XPTqsgybUrsILK5AF5GikE8PfTOw3MzazKwUuAXYmN7A3dvcfam7LwW+A/zJdIc5wPyacgCOnBzM3CCegLrFCnQRKQqT9tDdfdTM7iTMXokDD7j7djO7I7U+57j5dGqpnSTQQafRFZGikc+QC+6+Cdg0YVnGIHf3D5x7WfkZD/RD3ZMEevuWMHXRMh0OEBGJhoL9pihAdVkJNWUlHJ4s0Ie6of/YzBUmIjILCjrQIfTSD3UPZG+gmS4iUiQiEeiT9tBBVy8Skcgr+EBfUFvO4VwHReuXAKYeuohEXsEHekttBUd7hhgZy3KpuZIyqG1VoItI5BV8oC+oLcc9x4UuIJwCQIEuIhFX8IGe99RFBbqIRFzBB/qCVKBPemC0vwsGTsxMUSIis6DwA31eBUB+Uxc100VEIqzgA31eRQkViXh+Uxc17CIiEVbwgW5mLKgt51DOqYtLw60uRyciEVbwgQ55fLmotApqFqiHLiKRVhyBDtCwDLr2zExBIiKzIBKBvqC2nCMnBxlL5rgYdOMF0LV75ooSEZlhEQn0CkaTPsmXi5ZBfycMds9cYSIiMygSgd5aH6Yuth/vz96o8cJwq2EXEYmoiAR6JQDtx3PMRW9cFm4V6CISUREJ9Dx66PVthLMuKtBFJJryCnQz22BmO81st5ndnWH9TWb2rJk9Y2ZbzOytU19qduWJOE3VZbl76InycNZF9dBFJKImvaaomcWBe4HrgXZgs5ltdPcX0po9Bmx0dzezy4BvAxdPR8HZLKyv4MCJHIEOYdhFPXQRiah8eujrgN3uvtfdh4EHgZvSG7h7r7uPzxmsAnLMH5werfUVuXvokJqLvjtcMFpEJGLyCfSFwKtpj9tTy17DzG42sxeBHwJ/mOmFzOz21JDMlo6OjrOpN6vW+goOHB8gmXMu+rIwbVEXjBaRCMon0C3Dstelprt/z90vBt4J3JPphdz9fndf4+5rmpubz6jQybTWVzI8lqSjN8dc9PGpixp2EZEIyifQ24FFaY9bgYPZGrv748AyM2s6x9rOSF4zXRrGpy7qG6MiEj35BPpmYLmZtZlZKXALsDG9gZldaGaWun8lUAp0TXWxubTWjQd6jnH0+iVgcc10EZFImnSWi7uPmtmdwKNAHHjA3beb2R2p9fcB7wLeZ2YjwADw+2kHSWfEwvo8Aj2eCKGuIRcRiaBJAx3A3TcBmyYsuy/t/meBz05taWemsrSExqrSPGe6KNBFJHoi8U3RcWHqYo4xdAgzXbr2aOqiiEROxAK9cvIeeuOFMNIHvUdmpigRkRkSqUBf1FBJ+/H+3OdFH7++qIZdRCRiIhXoSxsrGRlzDuY6BUCjpi6KSDRFKtCXNFYBsL8rxzh67SKIl2qmi4hETsQCPZwXfV9XX/ZGsXg4la6GXEQkYiIV6C3zyiktifHKsTxmuhzbOzNFiYjMkEgFeixmLGmoZF9njh46hAOjx/ZCMjkzhYmIzIBIBTqEcfScY+gQpi6ODsLJAzNTlIjIDIhcoC9trGT/sb7JT6MLOjAqIpESuUBf0ljJ4EiSoz05TqOrsy6KSARFMNDHpy7mGEevWQCJSujSgVERiY7IBfrSfOaix2KpA6MachGR6IhcoJ9fV05JzHLPRYcQ6JqLLiIRErlAL4nHWNRQOXmgNy6D4y/D2OjMFCYiMs0iF+gAbU1V7O2YLNAvhOQodL8yM0WJiEyzSAb6suYqXu7sm+Ssi+MzXXRgVESiIa9AN7MNZrbTzHab2d0Z1r/HzJ5N/fy7mV0+9aXmb1lzNUOjSZ11UUSKyqSBbmZx4F7gRmAlcKuZrZzQ7GXgGne/DLgHuH+qCz0Ty+ZXA7C7ozd7o6pmKJunmS4iEhn59NDXAbvdfa+7DwMPAjelN3D3f3f346mH/wG0Tm2ZZ2ZZcwj0PUdzBLqZZrqISKTkE+gLgVfTHrenlmXzIeBfzqWoc9VQVUp9ZYI9kx4YXaYeuohERj6BbhmWZTzaaGbXEQL9z7Osv93MtpjZlo6OjvyrPAvLmqvZk2vIBcJMlxOvwGiO0wSIiBSIfAK9HViU9rgVODixkZldBnwJuMnduzK9kLvf7+5r3H1Nc3Pz2dSbt2XN1ezNJ9A9CcdentZaRERmQj6BvhlYbmZtZlYK3AJsTG9gZouB7wLvdfeXpr7MM7dsfhWdvcOc6B/O3qhpRbjtnBMli4ick0kD3d1HgTuBR4EdwLfdfbuZ3WFmd6Sa/SXQCPy9mT1jZlumreI8nTowmmscvWl5uO3cOQMViYhMr5J8Grn7JmDThGX3pd2/Dbhtaks7N6cDvZc3LqnP3Ki0Klw0unPXDFYmIjI9IvlNUYDW+gpK4zF255q6CKGX3qEeuogUvsgGekk8xoXzq3nxcE/uhk0XhR665zhNgIhIAYhsoANc3FLDzsMnczdqWg4jfbq+qIgUvGgH+oIajpwc4nhfjpkuzReFWw27iEiBi3SgX9QyDyD3sMupqYs6MCoihS3SgX5JSw0AL+YadqlqhvJaTV0UkYIX6UBvrimjvjLBzlw9dLPTB0ZFRApYpAPdzLi4ZR47Jp3pskJj6CJS8CId6AAXtdTw0uEekrmuXtS8AvqOwsDx7G1EROa4yAf6JQtqGBgZ45Vj/dkb6cCoiERA5AP94tRMlx2HchwY1Um6RCQCIh/oF7XUEI8Zzx/szt6obgnESzWOLiIFLfKBXp6Is+K8Gp5tzxHo8ZJwbnQNuYhIAYt8oANctrCW5w5047nO19K0XHPRRaSgFUegL6rlRP8I7ccHsjdqugiO79Pl6ESkYBVHoC+sA2Bb+4nsjZovCpej07CLiBSoogj0i1pqKI3HeC7XOPr8S8Jtx4szU5SIyBQrikAvLYlxyYJJDow2LodYCRx9YeYKExGZQnkFupltMLOdZrbbzO7OsP5iM3vSzIbM7H9OfZnnbnVrLc8f6M7+jdGS0jDT5eiOmS1MRGSKTBroZhYH7gVuBFYCt5rZygnNjgH/DfirKa9wily2sI6eoVH2dua4aPT8lXBk+8wVJSIyhfLpoa8Ddrv7XncfBh4Ebkpv4O5H3X0zMDINNU6JK1MXit66/1j2RvNXwon9MDTJdUhFROagfAJ9IfBq2uP21LIzZma3m9kWM9vS0dFxNi9x1pY1V9FYVcovX84V6OMHRjUfXUQKTz6BbhmWndUVld39fndf4+5rmpubz+YlzpqZsWZpPZv35Qj081IjSUeen5miRESmUD6B3g4sSnvcChycnnKm17q2Rl49NsCh7ixfMKpbCqU1cPi5Ga1LRGQq5BPom4HlZtZmZqXALcDG6S1reqxb2gDAU9mGXWIxaFkNh5+dwapERKbGpIHu7qPAncCjwA7g2+6+3czuMLM7AMysxczagT8D/peZtZvZvOks/GxcsqCG6rKS3MMuCy4LPfSxOXt8V0Qko5J8Grn7JmDThGX3pd0/TBiKmdNK4jGuXFKfvYcOsPhN8Mv74NA2aF0zc8WJiJyjovimaLqr2hp46Ugvnb1ZTsK15Opwu++JmStKRGQKFF2gr18eZtf8YleWaZPV88MVjPb/2wxWJSJy7oou0C89fx6NVaX8fGeOefBLrob9T8LY6MwVJiJyjoou0GMxY/2KZh7f1Zn9vC5L3wrDPXDomRmtTUTkXBRdoANcs6KZY33DPHsgy9kXL7gOMNj14xmtS0TkXBRtoMdjxiPPH87coKoxzHDZuSnzehGROagoA72+qpS3LGvkkecPZb/O6Kp3hy8YHdZpAESkMBRloANsWNXCvq5+Xjzck7nB6t+DWAKe+cbMFiYicpaKNtDfvrKFmMEPns1yWpqqRrjoRnj2IRjJcXFpEZE5omgDvbmmjPUrmnl46wHGss12ueoO6O+CzV+e2eJERM5C0QY6wO+vWcThk4M8nu1LRkuvhgt/A376qXAqABGROayoA/1tl5xHQ1Up3/rlK9kb/c4XoLIBvvbb8Px34cSrkEzOXJEiInnK6+RcUVVaEuMP1i3m3p/tZm9HLxc0V7++0bzz4QM/hG+8G77zwbAsVgJV86GyMQzJxOLQuCxcZBqD5otgqAcWvhFqFoDFoLYV4glIjoULUouITDHLOm1vmq1Zs8a3bNkyK++drqNniKs/+6+868qFfPp3L8vecHQYXv0P6NoDJ16B3qMwcAySozDcD507Q1iP9MPoYO43TVTBvAXQsCzsMKqaoecg1C6C+qVQ3wbNK6CsFnwMeo/AvIVgmS4eJSLFxMy2unvGU8EWdQ8dwsHR31+ziG899Qq3/doFLMvUS4fQq25bH35yGeqFvqMQL4Vje0P4A3S3h51BojwEes9B6NoLB7aEXn42sQQkR6Bucejtl9eFnUHTirCsaUV4z1gc2jfDqneF+2XztAMQKTJF30MH6Owd4rrP/4wrl9Tz1Q+uxWY6CEeHw0HXkwegog56DkNfx+mdQ80CePnx0PbVp2Asy6l/4fQOoKIeqltOL6+ogwWXhwthD/VCWQ0MHA/HB5ouCsNFA8ehbhEM94XlIjLnqIc+iabqMv70+hXc84MXeGjzq9yybvHMFlBSCovWAmuzt7nmI+G29yiUVoehncPPQl8nlNeGnUDvUTj6AjRcEIZpul+FkvIwBHRoG7zyZP41lc2DmpYwBFTZGObil9WE12y5DMrnhZ1GZRMcfznMBhoZDENE81eG9QMnwJPhteL6UxOZbuqhp4wlnQ985Sl++fIx/vFDV7GuLYI91P5jMNwbdgh7fxqGg5a8FTpehP7OsPzkwdAmORbun9gfDvCWlIehoYEcV3tKV9kUXhPCTqF2UXj/kf7wScGTYciotCrsGBKV4TjBcE94ro+FC3bXLwH38Ill/iXh9Tp2hgPP2T5JjQyGoS2RCMrVQ88r0M1sA/C3QBz4krt/ZsJ6S61/B9APfMDdn871mnMt0AG6eof4vfue5MCJAT5182p+98qFMz/8MteNDoWpm2Yh+MdGw/BM+5bTQz1HX4AjL8DRHWFnULswHDyOl4ULcR95Acqq4fi+M3vvioawIxg8ET4FjB+Enn8JHN8f3qNpOex+LHxi6OuA5ddD3RJIVMCv/jHslK7/ZDi+4Q7PPwxXvg8WrQvXkf3+n8Cb/wQuvTl8qtn2EPz6x8Lztn4N1vxheP+q+eG99zwGl/5uGNIa6oVdj8JFvwklZXDwV6G2RAWcPBSWVTaE9x1ODXtBeN/kaGiXbmw0fLIZ/z9qFn7/278Pl/wWlFSEGsrSjvu4h09t1c1hem1yJLwvQOcuOLIdLn1nePzzz4VPWxdtCL/L3qPh+MzEf+/x5w/3h5la8cSZ/bvJlDqnQDezOPAScD3QDmwGbnX3F9LavAP4MCHQrwL+1t2vyvW6czHQIYT67f93K1v3H2flgnncuKqF5efVUFNeQnkiRkkshhnEUkEfMzv1ONwCpC1LaxN+jJiBEW5Ju5++DjvdATXCunA7vsxe00E1O73MTi2b8Jy5tnMaHQ4BPdIfQqj3cJgSOtwPOIwNh08Ro4PhIPPRHWEK6Ogg9BwKgVXdDB0vhSEeT4YDw576nkBFQ/6fKCYqrQ6hO35/vE6LhfuJSrD46U8U578h7MhOHgizls5bFT4FQThG0flSCOw1fwgvPQJdu2HBFdC6FnZshMGTcOHbQqge2xMOfh/bCys2QNeucHzj0pvDsj3/CsveFrbt4K9g0VXQfSAc/0hUhp3MFe8JV906eRCuvweWvBm+mDqg/97vh+34+u+Ex+95GB77ZBjCW/2fwic2T4Yht92PhRqX/Tr8+xfCzmPVu8OOsKoZWlaHf6e+o2HHVNkYaq2eHy623rQi7NRPvALnXRr+fXsOhbbltaGORGV4P0+GncXRHeGTGUDPkTDlt78zvE/dkrCjPnkwTAs+sT/sxMrnhZ3SUE+YOTbYHY4F1S0OO7Lq+akd60GoagqfOId6w/MsFnaoY8OhrrHhcCyqoi48Hu4NHZWhk+G9EhXh02b5vNOnBYmXhu0YHQw/YyNh/WjqeNepv5uKMBx6+R+EjsNZONdAfzPwCXe/IfX4owDu/um0Nl8Efubu30o93glc6+6Hsr3uXA10gGTS+c7Wdr7xy/1sa89yzvQCli30jdN7kEw7j/EdS6rJqXanXidDG7NTrdPWn36vic85tSy9nkm25TVSf8+VDNBvldR4L/O8h2rv42B8AbXew5Lkq/RYDS3JI+yOX0CDH2dxsp0EoxyInc/FYy9R4YP0WhW9VsXC5CFiJPlV/DIuG9uO4VT6AJX0syV+BetHn6TK++izSg7FFrBm9FcYzsFYCx3WxOVjz/FybCl1foIVyT0csAU8kXgTq8Z2sHJsJ/tji9gVW8aVY9sYIcGh2HmcnzzEc/FLuWb03zhqTeyLL+aq0a2UMMoA5VQxwABlPFXyRtaNPs3LsSVU0k9L8gjlDAPwqp3PkJVxYfLlSX+PAMetlnrvZm9sCb1WxfKxPbwQv5jlY3uYRy87Y8uo8gFa/SAvxZZR6yeJM8oQZZywWgyopJ8+Kmn2To7E5rMgeYRBynk5vpjFyXYAOq0BMMp9kDhJEoyQJIZjVHkf++KLOT95GDCOxpqZn+ygx6rosypakwcZoJwjsflcOLaHrlgDfVZFlffhxBignEY/Rq9VM0yCFj/KgdgCmpJdxBnjUKyFOu8m4SMMWDnV3gfAGHFGrYRhEoxRQgkj1HgfI5QwZGXUejcnrQYnRpkP0WPVVHk/g1aOA+U+RIIRhqws9Rpxqr2PIQvfOYmTZIw4FT7A8Vg9/RfdzHW/d2de/y6v/5s/t0B/N7DB3W9LPX4vcJW735nW5gfAZ9z9idTjx4A/d/ctE17rduB2gMWLF79x//79Z7VBM6l7YIRXuvrpHx5lcDTJ6FgSd0i644T88NT9pPupdaQ9fm378TbgOMnUizhhRxJeh9ec1tdTbccXedqy8fWkvXa2Ns7p95r4uhOX8ZrXydwm/U/H034f4Xmnn3O63enfR7Y24++dz5Gdyf5209e+ptYsrzEjR5PSh0+AkuQwo5bIejzAfAwnBmaUJfspH+ujO9FM4/BB+uM1DMRrwmuanXptw5k/0k5XSQtJi7Oi/2nqRrt4ufwSRmOlXNS3FcPZW7GKkyUNtA7u5mRJA4dKl1IzdpyeeP1r6kkkB6kd7aIzcT4AZT7AkFVM37TY2TmsN6OuX3ke73zDwrN67rnOcsn0rzbxV55PG9z9fuB+CD30PN571tVWJFjdWjvbZYhMcOUk69P/v0+cPfWbEx5fd+7lyJyQz7lc2oFFaY9bgYnnnM2njYiITKN8An0zsNzM2sysFLgF2DihzUbgfRa8CejONX4uIiJTb9IhF3cfNbM7gUcJ0xYfcPftZnZHav19wCbCDJfdhGmLH5y+kkVEJJO8vr7n7psIoZ2+7L60+w7816ktTUREzkRRnw9dRCRKFOgiIhGhQBcRiQgFuohIRMza2RbNrAM426+KNgGdU1hOIdA2Fwdtc3E4l21e4u7NmVbMWqCfCzPbku2rr1GlbS4O2ubiMF3brCEXEZGIUKCLiEREoQb6/bNdwCzQNhcHbXNxmJZtLsgxdBEReb1C7aGLiMgECnQRkYgouEA3sw1mttPMdpvZ3bNdz1QxswfM7KiZPZ+2rMHMfmxmu1K39WnrPpr6Hew0sxtmp+pzY2aLzOynZrbDzLab2X9PLY/sdptZuZk9ZWbbUtv8ydTyyG4zhGsTm9mvUlc3i/z2ApjZPjN7zsyeMbMtqWXTu93h8mKF8UM4fe8e4AKgFNgGrJztuqZo29YTLkPzfNqyzwF3p+7fDXw2dX9latvLgLbU7yQ+29twFtu8ALgydb+GcDHylVHebsLVvapT9xPAL4E3RXmbU9vxZ8A3gR+kHkd6e1Pbsg9omrBsWre70Hro64Dd7r7X3YeBB4GbZrmmKeHujwMTL1F/E/C11P2vAe9MW/6guw+5+8uE89Cvm4k6p5K7H3L3p1P3e4AdwEIivN0e9KYeJlI/ToS32cxaCde9+1La4shu7ySmdbsLLdAXAq+mPW5PLYuq8zx15afU7fzU8sj9HsxsKfAGQo810tudGn54BjgK/Njdo77NfwN8BEimLYvy9o5z4EdmttXMbk8tm9btzusCF3NIXhejLgKR+j2YWTXwMPCn7n7Ssl9NPhLb7e5jwBVmVgd8z8xW5Whe0NtsZr8FHHX3rWZ2bT5PybCsYLZ3gqvd/aCZzQd+bGYv5mg7JdtdaD30YrsY9REzWwCQuj2aWh6Z34OZJQhh/g13/25qceS3G8DdTwA/AzYQ3W2+GvgdM9tHGCL9dTP7R6K7vae4+8HU7VHge4QhlGnd7kIL9HwuWB0lG4H3p+6/H/jntOW3mFmZmbUBy4GnZqG+c2KhK/5lYIe7/5+0VZHdbjNrTvXMMbMK4DeAF4noNrv7R9291d2XEv6//qu7/2ciur3jzKzKzGrG7wNvB55nurd7to8En8WR43cQZkPsAT422/VM4XZ9CzgEjBD21h8CGoHHgF2p24a09h9L/Q52AjfOdv1nuc1vJXysfBZ4JvXzjihvN3AZ8KvUNj8P/GVqeWS3OW07ruX0LJdIby9hJt621M/28aya7u3WV/9FRCKi0IZcREQkCwW6iEhEKNBFRCJCgS4iEhEKdBGRiFCgi4hEhAJdRCQi/j+pbmq7SavibgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efdaad14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2928350770380348e-05, 0.0035798398312181234]\n",
      "[1.3479855624609627e-05, 0.003668147372081876]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_train, y_train, verbose=0)) # The training error\n",
    "print(model.evaluate(X_test, y_test, verbose=0))   # The test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "394cb96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65791404],\n",
       "       [0.78070706],\n",
       "       [0.72066146],\n",
       "       [0.8001161 ],\n",
       "       [0.80211365],\n",
       "       [0.81057286],\n",
       "       [0.81666327],\n",
       "       [0.67372894],\n",
       "       [0.7901883 ],\n",
       "       [0.7310519 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = model.predict(X_test)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb5d3f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct Entropy</th>\n",
       "      <th>Model Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.661332</td>\n",
       "      <td>0.657914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.784546</td>\n",
       "      <td>0.780707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.724411</td>\n",
       "      <td>0.720661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.803932</td>\n",
       "      <td>0.800116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.805925</td>\n",
       "      <td>0.802114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.814360</td>\n",
       "      <td>0.810573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.820364</td>\n",
       "      <td>0.816663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.677254</td>\n",
       "      <td>0.673729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.793816</td>\n",
       "      <td>0.790188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.734460</td>\n",
       "      <td>0.731052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Correct Entropy  Model Predictions\n",
       "0         0.661332           0.657914\n",
       "1         0.784546           0.780707\n",
       "2         0.724411           0.720661\n",
       "3         0.803932           0.800116\n",
       "4         0.805925           0.802114\n",
       "5         0.814360           0.810573\n",
       "6         0.820364           0.816663\n",
       "7         0.677254           0.673729\n",
       "8         0.793816           0.790188\n",
       "9         0.734460           0.731052"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = pd.DataFrame(test_predictions)\n",
    "test_pred.columns = ['Model Predictions']\n",
    "\n",
    "pred_df = pd.DataFrame(y_test)\n",
    "pred_df_reset_index = pred_df.reset_index(drop=True)\n",
    "\n",
    "df_compare = pd.concat([pred_df_reset_index, test_pred], axis = 1)\n",
    "df_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd236e4",
   "metadata": {},
   "source": [
    "### Two Intervals at Decompactification Limit (Varying $x$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f62b111",
   "metadata": {},
   "source": [
    "Note that in this case we can also fix $x$ while varying $\\alpha$.\n",
    "\n",
    "Only approximate analytic result known. We will temporily take it as the correct entropy.\n",
    "\n",
    "Is it possible to find a better analytic result? (e.g. use some pre-trained model, under the assumption that analytic continuation is not pattern-less)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeefe88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\") \n",
    "# to restart the kernel, prevent from reusing any trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cce7f8",
   "metadata": {},
   "source": [
    "$k$ is only up to 100.\n",
    "\n",
    "$x=0.1, x<0.6, x+=0.005$\n",
    "\n",
    "10000 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75956a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct Entropy</th>\n",
       "      <th>Approx Entropy</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.07696</td>\n",
       "      <td>1.046462</td>\n",
       "      <td>0.487760</td>\n",
       "      <td>0.160987</td>\n",
       "      <td>0.083663</td>\n",
       "      <td>0.052823</td>\n",
       "      <td>0.036960</td>\n",
       "      <td>0.027552</td>\n",
       "      <td>0.021450</td>\n",
       "      <td>0.017242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.08691</td>\n",
       "      <td>1.055876</td>\n",
       "      <td>0.491345</td>\n",
       "      <td>0.162462</td>\n",
       "      <td>0.084450</td>\n",
       "      <td>0.053330</td>\n",
       "      <td>0.037326</td>\n",
       "      <td>0.027833</td>\n",
       "      <td>0.021675</td>\n",
       "      <td>0.017427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.09631</td>\n",
       "      <td>1.064758</td>\n",
       "      <td>0.494707</td>\n",
       "      <td>0.163855</td>\n",
       "      <td>0.085195</td>\n",
       "      <td>0.053811</td>\n",
       "      <td>0.037672</td>\n",
       "      <td>0.028099</td>\n",
       "      <td>0.021888</td>\n",
       "      <td>0.017603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.10520</td>\n",
       "      <td>1.073157</td>\n",
       "      <td>0.497867</td>\n",
       "      <td>0.165174</td>\n",
       "      <td>0.085902</td>\n",
       "      <td>0.054266</td>\n",
       "      <td>0.038001</td>\n",
       "      <td>0.028351</td>\n",
       "      <td>0.022091</td>\n",
       "      <td>0.017770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.11363</td>\n",
       "      <td>1.081115</td>\n",
       "      <td>0.500845</td>\n",
       "      <td>0.166423</td>\n",
       "      <td>0.086573</td>\n",
       "      <td>0.054699</td>\n",
       "      <td>0.038313</td>\n",
       "      <td>0.028592</td>\n",
       "      <td>0.022283</td>\n",
       "      <td>0.017929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.29957</td>\n",
       "      <td>1.255346</td>\n",
       "      <td>0.562168</td>\n",
       "      <td>0.193860</td>\n",
       "      <td>0.101678</td>\n",
       "      <td>0.064488</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>0.034026</td>\n",
       "      <td>0.026648</td>\n",
       "      <td>0.021537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.29888</td>\n",
       "      <td>1.254711</td>\n",
       "      <td>0.561957</td>\n",
       "      <td>0.193760</td>\n",
       "      <td>0.101621</td>\n",
       "      <td>0.064452</td>\n",
       "      <td>0.045344</td>\n",
       "      <td>0.034006</td>\n",
       "      <td>0.026631</td>\n",
       "      <td>0.021524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.29816</td>\n",
       "      <td>1.254033</td>\n",
       "      <td>0.561732</td>\n",
       "      <td>0.193654</td>\n",
       "      <td>0.101561</td>\n",
       "      <td>0.064412</td>\n",
       "      <td>0.045316</td>\n",
       "      <td>0.033984</td>\n",
       "      <td>0.026614</td>\n",
       "      <td>0.021509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.29738</td>\n",
       "      <td>1.253311</td>\n",
       "      <td>0.561492</td>\n",
       "      <td>0.193540</td>\n",
       "      <td>0.101497</td>\n",
       "      <td>0.064371</td>\n",
       "      <td>0.045286</td>\n",
       "      <td>0.033961</td>\n",
       "      <td>0.026595</td>\n",
       "      <td>0.021494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.29656</td>\n",
       "      <td>1.252545</td>\n",
       "      <td>0.561238</td>\n",
       "      <td>0.193420</td>\n",
       "      <td>0.101429</td>\n",
       "      <td>0.064326</td>\n",
       "      <td>0.045254</td>\n",
       "      <td>0.033936</td>\n",
       "      <td>0.026575</td>\n",
       "      <td>0.021477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Correct Entropy  Approx Entropy         1         2         3         4  \\\n",
       "0           1.07696        1.046462  0.487760  0.160987  0.083663  0.052823   \n",
       "1           1.08691        1.055876  0.491345  0.162462  0.084450  0.053330   \n",
       "2           1.09631        1.064758  0.494707  0.163855  0.085195  0.053811   \n",
       "3           1.10520        1.073157  0.497867  0.165174  0.085902  0.054266   \n",
       "4           1.11363        1.081115  0.500845  0.166423  0.086573  0.054699   \n",
       "..              ...             ...       ...       ...       ...       ...   \n",
       "95          1.29957        1.255346  0.562168  0.193860  0.101678  0.064488   \n",
       "96          1.29888        1.254711  0.561957  0.193760  0.101621  0.064452   \n",
       "97          1.29816        1.254033  0.561732  0.193654  0.101561  0.064412   \n",
       "98          1.29738        1.253311  0.561492  0.193540  0.101497  0.064371   \n",
       "99          1.29656        1.252545  0.561238  0.193420  0.101429  0.064326   \n",
       "\n",
       "           5         6         7         8  ...        91        92        93  \\\n",
       "0   0.036960  0.027552  0.021450  0.017242  ...  0.000275  0.000270  0.000265   \n",
       "1   0.037326  0.027833  0.021675  0.017427  ...  0.000279  0.000274  0.000269   \n",
       "2   0.037672  0.028099  0.021888  0.017603  ...  0.000283  0.000278  0.000273   \n",
       "3   0.038001  0.028351  0.022091  0.017770  ...  0.000287  0.000282  0.000276   \n",
       "4   0.038313  0.028592  0.022283  0.017929  ...  0.000291  0.000285  0.000280   \n",
       "..       ...       ...       ...       ...  ...       ...       ...       ...   \n",
       "95  0.045371  0.034026  0.026648  0.021537  ...  0.000379  0.000372  0.000365   \n",
       "96  0.045344  0.034006  0.026631  0.021524  ...  0.000379  0.000372  0.000365   \n",
       "97  0.045316  0.033984  0.026614  0.021509  ...  0.000379  0.000372  0.000365   \n",
       "98  0.045286  0.033961  0.026595  0.021494  ...  0.000378  0.000371  0.000364   \n",
       "99  0.045254  0.033936  0.026575  0.021477  ...  0.000378  0.000371  0.000364   \n",
       "\n",
       "          94        95        96        97        98        99       100  \n",
       "0   0.000260  0.000255  0.000250  0.000246  0.000241  0.000237  0.000233  \n",
       "1   0.000264  0.000259  0.000254  0.000250  0.000245  0.000241  0.000237  \n",
       "2   0.000268  0.000263  0.000258  0.000253  0.000249  0.000244  0.000240  \n",
       "3   0.000271  0.000266  0.000261  0.000257  0.000252  0.000248  0.000244  \n",
       "4   0.000275  0.000270  0.000265  0.000260  0.000256  0.000251  0.000247  \n",
       "..       ...       ...       ...       ...       ...       ...       ...  \n",
       "95  0.000359  0.000352  0.000346  0.000340  0.000334  0.000329  0.000323  \n",
       "96  0.000359  0.000352  0.000346  0.000340  0.000334  0.000328  0.000323  \n",
       "97  0.000358  0.000352  0.000346  0.000339  0.000334  0.000328  0.000322  \n",
       "98  0.000358  0.000351  0.000345  0.000339  0.000333  0.000328  0.000322  \n",
       "99  0.000357  0.000351  0.000345  0.000339  0.000333  0.000327  0.000322  \n",
       "\n",
       "[100 rows x 102 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('Data_Two_Interval_decom.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "747b976e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zxpet\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.775x0.755)\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we should check the data\n",
    "# If there are problems with data (e.g. extreme values, weired distribution), use Scaler in the next block\n",
    "\n",
    "print(sns.distplot(df['Correct Entropy']))\n",
    "# Safe to ignore warnings\n",
    "\n",
    "print(df.plot(y='Correct Entropy', use_index=True))\n",
    "\n",
    "print(df.reset_index().plot.scatter(x='index',y='Correct Entropy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef5b8503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.487760</td>\n",
       "      <td>0.160987</td>\n",
       "      <td>0.083663</td>\n",
       "      <td>0.052823</td>\n",
       "      <td>0.036960</td>\n",
       "      <td>0.027552</td>\n",
       "      <td>0.021450</td>\n",
       "      <td>0.017242</td>\n",
       "      <td>0.014205</td>\n",
       "      <td>0.011934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.491345</td>\n",
       "      <td>0.162462</td>\n",
       "      <td>0.084450</td>\n",
       "      <td>0.053330</td>\n",
       "      <td>0.037326</td>\n",
       "      <td>0.027833</td>\n",
       "      <td>0.021675</td>\n",
       "      <td>0.017427</td>\n",
       "      <td>0.014361</td>\n",
       "      <td>0.012068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.494707</td>\n",
       "      <td>0.163855</td>\n",
       "      <td>0.085195</td>\n",
       "      <td>0.053811</td>\n",
       "      <td>0.037672</td>\n",
       "      <td>0.028099</td>\n",
       "      <td>0.021888</td>\n",
       "      <td>0.017603</td>\n",
       "      <td>0.014509</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.497867</td>\n",
       "      <td>0.165174</td>\n",
       "      <td>0.085902</td>\n",
       "      <td>0.054266</td>\n",
       "      <td>0.038001</td>\n",
       "      <td>0.028351</td>\n",
       "      <td>0.022091</td>\n",
       "      <td>0.017770</td>\n",
       "      <td>0.014650</td>\n",
       "      <td>0.012315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500845</td>\n",
       "      <td>0.166423</td>\n",
       "      <td>0.086573</td>\n",
       "      <td>0.054699</td>\n",
       "      <td>0.038313</td>\n",
       "      <td>0.028592</td>\n",
       "      <td>0.022283</td>\n",
       "      <td>0.017929</td>\n",
       "      <td>0.014783</td>\n",
       "      <td>0.012430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0  0.487760  0.160987  0.083663  0.052823  0.036960  0.027552  0.021450   \n",
       "1  0.491345  0.162462  0.084450  0.053330  0.037326  0.027833  0.021675   \n",
       "2  0.494707  0.163855  0.085195  0.053811  0.037672  0.028099  0.021888   \n",
       "3  0.497867  0.165174  0.085902  0.054266  0.038001  0.028351  0.022091   \n",
       "4  0.500845  0.166423  0.086573  0.054699  0.038313  0.028592  0.022283   \n",
       "\n",
       "          8         9        10  ...        91        92        93        94  \\\n",
       "0  0.017242  0.014205  0.011934  ...  0.000275  0.000270  0.000265  0.000260   \n",
       "1  0.017427  0.014361  0.012068  ...  0.000279  0.000274  0.000269  0.000264   \n",
       "2  0.017603  0.014509  0.012195  ...  0.000283  0.000278  0.000273  0.000268   \n",
       "3  0.017770  0.014650  0.012315  ...  0.000287  0.000282  0.000276  0.000271   \n",
       "4  0.017929  0.014783  0.012430  ...  0.000291  0.000285  0.000280  0.000275   \n",
       "\n",
       "         95        96        97        98        99       100  \n",
       "0  0.000255  0.000250  0.000246  0.000241  0.000237  0.000233  \n",
       "1  0.000259  0.000254  0.000250  0.000245  0.000241  0.000237  \n",
       "2  0.000263  0.000258  0.000253  0.000249  0.000244  0.000240  \n",
       "3  0.000266  0.000261  0.000257  0.000252  0.000248  0.000244  \n",
       "4  0.000270  0.000265  0.000260  0.000256  0.000251  0.000247  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.drop(['Correct Entropy','Approx Entropy'], axis = 1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "281b7ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 100)\n",
      "(10, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df1\n",
    "y = df['Correct Entropy']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state = 42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a50ea12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# We don't need to worry about the input dimensions, the layers will automatically infer input shape as the shape of \n",
    "# the first inputs they see.\n",
    "\n",
    "# Write the layers separately such that it is easy to comment out each layer\n",
    "# Note we don't need to worry about input/output sizes that connect each layer, Keras will handle it automatically.\n",
    "\n",
    "model.add(Dense(4, activation = 'relu'))\n",
    "#model.add(Dense(4, activation = 'relu'))\n",
    "#model.add(Dense(4, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(1)) \n",
    "# The final layer has only 1 node as we are predicting a single value of correct entropy\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'mse', metrics=[\"mae\"]) \n",
    "#Root Mean Squared Propagation as optimizer and  Mean Squared Error as loss fun\n",
    "\n",
    "# Note we can have customized setup (have to build from scratch):\n",
    "# model.compilte(optimizer = keras.optimizers.RMSprop(learning_rate=1e-4, loss = my_custom_loss, \n",
    "# metrics=[my_custom_metric_1, my_custom_metric_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f00d25ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 1.2961 - mae: 1.1371\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 504us/step - loss: 1.2505 - mae: 1.1169\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.2183 - mae: 1.1024\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 1.1907 - mae: 1.0898\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.1654 - mae: 1.0782\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.1416 - mae: 1.0670\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 1.1188 - mae: 1.0563\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.0966 - mae: 1.0458\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.0749 - mae: 1.0354\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.0536 - mae: 1.0251\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 1.0326 - mae: 1.0148\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 1.0119 - mae: 1.0046\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 985us/step - loss: 0.9914 - mae: 0.9943\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.9712 - mae: 0.9841\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 968us/step - loss: 0.9511 - mae: 0.9738\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.9312 - mae: 0.9636\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.9115 - mae: 0.9533\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.8919 - mae: 0.9430\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.8725 - mae: 0.9326\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.8533 - mae: 0.9223\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.8342 - mae: 0.9119\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.8153 - mae: 0.9015\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 502us/step - loss: 0.7966 - mae: 0.8910\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.7780 - mae: 0.8806\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.7595 - mae: 0.8700\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.7412 - mae: 0.8595\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.7231 - mae: 0.8489\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.7052 - mae: 0.8383\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.6874 - mae: 0.8276\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.6698 - mae: 0.8169\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.6524 - mae: 0.8062\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.6352 - mae: 0.7955\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6182 - mae: 0.7847\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.6014 - mae: 0.7739\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 497us/step - loss: 0.5847 - mae: 0.7631\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.5682 - mae: 0.7522\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.5519 - mae: 0.7414\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.5358 - mae: 0.7304\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.5199 - mae: 0.7195\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.5042 - mae: 0.7085\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.4887 - mae: 0.6974\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.4735 - mae: 0.6865\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.4584 - mae: 0.6754\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4435 - mae: 0.6643\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.4288 - mae: 0.6532\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.4144 - mae: 0.6420\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.4001 - mae: 0.6309\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.3861 - mae: 0.6197\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.3724 - mae: 0.6085\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 993us/step - loss: 0.3588 - mae: 0.5973\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.3454 - mae: 0.5860\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3323 - mae: 0.5747\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.3194 - mae: 0.5634\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.3068 - mae: 0.5521\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.2943 - mae: 0.5407\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.2821 - mae: 0.5293\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.2702 - mae: 0.5179\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.2585 - mae: 0.5066\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.2470 - mae: 0.4951\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.2358 - mae: 0.4836\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.2248 - mae: 0.4722\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.2141 - mae: 0.4607\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 0.2036 - mae: 0.4492\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.1934 - mae: 0.4377\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1835 - mae: 0.4262\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.1738 - mae: 0.4147\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 0.1643 - mae: 0.4032\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1551 - mae: 0.3916\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1462 - mae: 0.3801\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.1375 - mae: 0.3686\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 994us/step - loss: 0.1291 - mae: 0.3570\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.1210 - mae: 0.3454\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.1131 - mae: 0.3339\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.1055 - mae: 0.3224\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0982 - mae: 0.3108\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0912 - mae: 0.2995\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0844 - mae: 0.2879\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0780 - mae: 0.2765\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 993us/step - loss: 0.0717 - mae: 0.2650\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0658 - mae: 0.2536\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0601 - mae: 0.2422\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0547 - mae: 0.2308\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0496 - mae: 0.2195\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0448 - mae: 0.2083\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0403 - mae: 0.1971\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0360 - mae: 0.1859\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0320 - mae: 0.1750\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0283 - mae: 0.1640\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0248 - mae: 0.1532\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0216 - mae: 0.1424\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0187 - mae: 0.1319\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0160 - mae: 0.1215\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 497us/step - loss: 0.0136 - mae: 0.1108\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 504us/step - loss: 0.0115 - mae: 0.1008\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0096 - mae: 0.0912\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0079 - mae: 0.0824\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0064 - mae: 0.0738\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0052 - mae: 0.0663\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0041 - mae: 0.0590\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0033 - mae: 0.0528\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0026 - mae: 0.0471\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 0.0021 - mae: 0.0424\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0018 - mae: 0.0383\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0015 - mae: 0.0350\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0013 - mae: 0.0324\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0012 - mae: 0.0305\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0012 - mae: 0.0295\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0285\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0011 - mae: 0.0278\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0011 - mae: 0.0276\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0011 - mae: 0.0279\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0273\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0011 - mae: 0.0271\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0011 - mae: 0.0268\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0011 - mae: 0.0273\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0011 - mae: 0.0273\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0011 - mae: 0.0265\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0275\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0011 - mae: 0.0276\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0269\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0011 - mae: 0.0268\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0273\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0265\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0273\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 0s 786us/step - loss: 0.0012 - mae: 0.0274\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0270\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0280\n",
      "Epoch 128/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0271\n",
      "Epoch 129/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0011 - mae: 0.0271\n",
      "Epoch 130/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0268\n",
      "Epoch 131/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0011 - mae: 0.0270\n",
      "Epoch 132/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0276\n",
      "Epoch 133/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0011 - mae: 0.0263\n",
      "Epoch 134/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0270\n",
      "Epoch 135/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0011 - mae: 0.0272\n",
      "Epoch 136/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0253\n",
      "Epoch 137/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0011 - mae: 0.0273\n",
      "Epoch 138/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0011 - mae: 0.0271\n",
      "Epoch 139/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0271\n",
      "Epoch 140/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0011 - mae: 0.0265\n",
      "Epoch 141/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0265\n",
      "Epoch 142/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0011 - mae: 0.0263\n",
      "Epoch 143/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0011 - mae: 0.0275\n",
      "Epoch 144/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0011 - mae: 0.0256\n",
      "Epoch 145/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0272\n",
      "Epoch 146/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0266\n",
      "Epoch 147/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0011 - mae: 0.0270\n",
      "Epoch 148/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0267\n",
      "Epoch 149/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0011 - mae: 0.0261\n",
      "Epoch 150/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0011 - mae: 0.0267\n",
      "Epoch 151/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0011 - mae: 0.0269\n",
      "Epoch 152/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0011 - mae: 0.0268\n",
      "Epoch 153/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0011 - mae: 0.0268\n",
      "Epoch 154/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0011 - mae: 0.0262\n",
      "Epoch 155/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0269\n",
      "Epoch 156/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0011 - mae: 0.0278\n",
      "Epoch 157/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0011 - mae: 0.0253\n",
      "Epoch 158/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0010 - mae: 0.0260\n",
      "Epoch 159/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 0.0010 - mae: 0.0263\n",
      "Epoch 160/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0263\n",
      "Epoch 161/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0011 - mae: 0.0264\n",
      "Epoch 162/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0010 - mae: 0.0256\n",
      "Epoch 163/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0010 - mae: 0.0265\n",
      "Epoch 164/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 0.0011 - mae: 0.0254\n",
      "Epoch 165/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0010 - mae: 0.0264\n",
      "Epoch 166/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0010 - mae: 0.0250\n",
      "Epoch 167/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0010 - mae: 0.0271\n",
      "Epoch 168/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0010 - mae: 0.0261\n",
      "Epoch 169/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0010 - mae: 0.0259\n",
      "Epoch 170/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0010 - mae: 0.0262\n",
      "Epoch 171/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0010 - mae: 0.0265\n",
      "Epoch 172/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 499us/step - loss: 0.0010 - mae: 0.0248\n",
      "Epoch 173/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0010 - mae: 0.0262\n",
      "Epoch 174/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0010 - mae: 0.0261\n",
      "Epoch 175/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0010 - mae: 0.0249\n",
      "Epoch 176/500\n",
      "3/3 [==============================] - 0s 497us/step - loss: 0.0010 - mae: 0.0253\n",
      "Epoch 177/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0010 - mae: 0.0263\n",
      "Epoch 178/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0010 - mae: 0.0253\n",
      "Epoch 179/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0010 - mae: 0.0269\n",
      "Epoch 180/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 0.0010 - mae: 0.0251\n",
      "Epoch 181/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0010 - mae: 0.0265\n",
      "Epoch 182/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.0010 - mae: 0.0253\n",
      "Epoch 183/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.8851e-04 - mae: 0.0248\n",
      "Epoch 184/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 0.0010 - mae: 0.0262\n",
      "Epoch 185/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 9.9019e-04 - mae: 0.0253\n",
      "Epoch 186/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.8294e-04 - mae: 0.0249\n",
      "Epoch 187/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0010 - mae: 0.0259\n",
      "Epoch 188/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 9.7733e-04 - mae: 0.0258\n",
      "Epoch 189/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.8892e-04 - mae: 0.0252\n",
      "Epoch 190/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.8071e-04 - mae: 0.0257\n",
      "Epoch 191/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 0.0010 - mae: 0.0265\n",
      "Epoch 192/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 9.8693e-04 - mae: 0.0244\n",
      "Epoch 193/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.6939e-04 - mae: 0.0250\n",
      "Epoch 194/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.8656e-04 - mae: 0.0261\n",
      "Epoch 195/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.7469e-04 - mae: 0.0245\n",
      "Epoch 196/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.6503e-04 - mae: 0.0254\n",
      "Epoch 197/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.7114e-04 - mae: 0.0240\n",
      "Epoch 198/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.9784e-04 - mae: 0.0266\n",
      "Epoch 199/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 9.6818e-04 - mae: 0.0246\n",
      "Epoch 200/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.6719e-04 - mae: 0.0256\n",
      "Epoch 201/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 9.5062e-04 - mae: 0.0250\n",
      "Epoch 202/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.6914e-04 - mae: 0.0244\n",
      "Epoch 203/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 9.7394e-04 - mae: 0.0257\n",
      "Epoch 204/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.5488e-04 - mae: 0.0253\n",
      "Epoch 205/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 9.7089e-04 - mae: 0.0259\n",
      "Epoch 206/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 9.6699e-04 - mae: 0.0253\n",
      "Epoch 207/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 9.6165e-04 - mae: 0.0245\n",
      "Epoch 208/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.3925e-04 - mae: 0.0242\n",
      "Epoch 209/500\n",
      "3/3 [==============================] - 0s 989us/step - loss: 9.5041e-04 - mae: 0.0253\n",
      "Epoch 210/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 9.8642e-04 - mae: 0.0247\n",
      "Epoch 211/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 9.4494e-04 - mae: 0.0250\n",
      "Epoch 212/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 9.6725e-04 - mae: 0.0251\n",
      "Epoch 213/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.3675e-04 - mae: 0.0251\n",
      "Epoch 214/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.3019e-04 - mae: 0.0240\n",
      "Epoch 215/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.4023e-04 - mae: 0.0249\n",
      "Epoch 216/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.3782e-04 - mae: 0.0251\n",
      "Epoch 217/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 9.8717e-04 - mae: 0.0263\n",
      "Epoch 218/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 9.2896e-04 - mae: 0.0235\n",
      "Epoch 219/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 9.2690e-04 - mae: 0.0248\n",
      "Epoch 220/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 9.4947e-04 - mae: 0.0248\n",
      "Epoch 221/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 9.2987e-04 - mae: 0.0254\n",
      "Epoch 222/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.9357e-04 - mae: 0.0260\n",
      "Epoch 223/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 9.1924e-04 - mae: 0.0237\n",
      "Epoch 224/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 9.1084e-04 - mae: 0.0246\n",
      "Epoch 225/500\n",
      "3/3 [==============================] - 0s 772us/step - loss: 9.5015e-04 - mae: 0.0247\n",
      "Epoch 226/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.3769e-04 - mae: 0.0253\n",
      "Epoch 227/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.0739e-04 - mae: 0.0242\n",
      "Epoch 228/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.1457e-04 - mae: 0.0241\n",
      "Epoch 229/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.0497e-04 - mae: 0.0251\n",
      "Epoch 230/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.0435e-04 - mae: 0.0240\n",
      "Epoch 231/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.9815e-04 - mae: 0.0244\n",
      "Epoch 232/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.2217e-04 - mae: 0.0244\n",
      "Epoch 233/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.9714e-04 - mae: 0.0243\n",
      "Epoch 234/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.9148e-04 - mae: 0.0246\n",
      "Epoch 235/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.9363e-04 - mae: 0.0233\n",
      "Epoch 236/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.5481e-04 - mae: 0.0251\n",
      "Epoch 237/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.9711e-04 - mae: 0.0238\n",
      "Epoch 238/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 9.2549e-04 - mae: 0.0247\n",
      "Epoch 239/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 8.9271e-04 - mae: 0.0247\n",
      "Epoch 240/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.9019e-04 - mae: 0.0244\n",
      "Epoch 241/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.7795e-04 - mae: 0.0237\n",
      "Epoch 242/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.0481e-04 - mae: 0.0246\n",
      "Epoch 243/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.7722e-04 - mae: 0.0246\n",
      "Epoch 244/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.8917e-04 - mae: 0.0238\n",
      "Epoch 245/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 9.4751e-04 - mae: 0.0251\n",
      "Epoch 246/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.8349e-04 - mae: 0.0233\n",
      "Epoch 247/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.6858e-04 - mae: 0.0244\n",
      "Epoch 248/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.6628e-04 - mae: 0.0235\n",
      "Epoch 249/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.6628e-04 - mae: 0.0238\n",
      "Epoch 250/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 9.0395e-04 - mae: 0.0251\n",
      "Epoch 251/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.7072e-04 - mae: 0.0231\n",
      "Epoch 252/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 9.2124e-04 - mae: 0.0246\n",
      "Epoch 253/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.5840e-04 - mae: 0.0238\n",
      "Epoch 254/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.5821e-04 - mae: 0.0234\n",
      "Epoch 255/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.6013e-04 - mae: 0.0239\n",
      "Epoch 256/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.7554e-04 - mae: 0.0238\n",
      "Epoch 257/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.8505e-04 - mae: 0.0246\n",
      "Epoch 258/500\n",
      "3/3 [==============================] - 0s 364us/step - loss: 8.7233e-04 - mae: 0.0252\n",
      "Epoch 259/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.7096e-04 - mae: 0.0231\n",
      "Epoch 260/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.5380e-04 - mae: 0.0236\n",
      "Epoch 261/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.5316e-04 - mae: 0.0233\n",
      "Epoch 262/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.6747e-04 - mae: 0.0242\n",
      "Epoch 263/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.6825e-04 - mae: 0.0225\n",
      "Epoch 264/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.7248e-04 - mae: 0.0249\n",
      "Epoch 265/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.8087e-04 - mae: 0.0247\n",
      "Epoch 266/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.4147e-04 - mae: 0.0230\n",
      "Epoch 267/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.4849e-04 - mae: 0.0241\n",
      "Epoch 268/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.3582e-04 - mae: 0.0230\n",
      "Epoch 269/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.4588e-04 - mae: 0.0235\n",
      "Epoch 270/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 8.4171e-04 - mae: 0.0240\n",
      "Epoch 271/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.4148e-04 - mae: 0.0238\n",
      "Epoch 272/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.4411e-04 - mae: 0.0231\n",
      "Epoch 273/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.2934e-04 - mae: 0.0232\n",
      "Epoch 274/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.4112e-04 - mae: 0.0231\n",
      "Epoch 275/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.3045e-04 - mae: 0.0240\n",
      "Epoch 276/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.2795e-04 - mae: 0.0234\n",
      "Epoch 277/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.5779e-04 - mae: 0.0224\n",
      "Epoch 278/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.2200e-04 - mae: 0.0239\n",
      "Epoch 279/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.1643e-04 - mae: 0.0229\n",
      "Epoch 280/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.1304e-04 - mae: 0.0229\n",
      "Epoch 281/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.0994e-04 - mae: 0.0233\n",
      "Epoch 282/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.0756e-04 - mae: 0.0231\n",
      "Epoch 283/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.0645e-04 - mae: 0.0228\n",
      "Epoch 284/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.3678e-04 - mae: 0.0233\n",
      "Epoch 285/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.1635e-04 - mae: 0.0234\n",
      "Epoch 286/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.1714e-04 - mae: 0.0226\n",
      "Epoch 287/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.3743e-04 - mae: 0.0236\n",
      "Epoch 288/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8.0025e-04 - mae: 0.0227\n",
      "Epoch 289/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.2612e-04 - mae: 0.0223\n",
      "Epoch 290/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.0200e-04 - mae: 0.0228\n",
      "Epoch 291/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.2544e-04 - mae: 0.0236\n",
      "Epoch 292/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.9760e-04 - mae: 0.0226\n",
      "Epoch 293/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.9828e-04 - mae: 0.0229\n",
      "Epoch 294/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.9630e-04 - mae: 0.0226\n",
      "Epoch 295/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.8882e-04 - mae: 0.0225\n",
      "Epoch 296/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.1148e-04 - mae: 0.0225\n",
      "Epoch 297/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.8379e-04 - mae: 0.0235\n",
      "Epoch 298/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.7795e-04 - mae: 0.0222\n",
      "Epoch 299/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.7854e-04 - mae: 0.0223\n",
      "Epoch 300/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.8942e-04 - mae: 0.0239\n",
      "Epoch 301/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.1440e-04 - mae: 0.0224\n",
      "Epoch 302/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 7.7048e-04 - mae: 0.0221\n",
      "Epoch 303/500\n",
      "3/3 [==============================] - 0s 497us/step - loss: 8.2271e-04 - mae: 0.0224\n",
      "Epoch 304/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 8.0635e-04 - mae: 0.0235\n",
      "Epoch 305/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.7043e-04 - mae: 0.0230\n",
      "Epoch 306/500\n",
      "3/3 [==============================] - 0s 495us/step - loss: 7.7070e-04 - mae: 0.0219\n",
      "Epoch 307/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.6243e-04 - mae: 0.0225\n",
      "Epoch 308/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.7610e-04 - mae: 0.0225\n",
      "Epoch 309/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.7501e-04 - mae: 0.0223\n",
      "Epoch 310/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.9258e-04 - mae: 0.0234\n",
      "Epoch 311/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.9190e-04 - mae: 0.0236\n",
      "Epoch 312/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.6663e-04 - mae: 0.0213\n",
      "Epoch 313/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.6383e-04 - mae: 0.0228\n",
      "Epoch 314/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.5497e-04 - mae: 0.0220\n",
      "Epoch 315/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.6782e-04 - mae: 0.0232\n",
      "Epoch 316/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.8080e-04 - mae: 0.0222\n",
      "Epoch 317/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.4754e-04 - mae: 0.0224\n",
      "Epoch 318/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.5692e-04 - mae: 0.0221\n",
      "Epoch 319/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.4903e-04 - mae: 0.0215\n",
      "Epoch 320/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 8.0137e-04 - mae: 0.0240\n",
      "Epoch 321/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.4735e-04 - mae: 0.0222\n",
      "Epoch 322/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.4219e-04 - mae: 0.0217\n",
      "Epoch 323/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.3729e-04 - mae: 0.0221\n",
      "Epoch 324/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 8.1122e-04 - mae: 0.0221\n",
      "Epoch 325/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.3844e-04 - mae: 0.0227\n",
      "Epoch 326/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.5822e-04 - mae: 0.0222\n",
      "Epoch 327/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.4327e-04 - mae: 0.0211\n",
      "Epoch 328/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 7.5884e-04 - mae: 0.0224\n",
      "Epoch 329/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.3287e-04 - mae: 0.0218\n",
      "Epoch 330/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.5065e-04 - mae: 0.0221\n",
      "Epoch 331/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.2667e-04 - mae: 0.0218\n",
      "Epoch 332/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.4104e-04 - mae: 0.0221\n",
      "Epoch 333/500\n",
      "3/3 [==============================] - 0s 987us/step - loss: 7.3602e-04 - mae: 0.0217\n",
      "Epoch 334/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.3125e-04 - mae: 0.0222\n",
      "Epoch 335/500\n",
      "3/3 [==============================] - 0s 883us/step - loss: 7.3066e-04 - mae: 0.0215\n",
      "Epoch 336/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 498us/step - loss: 7.1879e-04 - mae: 0.0213\n",
      "Epoch 337/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.1739e-04 - mae: 0.0219\n",
      "Epoch 338/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.5570e-04 - mae: 0.0217\n",
      "Epoch 339/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 7.1413e-04 - mae: 0.0216\n",
      "Epoch 340/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.2099e-04 - mae: 0.0222\n",
      "Epoch 341/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.2065e-04 - mae: 0.0211\n",
      "Epoch 342/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.1606e-04 - mae: 0.0218\n",
      "Epoch 343/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.1261e-04 - mae: 0.0217\n",
      "Epoch 344/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.6714e-04 - mae: 0.0214\n",
      "Epoch 345/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 6.9966e-04 - mae: 0.0213\n",
      "Epoch 346/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.9970e-04 - mae: 0.0216\n",
      "Epoch 347/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.0110e-04 - mae: 0.0216\n",
      "Epoch 348/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 6.9646e-04 - mae: 0.0216\n",
      "Epoch 349/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 7.2863e-04 - mae: 0.0217\n",
      "Epoch 350/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.2870e-04 - mae: 0.0220\n",
      "Epoch 351/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.1078e-04 - mae: 0.0206\n",
      "Epoch 352/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 6.9195e-04 - mae: 0.0212\n",
      "Epoch 353/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 7.0501e-04 - mae: 0.0209\n",
      "Epoch 354/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.9114e-04 - mae: 0.0214\n",
      "Epoch 355/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.8375e-04 - mae: 0.0215\n",
      "Epoch 356/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.9682e-04 - mae: 0.0215\n",
      "Epoch 357/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.7954e-04 - mae: 0.0210\n",
      "Epoch 358/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.9308e-04 - mae: 0.0203\n",
      "Epoch 359/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.9263e-04 - mae: 0.0221\n",
      "Epoch 360/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 7.2532e-04 - mae: 0.0205\n",
      "Epoch 361/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.7324e-04 - mae: 0.0215\n",
      "Epoch 362/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.8383e-04 - mae: 0.0213\n",
      "Epoch 363/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.9263e-04 - mae: 0.0210\n",
      "Epoch 364/500\n",
      "3/3 [==============================] - 0s 497us/step - loss: 6.6974e-04 - mae: 0.0204\n",
      "Epoch 365/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.0078e-04 - mae: 0.0216\n",
      "Epoch 366/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 7.0261e-04 - mae: 0.0216\n",
      "Epoch 367/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.8107e-04 - mae: 0.0198\n",
      "Epoch 368/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.7485e-04 - mae: 0.0217\n",
      "Epoch 369/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 6.7318e-04 - mae: 0.0208\n",
      "Epoch 370/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.6880e-04 - mae: 0.0213\n",
      "Epoch 371/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.7465e-04 - mae: 0.0209\n",
      "Epoch 372/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 7.0964e-04 - mae: 0.0213\n",
      "Epoch 373/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.6060e-04 - mae: 0.0208\n",
      "Epoch 374/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.7463e-04 - mae: 0.0215\n",
      "Epoch 375/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.5275e-04 - mae: 0.0202\n",
      "Epoch 376/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.5162e-04 - mae: 0.0210\n",
      "Epoch 377/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.7910e-04 - mae: 0.0213\n",
      "Epoch 378/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.9697e-04 - mae: 0.0217\n",
      "Epoch 379/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.5987e-04 - mae: 0.0199\n",
      "Epoch 380/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.4816e-04 - mae: 0.0204\n",
      "Epoch 381/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.4764e-04 - mae: 0.0206\n",
      "Epoch 382/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.4482e-04 - mae: 0.0208\n",
      "Epoch 383/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.4377e-04 - mae: 0.0201\n",
      "Epoch 384/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.5674e-04 - mae: 0.0210\n",
      "Epoch 385/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.5847e-04 - mae: 0.0211\n",
      "Epoch 386/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.4820e-04 - mae: 0.0198\n",
      "Epoch 387/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.3847e-04 - mae: 0.0204\n",
      "Epoch 388/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.3174e-04 - mae: 0.0208\n",
      "Epoch 389/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.3273e-04 - mae: 0.0201\n",
      "Epoch 390/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.6455e-04 - mae: 0.0212\n",
      "Epoch 391/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 6.4080e-04 - mae: 0.0207\n",
      "Epoch 392/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.3533e-04 - mae: 0.0198\n",
      "Epoch 393/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.3291e-04 - mae: 0.0202\n",
      "Epoch 394/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.3663e-04 - mae: 0.0202\n",
      "Epoch 395/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.4135e-04 - mae: 0.0209\n",
      "Epoch 396/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.1886e-04 - mae: 0.0202\n",
      "Epoch 397/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.4398e-04 - mae: 0.0199\n",
      "Epoch 398/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.3968e-04 - mae: 0.0206\n",
      "Epoch 399/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.2128e-04 - mae: 0.0204\n",
      "Epoch 400/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.2254e-04 - mae: 0.0200\n",
      "Epoch 401/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.5179e-04 - mae: 0.0212\n",
      "Epoch 402/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.1195e-04 - mae: 0.0195\n",
      "Epoch 403/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.1274e-04 - mae: 0.0205\n",
      "Epoch 404/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.5918e-04 - mae: 0.0201\n",
      "Epoch 405/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.2298e-04 - mae: 0.0199\n",
      "Epoch 406/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.1058e-04 - mae: 0.0202\n",
      "Epoch 407/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.0477e-04 - mae: 0.0200\n",
      "Epoch 408/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.0464e-04 - mae: 0.0199\n",
      "Epoch 409/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.0621e-04 - mae: 0.0198\n",
      "Epoch 410/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 5.9611e-04 - mae: 0.0207\n",
      "Epoch 411/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 6.0859e-04 - mae: 0.0194\n",
      "Epoch 412/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.0171e-04 - mae: 0.0201\n",
      "Epoch 413/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.9207e-04 - mae: 0.0186\n",
      "Epoch 414/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.9800e-04 - mae: 0.0200\n",
      "Epoch 415/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 5.9478e-04 - mae: 0.0196\n",
      "Epoch 416/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.0431e-04 - mae: 0.0205\n",
      "Epoch 417/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.0319e-04 - mae: 0.0200\n",
      "Epoch 418/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 997us/step - loss: 6.0946e-04 - mae: 0.0191\n",
      "Epoch 419/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 6.0017e-04 - mae: 0.0201\n",
      "Epoch 420/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.8681e-04 - mae: 0.0193\n",
      "Epoch 421/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 5.7826e-04 - mae: 0.0193\n",
      "Epoch 422/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 6.3748e-04 - mae: 0.0200\n",
      "Epoch 423/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.0527e-04 - mae: 0.0201\n",
      "Epoch 424/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.8639e-04 - mae: 0.0199\n",
      "Epoch 425/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 5.7682e-04 - mae: 0.0186\n",
      "Epoch 426/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 5.8475e-04 - mae: 0.0196\n",
      "Epoch 427/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.8381e-04 - mae: 0.0205\n",
      "Epoch 428/500\n",
      "3/3 [==============================] - 0s 497us/step - loss: 5.7798e-04 - mae: 0.0186\n",
      "Epoch 429/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 5.7280e-04 - mae: 0.0196\n",
      "Epoch 430/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.6644e-04 - mae: 0.0191\n",
      "Epoch 431/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.6866e-04 - mae: 0.0194\n",
      "Epoch 432/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 6.2673e-04 - mae: 0.0196\n",
      "Epoch 433/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 5.7475e-04 - mae: 0.0197\n",
      "Epoch 434/500\n",
      "3/3 [==============================] - 0s 500us/step - loss: 5.6620e-04 - mae: 0.0181\n",
      "Epoch 435/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 5.5949e-04 - mae: 0.0197\n",
      "Epoch 436/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 5.6022e-04 - mae: 0.0188\n",
      "Epoch 437/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.6201e-04 - mae: 0.0194\n",
      "Epoch 438/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 5.6590e-04 - mae: 0.0192\n",
      "Epoch 439/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.5725e-04 - mae: 0.0185\n",
      "Epoch 440/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 5.5136e-04 - mae: 0.0195\n",
      "Epoch 441/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.4912e-04 - mae: 0.0184\n",
      "Epoch 442/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.4854e-04 - mae: 0.0195\n",
      "Epoch 443/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.8417e-04 - mae: 0.0199\n",
      "Epoch 444/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 5.8056e-04 - mae: 0.0188\n",
      "Epoch 445/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.6562e-04 - mae: 0.0194\n",
      "Epoch 446/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.4095e-04 - mae: 0.0190\n",
      "Epoch 447/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.4755e-04 - mae: 0.0194\n",
      "Epoch 448/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 5.5573e-04 - mae: 0.0182\n",
      "Epoch 449/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 5.4227e-04 - mae: 0.0188\n",
      "Epoch 450/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 5.3879e-04 - mae: 0.0190\n",
      "Epoch 451/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.3941e-04 - mae: 0.0192\n",
      "Epoch 452/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 5.8320e-04 - mae: 0.0191\n",
      "Epoch 453/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.3821e-04 - mae: 0.0183\n",
      "Epoch 454/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.4092e-04 - mae: 0.0190\n",
      "Epoch 455/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 5.2772e-04 - mae: 0.0179\n",
      "Epoch 456/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.6897e-04 - mae: 0.0195\n",
      "Epoch 457/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.2902e-04 - mae: 0.0187\n",
      "Epoch 458/500\n",
      "3/3 [==============================] - 0s 999us/step - loss: 5.8977e-04 - mae: 0.0201\n",
      "Epoch 459/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.3732e-04 - mae: 0.0183\n",
      "Epoch 460/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.2384e-04 - mae: 0.0180\n",
      "Epoch 461/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.2786e-04 - mae: 0.0185\n",
      "Epoch 462/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 5.2092e-04 - mae: 0.0185\n",
      "Epoch 463/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 5.2091e-04 - mae: 0.0186\n",
      "Epoch 464/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.2641e-04 - mae: 0.0187\n",
      "Epoch 465/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.4072e-04 - mae: 0.0186\n",
      "Epoch 466/500\n",
      "3/3 [==============================] - 0s 985us/step - loss: 5.1361e-04 - mae: 0.0185\n",
      "Epoch 467/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.5401e-04 - mae: 0.0195\n",
      "Epoch 468/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 5.2587e-04 - mae: 0.0174\n",
      "Epoch 469/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.0881e-04 - mae: 0.0182\n",
      "Epoch 470/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 5.1515e-04 - mae: 0.0184\n",
      "Epoch 471/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.1266e-04 - mae: 0.0182\n",
      "Epoch 472/500\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.3319e-04 - mae: 0.0190\n",
      "Epoch 473/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.0487e-04 - mae: 0.0188\n",
      "Epoch 474/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 5.0251e-04 - mae: 0.0167\n",
      "Epoch 475/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.0803e-04 - mae: 0.0193\n",
      "Epoch 476/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.0983e-04 - mae: 0.0180\n",
      "Epoch 477/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 5.3666e-04 - mae: 0.0192\n",
      "Epoch 478/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.1577e-04 - mae: 0.0181\n",
      "Epoch 479/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.2255e-04 - mae: 0.0187\n",
      "Epoch 480/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 5.0824e-04 - mae: 0.0181\n",
      "Epoch 481/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.0883e-04 - mae: 0.0184\n",
      "Epoch 482/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 5.0510e-04 - mae: 0.0183\n",
      "Epoch 483/500\n",
      "3/3 [==============================] - 0s 995us/step - loss: 5.1815e-04 - mae: 0.0181\n",
      "Epoch 484/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.9520e-04 - mae: 0.0178\n",
      "Epoch 485/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 5.1541e-04 - mae: 0.0192\n",
      "Epoch 486/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 5.1032e-04 - mae: 0.0174\n",
      "Epoch 487/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 4.8914e-04 - mae: 0.0181\n",
      "Epoch 488/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.8482e-04 - mae: 0.0175\n",
      "Epoch 489/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.8631e-04 - mae: 0.0182\n",
      "Epoch 490/500\n",
      "3/3 [==============================] - 0s 998us/step - loss: 4.9268e-04 - mae: 0.0176\n",
      "Epoch 491/500\n",
      "3/3 [==============================] - 0s 996us/step - loss: 4.9669e-04 - mae: 0.0176\n",
      "Epoch 492/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 4.9944e-04 - mae: 0.0186\n",
      "Epoch 493/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.8041e-04 - mae: 0.0177\n",
      "Epoch 494/500\n",
      "3/3 [==============================] - 0s 498us/step - loss: 5.0281e-04 - mae: 0.0182\n",
      "Epoch 495/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.8433e-04 - mae: 0.0177\n",
      "Epoch 496/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.8670e-04 - mae: 0.0177\n",
      "Epoch 497/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.7980e-04 - mae: 0.0181\n",
      "Epoch 498/500\n",
      "3/3 [==============================] - 0s 997us/step - loss: 4.8540e-04 - mae: 0.0177\n",
      "Epoch 499/500\n",
      "3/3 [==============================] - 0s 499us/step - loss: 4.7434e-04 - mae: 0.0175\n",
      "Epoch 500/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3 [=========>....................] - ETA: 0s - loss: 6.9311e-04 - mae: 0.0216\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "3/3 [==============================] - 0s 997us/step - loss: 4.8214e-04 - mae: 0.0178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18ea8a309a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = X_train, y = y_train, epochs = 500) \n",
    "\n",
    "# Note we haven't implemented the batch_size.\n",
    "# can set verbose=0 to turn on silent mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebc63964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4889048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0004715146205853671, 0.016912011429667473]\n",
      "[0.0007059421623125672, 0.018580269068479538]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_train, y_train, verbose=0)) # The training error\n",
    "print(model.evaluate(X_test, y_test, verbose=0))   # The test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cdea866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.289276 ],\n",
       "       [1.2790974],\n",
       "       [1.2880347],\n",
       "       [1.2715664],\n",
       "       [1.2704504],\n",
       "       [1.2642182],\n",
       "       [1.2326666],\n",
       "       [1.289398 ],\n",
       "       [1.195055 ],\n",
       "       [1.143892 ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = model.predict(X_test)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e99c3285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct Entropy</th>\n",
       "      <th>Model Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.30426</td>\n",
       "      <td>1.289276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.28817</td>\n",
       "      <td>1.279097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.30229</td>\n",
       "      <td>1.288035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.27629</td>\n",
       "      <td>1.271566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.27453</td>\n",
       "      <td>1.270450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.26471</td>\n",
       "      <td>1.264218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.21514</td>\n",
       "      <td>1.232667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.30445</td>\n",
       "      <td>1.289398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.15637</td>\n",
       "      <td>1.195055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.07696</td>\n",
       "      <td>1.143892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Correct Entropy  Model Predictions\n",
       "0          1.30426           1.289276\n",
       "1          1.28817           1.279097\n",
       "2          1.30229           1.288035\n",
       "3          1.27629           1.271566\n",
       "4          1.27453           1.270450\n",
       "5          1.26471           1.264218\n",
       "6          1.21514           1.232667\n",
       "7          1.30445           1.289398\n",
       "8          1.15637           1.195055\n",
       "9          1.07696           1.143892"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = pd.DataFrame(test_predictions)\n",
    "test_pred.columns = ['Model Predictions']\n",
    "\n",
    "pred_df = pd.DataFrame(y_test)\n",
    "pred_df_reset_index = pred_df.reset_index(drop=True)\n",
    "\n",
    "df_compare = pd.concat([pred_df_reset_index, test_pred], axis = 1)\n",
    "df_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59b515b",
   "metadata": {},
   "source": [
    "### General Two Intervals "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2e205a",
   "metadata": {},
   "source": [
    "No analytic result known. 3 approaches:\n",
    "1. We sum up to a high enough $k$, take that as the correct entropy, but we only provide data points for a range of small $k$. (Might not be very feasible as it is computational expensive)\n",
    "\n",
    "2. We provide data points up to $k$, try to predict the value at $k+1$.\n",
    "\n",
    "3. We use some pre-trained models to predict the correct entropy (under the assumption that analytic continuation is not pattern-less)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33daa014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\") \n",
    "# to restart the kernel, prevent from reusing any trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f6a902c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approx Entropy</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.817893</td>\n",
       "      <td>0.486448</td>\n",
       "      <td>0.160007</td>\n",
       "      <td>0.082875</td>\n",
       "      <td>0.052165</td>\n",
       "      <td>0.036398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.843584</td>\n",
       "      <td>0.499866</td>\n",
       "      <td>0.165680</td>\n",
       "      <td>0.085970</td>\n",
       "      <td>0.054192</td>\n",
       "      <td>0.037876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.864144</td>\n",
       "      <td>0.510477</td>\n",
       "      <td>0.170265</td>\n",
       "      <td>0.088486</td>\n",
       "      <td>0.055839</td>\n",
       "      <td>0.039076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.881031</td>\n",
       "      <td>0.519111</td>\n",
       "      <td>0.174059</td>\n",
       "      <td>0.090579</td>\n",
       "      <td>0.057209</td>\n",
       "      <td>0.040074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.895161</td>\n",
       "      <td>0.526279</td>\n",
       "      <td>0.177252</td>\n",
       "      <td>0.092347</td>\n",
       "      <td>0.058367</td>\n",
       "      <td>0.040916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.907145</td>\n",
       "      <td>0.532318</td>\n",
       "      <td>0.179973</td>\n",
       "      <td>0.093860</td>\n",
       "      <td>0.059357</td>\n",
       "      <td>0.041637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.917408</td>\n",
       "      <td>0.537460</td>\n",
       "      <td>0.182312</td>\n",
       "      <td>0.095165</td>\n",
       "      <td>0.060212</td>\n",
       "      <td>0.042259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.926255</td>\n",
       "      <td>0.541872</td>\n",
       "      <td>0.184336</td>\n",
       "      <td>0.096297</td>\n",
       "      <td>0.060953</td>\n",
       "      <td>0.042798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.933915</td>\n",
       "      <td>0.545676</td>\n",
       "      <td>0.186093</td>\n",
       "      <td>0.097282</td>\n",
       "      <td>0.061598</td>\n",
       "      <td>0.043267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.940561</td>\n",
       "      <td>0.548964</td>\n",
       "      <td>0.187621</td>\n",
       "      <td>0.098140</td>\n",
       "      <td>0.062161</td>\n",
       "      <td>0.043675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.946324</td>\n",
       "      <td>0.551806</td>\n",
       "      <td>0.188948</td>\n",
       "      <td>0.098888</td>\n",
       "      <td>0.062651</td>\n",
       "      <td>0.044031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.951310</td>\n",
       "      <td>0.554259</td>\n",
       "      <td>0.190099</td>\n",
       "      <td>0.099537</td>\n",
       "      <td>0.063076</td>\n",
       "      <td>0.044340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.955601</td>\n",
       "      <td>0.556364</td>\n",
       "      <td>0.191090</td>\n",
       "      <td>0.100097</td>\n",
       "      <td>0.063443</td>\n",
       "      <td>0.044607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.959262</td>\n",
       "      <td>0.558157</td>\n",
       "      <td>0.191937</td>\n",
       "      <td>0.100576</td>\n",
       "      <td>0.063757</td>\n",
       "      <td>0.044835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.962345</td>\n",
       "      <td>0.559664</td>\n",
       "      <td>0.192652</td>\n",
       "      <td>0.100980</td>\n",
       "      <td>0.064022</td>\n",
       "      <td>0.045027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.964892</td>\n",
       "      <td>0.560907</td>\n",
       "      <td>0.193242</td>\n",
       "      <td>0.101315</td>\n",
       "      <td>0.064242</td>\n",
       "      <td>0.045186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.966936</td>\n",
       "      <td>0.561904</td>\n",
       "      <td>0.193716</td>\n",
       "      <td>0.101583</td>\n",
       "      <td>0.064418</td>\n",
       "      <td>0.045314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.968501</td>\n",
       "      <td>0.562666</td>\n",
       "      <td>0.194080</td>\n",
       "      <td>0.101790</td>\n",
       "      <td>0.064553</td>\n",
       "      <td>0.045412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.969606</td>\n",
       "      <td>0.563204</td>\n",
       "      <td>0.194336</td>\n",
       "      <td>0.101935</td>\n",
       "      <td>0.064649</td>\n",
       "      <td>0.045482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.970265</td>\n",
       "      <td>0.563524</td>\n",
       "      <td>0.194489</td>\n",
       "      <td>0.102022</td>\n",
       "      <td>0.064706</td>\n",
       "      <td>0.045523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.970483</td>\n",
       "      <td>0.563631</td>\n",
       "      <td>0.194540</td>\n",
       "      <td>0.102051</td>\n",
       "      <td>0.064725</td>\n",
       "      <td>0.045537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.970265</td>\n",
       "      <td>0.563524</td>\n",
       "      <td>0.194489</td>\n",
       "      <td>0.102022</td>\n",
       "      <td>0.064706</td>\n",
       "      <td>0.045523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.969606</td>\n",
       "      <td>0.563204</td>\n",
       "      <td>0.194336</td>\n",
       "      <td>0.101935</td>\n",
       "      <td>0.064649</td>\n",
       "      <td>0.045482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.968501</td>\n",
       "      <td>0.562666</td>\n",
       "      <td>0.194080</td>\n",
       "      <td>0.101790</td>\n",
       "      <td>0.064553</td>\n",
       "      <td>0.045412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.966936</td>\n",
       "      <td>0.561904</td>\n",
       "      <td>0.193716</td>\n",
       "      <td>0.101583</td>\n",
       "      <td>0.064418</td>\n",
       "      <td>0.045314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Approx Entropy         1         2         3         4         5\n",
       "0         0.817893  0.486448  0.160007  0.082875  0.052165  0.036398\n",
       "1         0.843584  0.499866  0.165680  0.085970  0.054192  0.037876\n",
       "2         0.864144  0.510477  0.170265  0.088486  0.055839  0.039076\n",
       "3         0.881031  0.519111  0.174059  0.090579  0.057209  0.040074\n",
       "4         0.895161  0.526279  0.177252  0.092347  0.058367  0.040916\n",
       "5         0.907145  0.532318  0.179973  0.093860  0.059357  0.041637\n",
       "6         0.917408  0.537460  0.182312  0.095165  0.060212  0.042259\n",
       "7         0.926255  0.541872  0.184336  0.096297  0.060953  0.042798\n",
       "8         0.933915  0.545676  0.186093  0.097282  0.061598  0.043267\n",
       "9         0.940561  0.548964  0.187621  0.098140  0.062161  0.043675\n",
       "10        0.946324  0.551806  0.188948  0.098888  0.062651  0.044031\n",
       "11        0.951310  0.554259  0.190099  0.099537  0.063076  0.044340\n",
       "12        0.955601  0.556364  0.191090  0.100097  0.063443  0.044607\n",
       "13        0.959262  0.558157  0.191937  0.100576  0.063757  0.044835\n",
       "14        0.962345  0.559664  0.192652  0.100980  0.064022  0.045027\n",
       "15        0.964892  0.560907  0.193242  0.101315  0.064242  0.045186\n",
       "16        0.966936  0.561904  0.193716  0.101583  0.064418  0.045314\n",
       "17        0.968501  0.562666  0.194080  0.101790  0.064553  0.045412\n",
       "18        0.969606  0.563204  0.194336  0.101935  0.064649  0.045482\n",
       "19        0.970265  0.563524  0.194489  0.102022  0.064706  0.045523\n",
       "20        0.970483  0.563631  0.194540  0.102051  0.064725  0.045537\n",
       "21        0.970265  0.563524  0.194489  0.102022  0.064706  0.045523\n",
       "22        0.969606  0.563204  0.194336  0.101935  0.064649  0.045482\n",
       "23        0.968501  0.562666  0.194080  0.101790  0.064553  0.045412\n",
       "24        0.966936  0.561904  0.193716  0.101583  0.064418  0.045314"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('Data_Two_Interval_general.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85928451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.486448</td>\n",
       "      <td>0.160007</td>\n",
       "      <td>0.082875</td>\n",
       "      <td>0.052165</td>\n",
       "      <td>0.036398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.499866</td>\n",
       "      <td>0.165680</td>\n",
       "      <td>0.085970</td>\n",
       "      <td>0.054192</td>\n",
       "      <td>0.037876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.510477</td>\n",
       "      <td>0.170265</td>\n",
       "      <td>0.088486</td>\n",
       "      <td>0.055839</td>\n",
       "      <td>0.039076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.519111</td>\n",
       "      <td>0.174059</td>\n",
       "      <td>0.090579</td>\n",
       "      <td>0.057209</td>\n",
       "      <td>0.040074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.526279</td>\n",
       "      <td>0.177252</td>\n",
       "      <td>0.092347</td>\n",
       "      <td>0.058367</td>\n",
       "      <td>0.040916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5\n",
       "0  0.486448  0.160007  0.082875  0.052165  0.036398\n",
       "1  0.499866  0.165680  0.085970  0.054192  0.037876\n",
       "2  0.510477  0.170265  0.088486  0.055839  0.039076\n",
       "3  0.519111  0.174059  0.090579  0.057209  0.040074\n",
       "4  0.526279  0.177252  0.092347  0.058367  0.040916"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.drop(['Approx Entropy'], axis = 1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b984119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df1\n",
    "y = df['Correct Entropy']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda941a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# We don't need to worry about the input dimensions, the layers will automatically infer input shape as the shape of \n",
    "# the first inputs they see.\n",
    "\n",
    "# Write the layers separately such that it is easy to comment out each layer\n",
    "# Note we don't need to worry about input/output sizes that connect each layer, Keras will handle it automatically.\n",
    "\n",
    "model.add(Dense(4, activation = 'relu'))\n",
    "#model.add(Dense(4, activation = 'relu'))\n",
    "#model.add(Dense(4, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(1)) \n",
    "# The final layer has only 1 node as we are predicting a single value of correct entropy\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'mse', metrics=[\"mae\"]) \n",
    "#Root Mean Squared Propagation as optimizer and  Mean Squared Error as loss fun\n",
    "\n",
    "# Note we can have customized setup (have to build from scratch):\n",
    "# model.compilte(optimizer = keras.optimizers.RMSprop(learning_rate=1e-4, loss = my_custom_loss, \n",
    "# metrics=[my_custom_metric_1, my_custom_metric_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c583f7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x = X_train, y = y_train, epochs = 500) \n",
    "\n",
    "# Note we haven't implemented the batch_size.\n",
    "# can set verbose=0 to turn on silent mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f08b9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1ef386",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.evaluate(X_train, y_train, verbose=0)) # The training error\n",
    "print(model.evaluate(X_test, y_test, verbose=0))   # The test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa48f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5d23bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pd.DataFrame(test_predictions)\n",
    "test_pred.columns = ['Model Predictions']\n",
    "\n",
    "pred_df = pd.DataFrame(y_test)\n",
    "pred_df_reset_index = pred_df.reset_index(drop=True)\n",
    "\n",
    "df_compare = pd.concat([pred_df_reset_index, test_pred], axis = 1)\n",
    "df_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d0a99b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
